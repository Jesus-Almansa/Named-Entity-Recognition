{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Universidad Internacional de La Rioja (UNIR) - Máster Universitario en Inteligencia Artificial - Procesamiento del Lenguaje Natural** "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "Datos del alumno (Nombre y Apellidos): JESÚS TOMÁS ALMANSA FERNÁNDEZ\n",
    "\n",
    "Fecha: 15 de abril de 2023\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size: 20pt; font-weight: bold; color: #0098cd;\">Trabajo: Named-Entity Recognition</span>\n",
    "\n",
    "**Objetivos** \n",
    "\n",
    "Con esta actividad se tratará de que el alumno se familiarice con el manejo de la librería spacy, así como con los conceptos básicos de manejo de las técnicas NER\n",
    "\n",
    "**Descripción**\n",
    "\n",
    "En esta actividad debes procesar de forma automática un texto en lenguaje natural para detectar características básicas en el mismo, y para identificar y etiquetar las ocurrencias de conceptos como localización, moneda, empresas, etc.\n",
    "\n",
    "En la primera parte del ejercicio se proporciona un código fuente a través del cual se lee un archivo de texto y se realiza un preprocesado del mismo. En esta parte el alumno tan sólo debe ejecutar y entender el código proporcionado.\n",
    "\n",
    "En la segunda parte del ejercicio se plantean una serie de preguntas que deben ser respondidas por el alumno. Cada pregunta deberá responderse con un fragmento de código fuente que esté acompañado de la explicación correspondiente. Para elaborar el código solicitado, el alumno deberá visitar la documentación de la librería spacy, cuyos enlaces se proporcionarán donde corresponda."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parte 1: carga y preprocesamiento del texto a analizar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observa las diferentes librerías que se están importando."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "import en_core_web_sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El siguiente código simplemente carga y preprocesa el texto. Para ello, lo primero que hace es cargar un modelo de lenguaje previamente entrenado. En este caso, se utiliza <i>en_core_web_sm</i>: \n",
    "\n",
    "https://spacy.io/models/en#en_core_web_sm\n",
    "\n",
    "Al cargar el modelo de lenguaje se genera un <i>Pipeline</i>, que nos permite realizar las diferentes tareas. En este caso, vamos a utilizar el pipeline para hacer un preprocesamiento básico, que consiste en tokenizar el texto.\n",
    "\n",
    "Al final del código proporcionado <i>doc</i> representa una versión tokenizada del texto leído."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = en_core_web_sm.load()\n",
    "file_name = \"barack-obama-speech.txt\"\n",
    "doc = nlp(pathlib.Path(file_name).read_text(encoding=\"utf-8\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Playground\n",
    "\n",
    "La variable <i>doc</i> es un objeto de la clase <i>Doc</i> (https://spacy.io/api/doc)\n",
    "\n",
    "Visita la documentación de dicha clase y experimenta probando las diferentes funciones y atributos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<method-wrapper '__iter__' of spacy.tokens.doc.Doc object at 0x000001948785EE80>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc.__iter__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator at 0x194879d24a0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc.__iter__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "“"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc.__iter__().__next__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<method-wrapper '__len__' of spacy.tokens.doc.Doc object at 0x000001948785EE80>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc.__len__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1939"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(“, True, [, True)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc[0], doc[0].is_punct, doc[-1], doc[-1].is_punct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parte 2: preguntas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para responder a cada una de las preguntas planteadas deberás aportar tanto el código fuente con el cual puedes conseguir la respuesta, como una explicación válida de la respuesta y de la forma de obtenerla."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size: 14pt; font-weight: bold; color: #0098cd;\">Pregunta 1.</span>\n",
    "<span style=\"font-size: 14pt; font-weight: bold; color: #0098cd;\">¿Cuántas palabras tiene el texto?</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open (\"barack-obama-speech.txt\", \"r\") as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "“\n",
      "H\n",
      "e\n",
      "l\n",
      "l\n",
      "o\n",
      ",\n",
      " \n",
      "C\n",
      "h\n"
     ]
    }
   ],
   "source": [
    "for token in text[:10]:\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(text) #Muestra todo el contenido del texto"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos obtener la longitud del texto de diferentes maneras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Longitud de la variable text: 8860\n",
      "Longitud de la variable doc: 1939\n"
     ]
    }
   ],
   "source": [
    "print(\"Longitud de la variable text: {}\".format(len(text)))\n",
    "print(\"Longitud de la variable doc: {}\".format(len(doc)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8860"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1939"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can also obtain the length of the text with the built in function of the scapy library\n",
    "doc.__len__()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hay que tener en cuenta que el texto está lleno de signos de puntuación, espacios y caracteres especiales, es por ello que debemos filtrarlos antes de contar los tokens que hay en el texto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1686\n"
     ]
    }
   ],
   "source": [
    "palabras = []\n",
    "for token in doc:\n",
    "    if token.is_punct != True:\n",
    "        if token.is_space != True:\n",
    "            palabras.append(token)\n",
    "print(len(palabras))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Incluye aquí, debajo de la línea, la explicación de tu respuesta</b>\n",
    "<hr>\n",
    " "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como podemos observar, ambas variables poseen longitudes diferentes, pues **text** contiene todos los caracteres del texto y **doc** almacena todas las palabras del texto como tokens.\n",
    "\n",
    "Es por eso que el número de palabras que contiene el texto es de 1686, habiéndolo obtenido de la variable **doc**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size: 14pt; font-weight: bold; color: #0098cd;\">Pregunta 2.</span>\n",
    "<span style=\"font-size: 14pt; font-weight: bold; color: #0098cd;\">¿Cuántas oraciones tiene el texto?</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for sent in doc.sents:\n",
    "#     print(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentences = doc.sents[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "doc objects are generators,this means we cannot iterate over them as if it were a list or a tupple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "“Hello, Chicago.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# You can write in the first way or in the second one, it does not matter\n",
    "# sentences = list(doc.sents)[0]\n",
    "# print(sentences)\n",
    "\n",
    "# Personally, I prefer the second one\n",
    "\n",
    "sentences = list(doc.sents)\n",
    "print(sentences[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If there is anyone out there who still doubts that America is a place where all things are possible, who still wonders if the dream of our founders is alive in our time, who still questions the power of our democracy, tonight is your answer.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(sentences[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "83"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "83"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences.__len__()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Incluye aquí, debajo de la línea, la explicación de tu respuesta</b>\n",
    "<hr>\n",
    " "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gracias a la función **doc.sents** podemos acceder a cada frase de manera individual, convirtiendo primero el objeto 'generator' a lista, permitiéndonos utilizar los métodos ya conocidas como **len()** "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size: 14pt; font-weight: bold; color: #0098cd;\">Pregunta 3.</span>\n",
    "<span style=\"font-size: 14pt; font-weight: bold; color: #0098cd;\">¿Cuál es el número de palabras de la oración más grande? ¿Cual es dicha oración?</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentences[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67\n",
      "It drew strength from the not-so-young people who braved the bitter cold and scorching heat to knock on doors of perfect strangers, and from the millions of Americans who volunteered and organized and proved that more than two centuries later a government of the people, by the people, and for the people has not perished from the Earth.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "frase_longa_len = 0\n",
    "frase_longa = \"\"\n",
    "for frase in sentences:\n",
    "    if len(frase) > frase_longa_len:\n",
    "        frase_longa_len = len(frase)\n",
    "        frase_longa = frase\n",
    "\n",
    "print(frase_longa_len)\n",
    "print(frase_longa)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Incluye aquí, debajo de la línea, la explicación de tu respuesta</b>\n",
    "<hr>\n",
    " "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se pueden iterar las frases obteniendo una lista de las mismas con el comando **doc.sents**. De esta manera podemos buscar la frase con mayor longitud.\n",
    "\n",
    "La frase más larga es *\"It drew strength from the not-so-young people who braved the bitter cold and scorching heat to knock on doors of perfect strangers, and from the millions of Americans who volunteered and organized and proved that more than two centuries later a government of the people, by the people, and for the people has not perished from the Earth.\n",
    "\"* con un total de 67 tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size: 14pt; font-weight: bold; color: #0098cd;\">Pregunta 4.</span>\n",
    "<span style=\"font-size: 14pt; font-weight: bold; color: #0098cd;\">¿Cómo puedes acceder al lema, lexema y morfemas de cada token?</span>\n",
    "\n",
    "Recomendación: si no lo has hecho ya, visita la documentación de la clase <i>Token</i>: https://spacy.io/api/token"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accediendo a los tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El token es Hello y su longitud es 5\n"
     ]
    }
   ],
   "source": [
    "print(\"El token es {} y su longitud es {}\".format(doc[1], doc[1].__len__()))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc[1].lemma_"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lexema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<spacy.lexeme.Lexeme at 0x194897a3940>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc[1].lex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello\n"
     ]
    }
   ],
   "source": [
    "print(doc[1].lex.text)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Morfema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Number': 'Sing'}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc[1].morph.to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Incluye aquí, debajo de la línea, la explicación de tu respuesta</b>\n",
    "<hr>\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token: The\n",
      "Lema: the\n",
      "Lexema: The\n",
      "Morfemas: {'Definite': 'Def', 'PronType': 'Art'}\n",
      "\n",
      "Token: cats\n",
      "Lema: cat\n",
      "Lexema: cats\n",
      "Morfemas: {'Number': 'Plur'}\n",
      "\n",
      "Token: are\n",
      "Lema: be\n",
      "Lexema: are\n",
      "Morfemas: {'Mood': 'Ind', 'Tense': 'Pres', 'VerbForm': 'Fin'}\n",
      "\n",
      "Token: sleeping\n",
      "Lema: sleep\n",
      "Lexema: sleeping\n",
      "Morfemas: {'Aspect': 'Prog', 'Tense': 'Pres', 'VerbForm': 'Part'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Cargar el modelo de lenguaje correspondiente\n",
    "nlp2 = en_core_web_sm.load()\n",
    "\n",
    "\n",
    "# Procesar el texto que quieras analizar\n",
    "doc2 = nlp('The cats are sleeping')\n",
    "\n",
    "\n",
    "# Iterar sobre cada token en el texto y obtener información lingüística\n",
    "for token in doc2:\n",
    "    print('Token:', token.text)\n",
    "    print('Lema:', token.lemma_)\n",
    "    print('Lexema:', token.lex.text)\n",
    "    print('Morfemas:', token.morph.to_dict())\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token: “\n",
      "Lema: \"\n",
      "Lexema: “\n",
      "Morfemas: {'PunctSide': 'Ini', 'PunctType': 'Quot'}\n",
      "\n",
      "Token: Hello\n",
      "Lema: Hello\n",
      "Lexema: Hello\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: ,\n",
      "Lema: ,\n",
      "Lexema: ,\n",
      "Morfemas: {'PunctType': 'Comm'}\n",
      "\n",
      "Token: Chicago\n",
      "Lema: Chicago\n",
      "Lexema: Chicago\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: .\n",
      "Lema: .\n",
      "Lexema: .\n",
      "Morfemas: {'PunctType': 'Peri'}\n",
      "\n",
      "Token: \n",
      "\n",
      "Lema: \n",
      "\n",
      "Lexema: \n",
      "\n",
      "Morfemas: {}\n",
      "\n",
      "Token: If\n",
      "Lema: if\n",
      "Lexema: If\n",
      "Morfemas: {}\n",
      "\n",
      "Token: there\n",
      "Lema: there\n",
      "Lexema: there\n",
      "Morfemas: {}\n",
      "\n",
      "Token: is\n",
      "Lema: be\n",
      "Lexema: is\n",
      "Morfemas: {'Mood': 'Ind', 'Number': 'Sing', 'Person': '3', 'Tense': 'Pres', 'VerbForm': 'Fin'}\n",
      "\n",
      "Token: anyone\n",
      "Lema: anyone\n",
      "Lexema: anyone\n",
      "Morfemas: {'Number': 'Sing', 'PronType': 'Ind'}\n",
      "\n",
      "Token: out\n",
      "Lema: out\n",
      "Lexema: out\n",
      "Morfemas: {}\n",
      "\n",
      "Token: there\n",
      "Lema: there\n",
      "Lexema: there\n",
      "Morfemas: {'PronType': 'Dem'}\n",
      "\n",
      "Token: who\n",
      "Lema: who\n",
      "Lexema: who\n",
      "Morfemas: {}\n",
      "\n",
      "Token: still\n",
      "Lema: still\n",
      "Lexema: still\n",
      "Morfemas: {}\n",
      "\n",
      "Token: doubts\n",
      "Lema: doubt\n",
      "Lexema: doubts\n",
      "Morfemas: {'Number': 'Sing', 'Person': '3', 'Tense': 'Pres', 'VerbForm': 'Fin'}\n",
      "\n",
      "Token: that\n",
      "Lema: that\n",
      "Lexema: that\n",
      "Morfemas: {}\n",
      "\n",
      "Token: America\n",
      "Lema: America\n",
      "Lexema: America\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: is\n",
      "Lema: be\n",
      "Lexema: is\n",
      "Morfemas: {'Mood': 'Ind', 'Number': 'Sing', 'Person': '3', 'Tense': 'Pres', 'VerbForm': 'Fin'}\n",
      "\n",
      "Token: a\n",
      "Lema: a\n",
      "Lexema: a\n",
      "Morfemas: {'Definite': 'Ind', 'PronType': 'Art'}\n",
      "\n",
      "Token: place\n",
      "Lema: place\n",
      "Lexema: place\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: where\n",
      "Lema: where\n",
      "Lexema: where\n",
      "Morfemas: {}\n",
      "\n",
      "Token: all\n",
      "Lema: all\n",
      "Lexema: all\n",
      "Morfemas: {}\n",
      "\n",
      "Token: things\n",
      "Lema: thing\n",
      "Lexema: things\n",
      "Morfemas: {'Number': 'Plur'}\n",
      "\n",
      "Token: are\n",
      "Lema: be\n",
      "Lexema: are\n",
      "Morfemas: {'Mood': 'Ind', 'Tense': 'Pres', 'VerbForm': 'Fin'}\n",
      "\n",
      "Token: possible\n",
      "Lema: possible\n",
      "Lexema: possible\n",
      "Morfemas: {'Degree': 'Pos'}\n",
      "\n",
      "Token: ,\n",
      "Lema: ,\n",
      "Lexema: ,\n",
      "Morfemas: {'PunctType': 'Comm'}\n",
      "\n",
      "Token: who\n",
      "Lema: who\n",
      "Lexema: who\n",
      "Morfemas: {}\n",
      "\n",
      "Token: still\n",
      "Lema: still\n",
      "Lexema: still\n",
      "Morfemas: {}\n",
      "\n",
      "Token: wonders\n",
      "Lema: wonder\n",
      "Lexema: wonders\n",
      "Morfemas: {'Number': 'Sing', 'Person': '3', 'Tense': 'Pres', 'VerbForm': 'Fin'}\n",
      "\n",
      "Token: if\n",
      "Lema: if\n",
      "Lexema: if\n",
      "Morfemas: {}\n",
      "\n",
      "Token: the\n",
      "Lema: the\n",
      "Lexema: the\n",
      "Morfemas: {'Definite': 'Def', 'PronType': 'Art'}\n",
      "\n",
      "Token: dream\n",
      "Lema: dream\n",
      "Lexema: dream\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: of\n",
      "Lema: of\n",
      "Lexema: of\n",
      "Morfemas: {}\n",
      "\n",
      "Token: our\n",
      "Lema: our\n",
      "Lexema: our\n",
      "Morfemas: {'Number': 'Plur', 'Person': '1', 'Poss': 'Yes', 'PronType': 'Prs'}\n",
      "\n",
      "Token: founders\n",
      "Lema: founder\n",
      "Lexema: founders\n",
      "Morfemas: {'Number': 'Plur'}\n",
      "\n",
      "Token: is\n",
      "Lema: be\n",
      "Lexema: is\n",
      "Morfemas: {'Mood': 'Ind', 'Number': 'Sing', 'Person': '3', 'Tense': 'Pres', 'VerbForm': 'Fin'}\n",
      "\n",
      "Token: alive\n",
      "Lema: alive\n",
      "Lexema: alive\n",
      "Morfemas: {'Degree': 'Pos'}\n",
      "\n",
      "Token: in\n",
      "Lema: in\n",
      "Lexema: in\n",
      "Morfemas: {}\n",
      "\n",
      "Token: our\n",
      "Lema: our\n",
      "Lexema: our\n",
      "Morfemas: {'Number': 'Plur', 'Person': '1', 'Poss': 'Yes', 'PronType': 'Prs'}\n",
      "\n",
      "Token: time\n",
      "Lema: time\n",
      "Lexema: time\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: ,\n",
      "Lema: ,\n",
      "Lexema: ,\n",
      "Morfemas: {'PunctType': 'Comm'}\n",
      "\n",
      "Token: who\n",
      "Lema: who\n",
      "Lexema: who\n",
      "Morfemas: {}\n",
      "\n",
      "Token: still\n",
      "Lema: still\n",
      "Lexema: still\n",
      "Morfemas: {}\n",
      "\n",
      "Token: questions\n",
      "Lema: question\n",
      "Lexema: questions\n",
      "Morfemas: {'Number': 'Sing', 'Person': '3', 'Tense': 'Pres', 'VerbForm': 'Fin'}\n",
      "\n",
      "Token: the\n",
      "Lema: the\n",
      "Lexema: the\n",
      "Morfemas: {'Definite': 'Def', 'PronType': 'Art'}\n",
      "\n",
      "Token: power\n",
      "Lema: power\n",
      "Lexema: power\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: of\n",
      "Lema: of\n",
      "Lexema: of\n",
      "Morfemas: {}\n",
      "\n",
      "Token: our\n",
      "Lema: our\n",
      "Lexema: our\n",
      "Morfemas: {'Number': 'Plur', 'Person': '1', 'Poss': 'Yes', 'PronType': 'Prs'}\n",
      "\n",
      "Token: democracy\n",
      "Lema: democracy\n",
      "Lexema: democracy\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: ,\n",
      "Lema: ,\n",
      "Lexema: ,\n",
      "Morfemas: {'PunctType': 'Comm'}\n",
      "\n",
      "Token: tonight\n",
      "Lema: tonight\n",
      "Lexema: tonight\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: is\n",
      "Lema: be\n",
      "Lexema: is\n",
      "Morfemas: {'Mood': 'Ind', 'Number': 'Sing', 'Person': '3', 'Tense': 'Pres', 'VerbForm': 'Fin'}\n",
      "\n",
      "Token: your\n",
      "Lema: your\n",
      "Lexema: your\n",
      "Morfemas: {'Person': '2', 'Poss': 'Yes', 'PronType': 'Prs'}\n",
      "\n",
      "Token: answer\n",
      "Lema: answer\n",
      "Lexema: answer\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: .\n",
      "Lema: .\n",
      "Lexema: .\n",
      "Morfemas: {'PunctType': 'Peri'}\n",
      "\n",
      "Token: \n",
      "\n",
      "Lema: \n",
      "\n",
      "Lexema: \n",
      "\n",
      "Morfemas: {}\n",
      "\n",
      "Token: It\n",
      "Lema: it\n",
      "Lexema: It\n",
      "Morfemas: {'Case': 'Nom', 'Gender': 'Neut', 'Number': 'Sing', 'Person': '3', 'PronType': 'Prs'}\n",
      "\n",
      "Token: ’s\n",
      "Lema: ’\n",
      "Lexema: ’s\n",
      "Morfemas: {'Number': 'Sing', 'Person': '3', 'Tense': 'Pres', 'VerbForm': 'Fin'}\n",
      "\n",
      "Token: the\n",
      "Lema: the\n",
      "Lexema: the\n",
      "Morfemas: {'Definite': 'Def', 'PronType': 'Art'}\n",
      "\n",
      "Token: answer\n",
      "Lema: answer\n",
      "Lexema: answer\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: told\n",
      "Lema: tell\n",
      "Lexema: told\n",
      "Morfemas: {'Aspect': 'Perf', 'Tense': 'Past', 'VerbForm': 'Part'}\n",
      "\n",
      "Token: by\n",
      "Lema: by\n",
      "Lexema: by\n",
      "Morfemas: {}\n",
      "\n",
      "Token: lines\n",
      "Lema: line\n",
      "Lexema: lines\n",
      "Morfemas: {'Number': 'Plur'}\n",
      "\n",
      "Token: that\n",
      "Lema: that\n",
      "Lexema: that\n",
      "Morfemas: {'PronType': 'Rel'}\n",
      "\n",
      "Token: stretched\n",
      "Lema: stretch\n",
      "Lexema: stretched\n",
      "Morfemas: {'Tense': 'Past', 'VerbForm': 'Fin'}\n",
      "\n",
      "Token: around\n",
      "Lema: around\n",
      "Lexema: around\n",
      "Morfemas: {}\n",
      "\n",
      "Token: schools\n",
      "Lema: school\n",
      "Lexema: schools\n",
      "Morfemas: {'Number': 'Plur'}\n",
      "\n",
      "Token: and\n",
      "Lema: and\n",
      "Lexema: and\n",
      "Morfemas: {'ConjType': 'Cmp'}\n",
      "\n",
      "Token: churches\n",
      "Lema: church\n",
      "Lexema: churches\n",
      "Morfemas: {'Number': 'Plur'}\n",
      "\n",
      "Token: in\n",
      "Lema: in\n",
      "Lexema: in\n",
      "Morfemas: {}\n",
      "\n",
      "Token: numbers\n",
      "Lema: number\n",
      "Lexema: numbers\n",
      "Morfemas: {'Number': 'Plur'}\n",
      "\n",
      "Token: this\n",
      "Lema: this\n",
      "Lexema: this\n",
      "Morfemas: {'Number': 'Sing', 'PronType': 'Dem'}\n",
      "\n",
      "Token: nation\n",
      "Lema: nation\n",
      "Lexema: nation\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: has\n",
      "Lema: have\n",
      "Lexema: has\n",
      "Morfemas: {'Mood': 'Ind', 'Number': 'Sing', 'Person': '3', 'Tense': 'Pres', 'VerbForm': 'Fin'}\n",
      "\n",
      "Token: never\n",
      "Lema: never\n",
      "Lexema: never\n",
      "Morfemas: {}\n",
      "\n",
      "Token: seen\n",
      "Lema: see\n",
      "Lexema: seen\n",
      "Morfemas: {'Aspect': 'Perf', 'Tense': 'Past', 'VerbForm': 'Part'}\n",
      "\n",
      "Token: ,\n",
      "Lema: ,\n",
      "Lexema: ,\n",
      "Morfemas: {'PunctType': 'Comm'}\n",
      "\n",
      "Token: by\n",
      "Lema: by\n",
      "Lexema: by\n",
      "Morfemas: {}\n",
      "\n",
      "Token: people\n",
      "Lema: people\n",
      "Lexema: people\n",
      "Morfemas: {'Number': 'Plur'}\n",
      "\n",
      "Token: who\n",
      "Lema: who\n",
      "Lexema: who\n",
      "Morfemas: {}\n",
      "\n",
      "Token: waited\n",
      "Lema: wait\n",
      "Lexema: waited\n",
      "Morfemas: {'Tense': 'Past', 'VerbForm': 'Fin'}\n",
      "\n",
      "Token: three\n",
      "Lema: three\n",
      "Lexema: three\n",
      "Morfemas: {'NumType': 'Card'}\n",
      "\n",
      "Token: hours\n",
      "Lema: hour\n",
      "Lexema: hours\n",
      "Morfemas: {'Number': 'Plur'}\n",
      "\n",
      "Token: and\n",
      "Lema: and\n",
      "Lexema: and\n",
      "Morfemas: {'ConjType': 'Cmp'}\n",
      "\n",
      "Token: four\n",
      "Lema: four\n",
      "Lexema: four\n",
      "Morfemas: {'NumType': 'Card'}\n",
      "\n",
      "Token: hours\n",
      "Lema: hour\n",
      "Lexema: hours\n",
      "Morfemas: {'Number': 'Plur'}\n",
      "\n",
      "Token: ,\n",
      "Lema: ,\n",
      "Lexema: ,\n",
      "Morfemas: {'PunctType': 'Comm'}\n",
      "\n",
      "Token: many\n",
      "Lema: many\n",
      "Lexema: many\n",
      "Morfemas: {'Degree': 'Pos'}\n",
      "\n",
      "Token: for\n",
      "Lema: for\n",
      "Lexema: for\n",
      "Morfemas: {}\n",
      "\n",
      "Token: the\n",
      "Lema: the\n",
      "Lexema: the\n",
      "Morfemas: {'Definite': 'Def', 'PronType': 'Art'}\n",
      "\n",
      "Token: first\n",
      "Lema: first\n",
      "Lexema: first\n",
      "Morfemas: {'Degree': 'Pos'}\n",
      "\n",
      "Token: time\n",
      "Lema: time\n",
      "Lexema: time\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: in\n",
      "Lema: in\n",
      "Lexema: in\n",
      "Morfemas: {}\n",
      "\n",
      "Token: their\n",
      "Lema: their\n",
      "Lexema: their\n",
      "Morfemas: {'Number': 'Plur', 'Person': '3', 'Poss': 'Yes', 'PronType': 'Prs'}\n",
      "\n",
      "Token: lives\n",
      "Lema: life\n",
      "Lexema: lives\n",
      "Morfemas: {'Number': 'Plur'}\n",
      "\n",
      "Token: ,\n",
      "Lema: ,\n",
      "Lexema: ,\n",
      "Morfemas: {'PunctType': 'Comm'}\n",
      "\n",
      "Token: because\n",
      "Lema: because\n",
      "Lexema: because\n",
      "Morfemas: {}\n",
      "\n",
      "Token: they\n",
      "Lema: they\n",
      "Lexema: they\n",
      "Morfemas: {'Case': 'Nom', 'Number': 'Plur', 'Person': '3', 'PronType': 'Prs'}\n",
      "\n",
      "Token: believed\n",
      "Lema: believe\n",
      "Lexema: believed\n",
      "Morfemas: {'Tense': 'Past', 'VerbForm': 'Fin'}\n",
      "\n",
      "Token: that\n",
      "Lema: that\n",
      "Lexema: that\n",
      "Morfemas: {}\n",
      "\n",
      "Token: this\n",
      "Lema: this\n",
      "Lexema: this\n",
      "Morfemas: {'Number': 'Sing', 'PronType': 'Dem'}\n",
      "\n",
      "Token: time\n",
      "Lema: time\n",
      "Lexema: time\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: must\n",
      "Lema: must\n",
      "Lexema: must\n",
      "Morfemas: {'VerbForm': 'Fin'}\n",
      "\n",
      "Token: be\n",
      "Lema: be\n",
      "Lexema: be\n",
      "Morfemas: {'VerbForm': 'Inf'}\n",
      "\n",
      "Token: different\n",
      "Lema: different\n",
      "Lexema: different\n",
      "Morfemas: {'Degree': 'Pos'}\n",
      "\n",
      "Token: ,\n",
      "Lema: ,\n",
      "Lexema: ,\n",
      "Morfemas: {'PunctType': 'Comm'}\n",
      "\n",
      "Token: that\n",
      "Lema: that\n",
      "Lexema: that\n",
      "Morfemas: {}\n",
      "\n",
      "Token: their\n",
      "Lema: their\n",
      "Lexema: their\n",
      "Morfemas: {'Number': 'Plur', 'Person': '3', 'Poss': 'Yes', 'PronType': 'Prs'}\n",
      "\n",
      "Token: voices\n",
      "Lema: voice\n",
      "Lexema: voices\n",
      "Morfemas: {'Number': 'Plur'}\n",
      "\n",
      "Token: could\n",
      "Lema: could\n",
      "Lexema: could\n",
      "Morfemas: {'VerbForm': 'Fin'}\n",
      "\n",
      "Token: be\n",
      "Lema: be\n",
      "Lexema: be\n",
      "Morfemas: {'VerbForm': 'Inf'}\n",
      "\n",
      "Token: that\n",
      "Lema: that\n",
      "Lexema: that\n",
      "Morfemas: {'Number': 'Sing', 'PronType': 'Dem'}\n",
      "\n",
      "Token: difference\n",
      "Lema: difference\n",
      "Lexema: difference\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: .\n",
      "Lema: .\n",
      "Lexema: .\n",
      "Morfemas: {'PunctType': 'Peri'}\n",
      "\n",
      "Token: \n",
      "\n",
      "Lema: \n",
      "\n",
      "Lexema: \n",
      "\n",
      "Morfemas: {}\n",
      "\n",
      "Token: It\n",
      "Lema: it\n",
      "Lexema: It\n",
      "Morfemas: {'Case': 'Nom', 'Gender': 'Neut', 'Number': 'Sing', 'Person': '3', 'PronType': 'Prs'}\n",
      "\n",
      "Token: ’s\n",
      "Lema: ’\n",
      "Lexema: ’s\n",
      "Morfemas: {'Number': 'Sing', 'Person': '3', 'Tense': 'Pres', 'VerbForm': 'Fin'}\n",
      "\n",
      "Token: the\n",
      "Lema: the\n",
      "Lexema: the\n",
      "Morfemas: {'Definite': 'Def', 'PronType': 'Art'}\n",
      "\n",
      "Token: answer\n",
      "Lema: answer\n",
      "Lexema: answer\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: spoken\n",
      "Lema: speak\n",
      "Lexema: spoken\n",
      "Morfemas: {'Aspect': 'Perf', 'Tense': 'Past', 'VerbForm': 'Part'}\n",
      "\n",
      "Token: by\n",
      "Lema: by\n",
      "Lexema: by\n",
      "Morfemas: {}\n",
      "\n",
      "Token: young\n",
      "Lema: young\n",
      "Lexema: young\n",
      "Morfemas: {'Degree': 'Pos'}\n",
      "\n",
      "Token: and\n",
      "Lema: and\n",
      "Lexema: and\n",
      "Morfemas: {'ConjType': 'Cmp'}\n",
      "\n",
      "Token: old\n",
      "Lema: old\n",
      "Lexema: old\n",
      "Morfemas: {'Degree': 'Pos'}\n",
      "\n",
      "Token: ,\n",
      "Lema: ,\n",
      "Lexema: ,\n",
      "Morfemas: {'PunctType': 'Comm'}\n",
      "\n",
      "Token: rich\n",
      "Lema: rich\n",
      "Lexema: rich\n",
      "Morfemas: {'Degree': 'Pos'}\n",
      "\n",
      "Token: and\n",
      "Lema: and\n",
      "Lexema: and\n",
      "Morfemas: {'ConjType': 'Cmp'}\n",
      "\n",
      "Token: poor\n",
      "Lema: poor\n",
      "Lexema: poor\n",
      "Morfemas: {'Degree': 'Pos'}\n",
      "\n",
      "Token: ,\n",
      "Lema: ,\n",
      "Lexema: ,\n",
      "Morfemas: {'PunctType': 'Comm'}\n",
      "\n",
      "Token: Democrat\n",
      "Lema: Democrat\n",
      "Lexema: Democrat\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: and\n",
      "Lema: and\n",
      "Lexema: and\n",
      "Morfemas: {'ConjType': 'Cmp'}\n",
      "\n",
      "Token: Republican\n",
      "Lema: Republican\n",
      "Lexema: Republican\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: ,\n",
      "Lema: ,\n",
      "Lexema: ,\n",
      "Morfemas: {'PunctType': 'Comm'}\n",
      "\n",
      "Token: black\n",
      "Lema: black\n",
      "Lexema: black\n",
      "Morfemas: {'Degree': 'Pos'}\n",
      "\n",
      "Token: ,\n",
      "Lema: ,\n",
      "Lexema: ,\n",
      "Morfemas: {'PunctType': 'Comm'}\n",
      "\n",
      "Token: white\n",
      "Lema: white\n",
      "Lexema: white\n",
      "Morfemas: {'Degree': 'Pos'}\n",
      "\n",
      "Token: ,\n",
      "Lema: ,\n",
      "Lexema: ,\n",
      "Morfemas: {'PunctType': 'Comm'}\n",
      "\n",
      "Token: Hispanic\n",
      "Lema: hispanic\n",
      "Lexema: Hispanic\n",
      "Morfemas: {'Degree': 'Pos'}\n",
      "\n",
      "Token: ,\n",
      "Lema: ,\n",
      "Lexema: ,\n",
      "Morfemas: {'PunctType': 'Comm'}\n",
      "\n",
      "Token: Asian\n",
      "Lema: asian\n",
      "Lexema: Asian\n",
      "Morfemas: {'Degree': 'Pos'}\n",
      "\n",
      "Token: ,\n",
      "Lema: ,\n",
      "Lexema: ,\n",
      "Morfemas: {'PunctType': 'Comm'}\n",
      "\n",
      "Token: Native\n",
      "Lema: Native\n",
      "Lexema: Native\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: American\n",
      "Lema: American\n",
      "Lexema: American\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: ,\n",
      "Lema: ,\n",
      "Lexema: ,\n",
      "Morfemas: {'PunctType': 'Comm'}\n",
      "\n",
      "Token: gay\n",
      "Lema: gay\n",
      "Lexema: gay\n",
      "Morfemas: {'Degree': 'Pos'}\n",
      "\n",
      "Token: ,\n",
      "Lema: ,\n",
      "Lexema: ,\n",
      "Morfemas: {'PunctType': 'Comm'}\n",
      "\n",
      "Token: straight\n",
      "Lema: straight\n",
      "Lexema: straight\n",
      "Morfemas: {'Degree': 'Pos'}\n",
      "\n",
      "Token: ,\n",
      "Lema: ,\n",
      "Lexema: ,\n",
      "Morfemas: {'PunctType': 'Comm'}\n",
      "\n",
      "Token: disabled\n",
      "Lema: disabled\n",
      "Lexema: disabled\n",
      "Morfemas: {'Degree': 'Pos'}\n",
      "\n",
      "Token: and\n",
      "Lema: and\n",
      "Lexema: and\n",
      "Morfemas: {'ConjType': 'Cmp'}\n",
      "\n",
      "Token: not\n",
      "Lema: not\n",
      "Lexema: not\n",
      "Morfemas: {'Polarity': 'Neg'}\n",
      "\n",
      "Token: disabled\n",
      "Lema: disabled\n",
      "Lexema: disabled\n",
      "Morfemas: {'Degree': 'Pos'}\n",
      "\n",
      "Token: .\n",
      "Lema: .\n",
      "Lexema: .\n",
      "Morfemas: {'PunctType': 'Peri'}\n",
      "\n",
      "Token: Americans\n",
      "Lema: american\n",
      "Lexema: Americans\n",
      "Morfemas: {'Number': 'Plur'}\n",
      "\n",
      "Token: who\n",
      "Lema: who\n",
      "Lexema: who\n",
      "Morfemas: {}\n",
      "\n",
      "Token: sent\n",
      "Lema: send\n",
      "Lexema: sent\n",
      "Morfemas: {'Tense': 'Past', 'VerbForm': 'Fin'}\n",
      "\n",
      "Token: a\n",
      "Lema: a\n",
      "Lexema: a\n",
      "Morfemas: {'Definite': 'Ind', 'PronType': 'Art'}\n",
      "\n",
      "Token: message\n",
      "Lema: message\n",
      "Lexema: message\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: to\n",
      "Lema: to\n",
      "Lexema: to\n",
      "Morfemas: {}\n",
      "\n",
      "Token: the\n",
      "Lema: the\n",
      "Lexema: the\n",
      "Morfemas: {'Definite': 'Def', 'PronType': 'Art'}\n",
      "\n",
      "Token: world\n",
      "Lema: world\n",
      "Lexema: world\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: that\n",
      "Lema: that\n",
      "Lexema: that\n",
      "Morfemas: {}\n",
      "\n",
      "Token: we\n",
      "Lema: we\n",
      "Lexema: we\n",
      "Morfemas: {'Case': 'Nom', 'Number': 'Plur', 'Person': '1', 'PronType': 'Prs'}\n",
      "\n",
      "Token: have\n",
      "Lema: have\n",
      "Lexema: have\n",
      "Morfemas: {'Mood': 'Ind', 'Tense': 'Pres', 'VerbForm': 'Fin'}\n",
      "\n",
      "Token: never\n",
      "Lema: never\n",
      "Lexema: never\n",
      "Morfemas: {}\n",
      "\n",
      "Token: been\n",
      "Lema: be\n",
      "Lexema: been\n",
      "Morfemas: {'Tense': 'Past', 'VerbForm': 'Part'}\n",
      "\n",
      "Token: just\n",
      "Lema: just\n",
      "Lexema: just\n",
      "Morfemas: {}\n",
      "\n",
      "Token: a\n",
      "Lema: a\n",
      "Lexema: a\n",
      "Morfemas: {'Definite': 'Ind', 'PronType': 'Art'}\n",
      "\n",
      "Token: collection\n",
      "Lema: collection\n",
      "Lexema: collection\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: of\n",
      "Lema: of\n",
      "Lexema: of\n",
      "Morfemas: {}\n",
      "\n",
      "Token: individuals\n",
      "Lema: individual\n",
      "Lexema: individuals\n",
      "Morfemas: {'Number': 'Plur'}\n",
      "\n",
      "Token: or\n",
      "Lema: or\n",
      "Lexema: or\n",
      "Morfemas: {'ConjType': 'Cmp'}\n",
      "\n",
      "Token: a\n",
      "Lema: a\n",
      "Lexema: a\n",
      "Morfemas: {'Definite': 'Ind', 'PronType': 'Art'}\n",
      "\n",
      "Token: collection\n",
      "Lema: collection\n",
      "Lexema: collection\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: of\n",
      "Lema: of\n",
      "Lexema: of\n",
      "Morfemas: {}\n",
      "\n",
      "Token: red\n",
      "Lema: red\n",
      "Lexema: red\n",
      "Morfemas: {'Degree': 'Pos'}\n",
      "\n",
      "Token: states\n",
      "Lema: state\n",
      "Lexema: states\n",
      "Morfemas: {'Number': 'Plur'}\n",
      "\n",
      "Token: and\n",
      "Lema: and\n",
      "Lexema: and\n",
      "Morfemas: {'ConjType': 'Cmp'}\n",
      "\n",
      "Token: blue\n",
      "Lema: blue\n",
      "Lexema: blue\n",
      "Morfemas: {'Degree': 'Pos'}\n",
      "\n",
      "Token: states\n",
      "Lema: state\n",
      "Lexema: states\n",
      "Morfemas: {'Number': 'Plur'}\n",
      "\n",
      "Token: .\n",
      "Lema: .\n",
      "Lexema: .\n",
      "Morfemas: {'PunctType': 'Peri'}\n",
      "\n",
      "Token: \n",
      "\n",
      "Lema: \n",
      "\n",
      "Lexema: \n",
      "\n",
      "Morfemas: {}\n",
      "\n",
      "Token: We\n",
      "Lema: we\n",
      "Lexema: We\n",
      "Morfemas: {'Case': 'Nom', 'Number': 'Plur', 'Person': '1', 'PronType': 'Prs'}\n",
      "\n",
      "Token: are\n",
      "Lema: be\n",
      "Lexema: are\n",
      "Morfemas: {'Mood': 'Ind', 'Tense': 'Pres', 'VerbForm': 'Fin'}\n",
      "\n",
      "Token: ,\n",
      "Lema: ,\n",
      "Lexema: ,\n",
      "Morfemas: {'PunctType': 'Comm'}\n",
      "\n",
      "Token: and\n",
      "Lema: and\n",
      "Lexema: and\n",
      "Morfemas: {'ConjType': 'Cmp'}\n",
      "\n",
      "Token: always\n",
      "Lema: always\n",
      "Lexema: always\n",
      "Morfemas: {}\n",
      "\n",
      "Token: will\n",
      "Lema: will\n",
      "Lexema: will\n",
      "Morfemas: {'VerbForm': 'Fin'}\n",
      "\n",
      "Token: be\n",
      "Lema: be\n",
      "Lexema: be\n",
      "Morfemas: {'VerbForm': 'Inf'}\n",
      "\n",
      "Token: ,\n",
      "Lema: ,\n",
      "Lexema: ,\n",
      "Morfemas: {'PunctType': 'Comm'}\n",
      "\n",
      "Token: the\n",
      "Lema: the\n",
      "Lexema: the\n",
      "Morfemas: {'Definite': 'Def', 'PronType': 'Art'}\n",
      "\n",
      "Token: United\n",
      "Lema: United\n",
      "Lexema: United\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: States\n",
      "Lema: States\n",
      "Lexema: States\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: of\n",
      "Lema: of\n",
      "Lexema: of\n",
      "Morfemas: {}\n",
      "\n",
      "Token: America\n",
      "Lema: America\n",
      "Lexema: America\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: .\n",
      "Lema: .\n",
      "Lexema: .\n",
      "Morfemas: {'PunctType': 'Peri'}\n",
      "\n",
      "Token: \n",
      "\n",
      "Lema: \n",
      "\n",
      "Lexema: \n",
      "\n",
      "Morfemas: {}\n",
      "\n",
      "Token: It\n",
      "Lema: it\n",
      "Lexema: It\n",
      "Morfemas: {'Case': 'Nom', 'Gender': 'Neut', 'Number': 'Sing', 'Person': '3', 'PronType': 'Prs'}\n",
      "\n",
      "Token: ’s\n",
      "Lema: ’\n",
      "Lexema: ’s\n",
      "Morfemas: {'Number': 'Sing', 'Person': '3', 'Tense': 'Pres', 'VerbForm': 'Fin'}\n",
      "\n",
      "Token: the\n",
      "Lema: the\n",
      "Lexema: the\n",
      "Morfemas: {'Definite': 'Def', 'PronType': 'Art'}\n",
      "\n",
      "Token: answer\n",
      "Lema: answer\n",
      "Lexema: answer\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: that\n",
      "Lema: that\n",
      "Lexema: that\n",
      "Morfemas: {'PronType': 'Rel'}\n",
      "\n",
      "Token: led\n",
      "Lema: lead\n",
      "Lexema: led\n",
      "Morfemas: {'Tense': 'Past', 'VerbForm': 'Fin'}\n",
      "\n",
      "Token: those\n",
      "Lema: those\n",
      "Lexema: those\n",
      "Morfemas: {'Number': 'Plur', 'PronType': 'Dem'}\n",
      "\n",
      "Token: who\n",
      "Lema: who\n",
      "Lexema: who\n",
      "Morfemas: {}\n",
      "\n",
      "Token: ’ve\n",
      "Lema: ’ve\n",
      "Lexema: ’ve\n",
      "Morfemas: {'Tense': 'Pres', 'VerbForm': 'Fin'}\n",
      "\n",
      "Token: been\n",
      "Lema: been\n",
      "Lexema: been\n",
      "Morfemas: {'Tense': 'Past', 'VerbForm': 'Fin'}\n",
      "\n",
      "Token: told\n",
      "Lema: tell\n",
      "Lexema: told\n",
      "Morfemas: {'Aspect': 'Perf', 'Tense': 'Past', 'VerbForm': 'Part'}\n",
      "\n",
      "Token: for\n",
      "Lema: for\n",
      "Lexema: for\n",
      "Morfemas: {}\n",
      "\n",
      "Token: so\n",
      "Lema: so\n",
      "Lexema: so\n",
      "Morfemas: {}\n",
      "\n",
      "Token: long\n",
      "Lema: long\n",
      "Lexema: long\n",
      "Morfemas: {}\n",
      "\n",
      "Token: by\n",
      "Lema: by\n",
      "Lexema: by\n",
      "Morfemas: {}\n",
      "\n",
      "Token: so\n",
      "Lema: so\n",
      "Lexema: so\n",
      "Morfemas: {}\n",
      "\n",
      "Token: many\n",
      "Lema: many\n",
      "Lexema: many\n",
      "Morfemas: {'Degree': 'Pos'}\n",
      "\n",
      "Token: to\n",
      "Lema: to\n",
      "Lexema: to\n",
      "Morfemas: {}\n",
      "\n",
      "Token: be\n",
      "Lema: be\n",
      "Lexema: be\n",
      "Morfemas: {'VerbForm': 'Inf'}\n",
      "\n",
      "Token: cynical\n",
      "Lema: cynical\n",
      "Lexema: cynical\n",
      "Morfemas: {'Degree': 'Pos'}\n",
      "\n",
      "Token: and\n",
      "Lema: and\n",
      "Lexema: and\n",
      "Morfemas: {'ConjType': 'Cmp'}\n",
      "\n",
      "Token: fearful\n",
      "Lema: fearful\n",
      "Lexema: fearful\n",
      "Morfemas: {'Degree': 'Pos'}\n",
      "\n",
      "Token: and\n",
      "Lema: and\n",
      "Lexema: and\n",
      "Morfemas: {'ConjType': 'Cmp'}\n",
      "\n",
      "Token: doubtful\n",
      "Lema: doubtful\n",
      "Lexema: doubtful\n",
      "Morfemas: {'Degree': 'Pos'}\n",
      "\n",
      "Token: about\n",
      "Lema: about\n",
      "Lexema: about\n",
      "Morfemas: {}\n",
      "\n",
      "Token: what\n",
      "Lema: what\n",
      "Lexema: what\n",
      "Morfemas: {}\n",
      "\n",
      "Token: we\n",
      "Lema: we\n",
      "Lexema: we\n",
      "Morfemas: {'Case': 'Nom', 'Number': 'Plur', 'Person': '1', 'PronType': 'Prs'}\n",
      "\n",
      "Token: can\n",
      "Lema: can\n",
      "Lexema: can\n",
      "Morfemas: {'VerbForm': 'Fin'}\n",
      "\n",
      "Token: achieve\n",
      "Lema: achieve\n",
      "Lexema: achieve\n",
      "Morfemas: {'VerbForm': 'Inf'}\n",
      "\n",
      "Token: to\n",
      "Lema: to\n",
      "Lexema: to\n",
      "Morfemas: {}\n",
      "\n",
      "Token: put\n",
      "Lema: put\n",
      "Lexema: put\n",
      "Morfemas: {'VerbForm': 'Inf'}\n",
      "\n",
      "Token: their\n",
      "Lema: their\n",
      "Lexema: their\n",
      "Morfemas: {'Number': 'Plur', 'Person': '3', 'Poss': 'Yes', 'PronType': 'Prs'}\n",
      "\n",
      "Token: hands\n",
      "Lema: hand\n",
      "Lexema: hands\n",
      "Morfemas: {'Number': 'Plur'}\n",
      "\n",
      "Token: on\n",
      "Lema: on\n",
      "Lexema: on\n",
      "Morfemas: {}\n",
      "\n",
      "Token: the\n",
      "Lema: the\n",
      "Lexema: the\n",
      "Morfemas: {'Definite': 'Def', 'PronType': 'Art'}\n",
      "\n",
      "Token: arc\n",
      "Lema: arc\n",
      "Lexema: arc\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: of\n",
      "Lema: of\n",
      "Lexema: of\n",
      "Morfemas: {}\n",
      "\n",
      "Token: history\n",
      "Lema: history\n",
      "Lexema: history\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: and\n",
      "Lema: and\n",
      "Lexema: and\n",
      "Morfemas: {'ConjType': 'Cmp'}\n",
      "\n",
      "Token: bend\n",
      "Lema: bend\n",
      "Lexema: bend\n",
      "Morfemas: {'VerbForm': 'Inf'}\n",
      "\n",
      "Token: it\n",
      "Lema: it\n",
      "Lexema: it\n",
      "Morfemas: {'Case': 'Acc', 'Gender': 'Neut', 'Number': 'Sing', 'Person': '3', 'PronType': 'Prs'}\n",
      "\n",
      "Token: once\n",
      "Lema: once\n",
      "Lexema: once\n",
      "Morfemas: {'NumType': 'Mult'}\n",
      "\n",
      "Token: more\n",
      "Lema: more\n",
      "Lexema: more\n",
      "Morfemas: {'Degree': 'Cmp'}\n",
      "\n",
      "Token: toward\n",
      "Lema: toward\n",
      "Lexema: toward\n",
      "Morfemas: {}\n",
      "\n",
      "Token: the\n",
      "Lema: the\n",
      "Lexema: the\n",
      "Morfemas: {'Definite': 'Def', 'PronType': 'Art'}\n",
      "\n",
      "Token: hope\n",
      "Lema: hope\n",
      "Lexema: hope\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: of\n",
      "Lema: of\n",
      "Lexema: of\n",
      "Morfemas: {}\n",
      "\n",
      "Token: a\n",
      "Lema: a\n",
      "Lexema: a\n",
      "Morfemas: {'Definite': 'Ind', 'PronType': 'Art'}\n",
      "\n",
      "Token: better\n",
      "Lema: well\n",
      "Lexema: better\n",
      "Morfemas: {'Degree': 'Cmp'}\n",
      "\n",
      "Token: day\n",
      "Lema: day\n",
      "Lexema: day\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: .\n",
      "Lema: .\n",
      "Lexema: .\n",
      "Morfemas: {'PunctType': 'Peri'}\n",
      "\n",
      "Token: \n",
      "\n",
      "Lema: \n",
      "\n",
      "Lexema: \n",
      "\n",
      "Morfemas: {}\n",
      "\n",
      "Token: It\n",
      "Lema: it\n",
      "Lexema: It\n",
      "Morfemas: {'Gender': 'Neut', 'Number': 'Sing', 'Person': '3', 'PronType': 'Prs'}\n",
      "\n",
      "Token: ’s\n",
      "Lema: ’s\n",
      "Lexema: ’s\n",
      "Morfemas: {'Number': 'Sing', 'Person': '3', 'Tense': 'Pres', 'VerbForm': 'Fin'}\n",
      "\n",
      "Token: been\n",
      "Lema: be\n",
      "Lexema: been\n",
      "Morfemas: {'Tense': 'Past', 'VerbForm': 'Part'}\n",
      "\n",
      "Token: a\n",
      "Lema: a\n",
      "Lexema: a\n",
      "Morfemas: {'Definite': 'Ind', 'PronType': 'Art'}\n",
      "\n",
      "Token: long\n",
      "Lema: long\n",
      "Lexema: long\n",
      "Morfemas: {'Degree': 'Pos'}\n",
      "\n",
      "Token: time\n",
      "Lema: time\n",
      "Lexema: time\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: coming\n",
      "Lema: come\n",
      "Lexema: coming\n",
      "Morfemas: {'Aspect': 'Prog', 'Tense': 'Pres', 'VerbForm': 'Part'}\n",
      "\n",
      "Token: ,\n",
      "Lema: ,\n",
      "Lexema: ,\n",
      "Morfemas: {'PunctType': 'Comm'}\n",
      "\n",
      "Token: but\n",
      "Lema: but\n",
      "Lexema: but\n",
      "Morfemas: {'ConjType': 'Cmp'}\n",
      "\n",
      "Token: tonight\n",
      "Lema: tonight\n",
      "Lexema: tonight\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: ,\n",
      "Lema: ,\n",
      "Lexema: ,\n",
      "Morfemas: {'PunctType': 'Comm'}\n",
      "\n",
      "Token: because\n",
      "Lema: because\n",
      "Lexema: because\n",
      "Morfemas: {}\n",
      "\n",
      "Token: of\n",
      "Lema: of\n",
      "Lexema: of\n",
      "Morfemas: {}\n",
      "\n",
      "Token: what\n",
      "Lema: what\n",
      "Lexema: what\n",
      "Morfemas: {}\n",
      "\n",
      "Token: we\n",
      "Lema: we\n",
      "Lexema: we\n",
      "Morfemas: {'Case': 'Nom', 'Number': 'Plur', 'Person': '1', 'PronType': 'Prs'}\n",
      "\n",
      "Token: did\n",
      "Lema: do\n",
      "Lexema: did\n",
      "Morfemas: {'Tense': 'Past', 'VerbForm': 'Fin'}\n",
      "\n",
      "Token: on\n",
      "Lema: on\n",
      "Lexema: on\n",
      "Morfemas: {}\n",
      "\n",
      "Token: this\n",
      "Lema: this\n",
      "Lexema: this\n",
      "Morfemas: {'Number': 'Sing', 'PronType': 'Dem'}\n",
      "\n",
      "Token: date\n",
      "Lema: date\n",
      "Lexema: date\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: in\n",
      "Lema: in\n",
      "Lexema: in\n",
      "Morfemas: {}\n",
      "\n",
      "Token: this\n",
      "Lema: this\n",
      "Lexema: this\n",
      "Morfemas: {'Number': 'Sing', 'PronType': 'Dem'}\n",
      "\n",
      "Token: election\n",
      "Lema: election\n",
      "Lexema: election\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: at\n",
      "Lema: at\n",
      "Lexema: at\n",
      "Morfemas: {}\n",
      "\n",
      "Token: this\n",
      "Lema: this\n",
      "Lexema: this\n",
      "Morfemas: {'Number': 'Sing', 'PronType': 'Dem'}\n",
      "\n",
      "Token: defining\n",
      "Lema: define\n",
      "Lexema: defining\n",
      "Morfemas: {'Aspect': 'Prog', 'Tense': 'Pres', 'VerbForm': 'Part'}\n",
      "\n",
      "Token: moment\n",
      "Lema: moment\n",
      "Lexema: moment\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: change\n",
      "Lema: change\n",
      "Lexema: change\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: has\n",
      "Lema: have\n",
      "Lexema: has\n",
      "Morfemas: {'Mood': 'Ind', 'Number': 'Sing', 'Person': '3', 'Tense': 'Pres', 'VerbForm': 'Fin'}\n",
      "\n",
      "Token: come\n",
      "Lema: come\n",
      "Lexema: come\n",
      "Morfemas: {'Aspect': 'Perf', 'Tense': 'Past', 'VerbForm': 'Part'}\n",
      "\n",
      "Token: to\n",
      "Lema: to\n",
      "Lexema: to\n",
      "Morfemas: {}\n",
      "\n",
      "Token: America\n",
      "Lema: America\n",
      "Lexema: America\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: .\n",
      "Lema: .\n",
      "Lexema: .\n",
      "Morfemas: {'PunctType': 'Peri'}\n",
      "\n",
      "Token: \n",
      "\n",
      "Lema: \n",
      "\n",
      "Lexema: \n",
      "\n",
      "Morfemas: {}\n",
      "\n",
      "Token: [\n",
      "Lema: [\n",
      "Lexema: [\n",
      "Morfemas: {'PunctSide': 'Ini', 'PunctType': 'Brck'}\n",
      "\n",
      "Token: read\n",
      "Lema: read\n",
      "Lexema: read\n",
      "Morfemas: {'VerbForm': 'Inf'}\n",
      "\n",
      "Token: more\n",
      "Lema: more\n",
      "Lexema: more\n",
      "Morfemas: {'Degree': 'Cmp'}\n",
      "\n",
      "Token: ]\n",
      "Lema: ]\n",
      "Lexema: ]\n",
      "Morfemas: {'PunctSide': 'Fin', 'PunctType': 'Brck'}\n",
      "\n",
      "Token: \n",
      "\n",
      "\n",
      "Lema: \n",
      "\n",
      "\n",
      "Lexema: \n",
      "\n",
      "\n",
      "Morfemas: {}\n",
      "\n",
      "Token: We\n",
      "Lema: we\n",
      "Lexema: We\n",
      "Morfemas: {'Case': 'Nom', 'Number': 'Plur', 'Person': '1', 'PronType': 'Prs'}\n",
      "\n",
      "Token: did\n",
      "Lema: do\n",
      "Lexema: did\n",
      "Morfemas: {'Tense': 'Past', 'VerbForm': 'Fin'}\n",
      "\n",
      "Token: n’t\n",
      "Lema: not\n",
      "Lexema: n’t\n",
      "Morfemas: {}\n",
      "\n",
      "Token: start\n",
      "Lema: start\n",
      "Lexema: start\n",
      "Morfemas: {'VerbForm': 'Inf'}\n",
      "\n",
      "Token: with\n",
      "Lema: with\n",
      "Lexema: with\n",
      "Morfemas: {}\n",
      "\n",
      "Token: much\n",
      "Lema: much\n",
      "Lexema: much\n",
      "Morfemas: {'Degree': 'Pos'}\n",
      "\n",
      "Token: money\n",
      "Lema: money\n",
      "Lexema: money\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: or\n",
      "Lema: or\n",
      "Lexema: or\n",
      "Morfemas: {'ConjType': 'Cmp'}\n",
      "\n",
      "Token: many\n",
      "Lema: many\n",
      "Lexema: many\n",
      "Morfemas: {'Degree': 'Pos'}\n",
      "\n",
      "Token: endorsements\n",
      "Lema: endorsement\n",
      "Lexema: endorsements\n",
      "Morfemas: {'Number': 'Plur'}\n",
      "\n",
      "Token: .\n",
      "Lema: .\n",
      "Lexema: .\n",
      "Morfemas: {'PunctType': 'Peri'}\n",
      "\n",
      "Token: Our\n",
      "Lema: our\n",
      "Lexema: Our\n",
      "Morfemas: {'Number': 'Plur', 'Person': '1', 'Poss': 'Yes', 'PronType': 'Prs'}\n",
      "\n",
      "Token: campaign\n",
      "Lema: campaign\n",
      "Lexema: campaign\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: was\n",
      "Lema: be\n",
      "Lexema: was\n",
      "Morfemas: {'Mood': 'Ind', 'Number': 'Sing', 'Person': '3', 'Tense': 'Past', 'VerbForm': 'Fin'}\n",
      "\n",
      "Token: not\n",
      "Lema: not\n",
      "Lexema: not\n",
      "Morfemas: {'Polarity': 'Neg'}\n",
      "\n",
      "Token: hatched\n",
      "Lema: hatch\n",
      "Lexema: hatched\n",
      "Morfemas: {'Aspect': 'Perf', 'Tense': 'Past', 'VerbForm': 'Part'}\n",
      "\n",
      "Token: in\n",
      "Lema: in\n",
      "Lexema: in\n",
      "Morfemas: {}\n",
      "\n",
      "Token: the\n",
      "Lema: the\n",
      "Lexema: the\n",
      "Morfemas: {'Definite': 'Def', 'PronType': 'Art'}\n",
      "\n",
      "Token: halls\n",
      "Lema: hall\n",
      "Lexema: halls\n",
      "Morfemas: {'Number': 'Plur'}\n",
      "\n",
      "Token: of\n",
      "Lema: of\n",
      "Lexema: of\n",
      "Morfemas: {}\n",
      "\n",
      "Token: Washington\n",
      "Lema: Washington\n",
      "Lexema: Washington\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: .\n",
      "Lema: .\n",
      "Lexema: .\n",
      "Morfemas: {'PunctType': 'Peri'}\n",
      "\n",
      "Token: It\n",
      "Lema: it\n",
      "Lexema: It\n",
      "Morfemas: {'Case': 'Nom', 'Gender': 'Neut', 'Number': 'Sing', 'Person': '3', 'PronType': 'Prs'}\n",
      "\n",
      "Token: began\n",
      "Lema: begin\n",
      "Lexema: began\n",
      "Morfemas: {'Tense': 'Past', 'VerbForm': 'Fin'}\n",
      "\n",
      "Token: in\n",
      "Lema: in\n",
      "Lexema: in\n",
      "Morfemas: {}\n",
      "\n",
      "Token: the\n",
      "Lema: the\n",
      "Lexema: the\n",
      "Morfemas: {'Definite': 'Def', 'PronType': 'Art'}\n",
      "\n",
      "Token: backyards\n",
      "Lema: backyard\n",
      "Lexema: backyards\n",
      "Morfemas: {'Number': 'Plur'}\n",
      "\n",
      "Token: of\n",
      "Lema: of\n",
      "Lexema: of\n",
      "Morfemas: {}\n",
      "\n",
      "Token: Des\n",
      "Lema: Des\n",
      "Lexema: Des\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: Moines\n",
      "Lema: Moines\n",
      "Lexema: Moines\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: and\n",
      "Lema: and\n",
      "Lexema: and\n",
      "Morfemas: {'ConjType': 'Cmp'}\n",
      "\n",
      "Token: the\n",
      "Lema: the\n",
      "Lexema: the\n",
      "Morfemas: {'Definite': 'Def', 'PronType': 'Art'}\n",
      "\n",
      "Token: living\n",
      "Lema: live\n",
      "Lexema: living\n",
      "Morfemas: {'Aspect': 'Prog', 'Tense': 'Pres', 'VerbForm': 'Part'}\n",
      "\n",
      "Token: rooms\n",
      "Lema: room\n",
      "Lexema: rooms\n",
      "Morfemas: {'Number': 'Plur'}\n",
      "\n",
      "Token: of\n",
      "Lema: of\n",
      "Lexema: of\n",
      "Morfemas: {}\n",
      "\n",
      "Token: Concord\n",
      "Lema: Concord\n",
      "Lexema: Concord\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: and\n",
      "Lema: and\n",
      "Lexema: and\n",
      "Morfemas: {'ConjType': 'Cmp'}\n",
      "\n",
      "Token: the\n",
      "Lema: the\n",
      "Lexema: the\n",
      "Morfemas: {'Definite': 'Def', 'PronType': 'Art'}\n",
      "\n",
      "Token: front\n",
      "Lema: front\n",
      "Lexema: front\n",
      "Morfemas: {'Degree': 'Pos'}\n",
      "\n",
      "Token: porches\n",
      "Lema: porch\n",
      "Lexema: porches\n",
      "Morfemas: {'Number': 'Plur'}\n",
      "\n",
      "Token: of\n",
      "Lema: of\n",
      "Lexema: of\n",
      "Morfemas: {}\n",
      "\n",
      "Token: Charleston\n",
      "Lema: Charleston\n",
      "Lexema: Charleston\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: .\n",
      "Lema: .\n",
      "Lexema: .\n",
      "Morfemas: {'PunctType': 'Peri'}\n",
      "\n",
      "Token: It\n",
      "Lema: it\n",
      "Lexema: It\n",
      "Morfemas: {'Gender': 'Neut', 'Number': 'Sing', 'Person': '3', 'PronType': 'Prs'}\n",
      "\n",
      "Token: was\n",
      "Lema: be\n",
      "Lexema: was\n",
      "Morfemas: {'Mood': 'Ind', 'Number': 'Sing', 'Person': '3', 'Tense': 'Past', 'VerbForm': 'Fin'}\n",
      "\n",
      "Token: built\n",
      "Lema: build\n",
      "Lexema: built\n",
      "Morfemas: {'Aspect': 'Perf', 'Tense': 'Past', 'VerbForm': 'Part'}\n",
      "\n",
      "Token: by\n",
      "Lema: by\n",
      "Lexema: by\n",
      "Morfemas: {}\n",
      "\n",
      "Token: working\n",
      "Lema: work\n",
      "Lexema: working\n",
      "Morfemas: {'Aspect': 'Prog', 'Tense': 'Pres', 'VerbForm': 'Part'}\n",
      "\n",
      "Token: men\n",
      "Lema: man\n",
      "Lexema: men\n",
      "Morfemas: {'Number': 'Plur'}\n",
      "\n",
      "Token: and\n",
      "Lema: and\n",
      "Lexema: and\n",
      "Morfemas: {'ConjType': 'Cmp'}\n",
      "\n",
      "Token: women\n",
      "Lema: woman\n",
      "Lexema: women\n",
      "Morfemas: {'Number': 'Plur'}\n",
      "\n",
      "Token: who\n",
      "Lema: who\n",
      "Lexema: who\n",
      "Morfemas: {}\n",
      "\n",
      "Token: dug\n",
      "Lema: dig\n",
      "Lexema: dug\n",
      "Morfemas: {'Tense': 'Past', 'VerbForm': 'Fin'}\n",
      "\n",
      "Token: into\n",
      "Lema: into\n",
      "Lexema: into\n",
      "Morfemas: {}\n",
      "\n",
      "Token: what\n",
      "Lema: what\n",
      "Lexema: what\n",
      "Morfemas: {}\n",
      "\n",
      "Token: little\n",
      "Lema: little\n",
      "Lexema: little\n",
      "Morfemas: {'Degree': 'Pos'}\n",
      "\n",
      "Token: savings\n",
      "Lema: saving\n",
      "Lexema: savings\n",
      "Morfemas: {'Number': 'Plur'}\n",
      "\n",
      "Token: they\n",
      "Lema: they\n",
      "Lexema: they\n",
      "Morfemas: {'Case': 'Nom', 'Number': 'Plur', 'Person': '3', 'PronType': 'Prs'}\n",
      "\n",
      "Token: had\n",
      "Lema: have\n",
      "Lexema: had\n",
      "Morfemas: {'Tense': 'Past', 'VerbForm': 'Fin'}\n",
      "\n",
      "Token: to\n",
      "Lema: to\n",
      "Lexema: to\n",
      "Morfemas: {}\n",
      "\n",
      "Token: give\n",
      "Lema: give\n",
      "Lexema: give\n",
      "Morfemas: {'VerbForm': 'Inf'}\n",
      "\n",
      "Token: $\n",
      "Lema: $\n",
      "Lexema: $\n",
      "Morfemas: {}\n",
      "\n",
      "Token: 5\n",
      "Lema: 5\n",
      "Lexema: 5\n",
      "Morfemas: {'NumType': 'Card'}\n",
      "\n",
      "Token: and\n",
      "Lema: and\n",
      "Lexema: and\n",
      "Morfemas: {'ConjType': 'Cmp'}\n",
      "\n",
      "Token: $\n",
      "Lema: $\n",
      "Lexema: $\n",
      "Morfemas: {}\n",
      "\n",
      "Token: 10\n",
      "Lema: 10\n",
      "Lexema: 10\n",
      "Morfemas: {'NumType': 'Card'}\n",
      "\n",
      "Token: and\n",
      "Lema: and\n",
      "Lexema: and\n",
      "Morfemas: {'ConjType': 'Cmp'}\n",
      "\n",
      "Token: $\n",
      "Lema: $\n",
      "Lexema: $\n",
      "Morfemas: {}\n",
      "\n",
      "Token: 20\n",
      "Lema: 20\n",
      "Lexema: 20\n",
      "Morfemas: {'NumType': 'Card'}\n",
      "\n",
      "Token: to\n",
      "Lema: to\n",
      "Lexema: to\n",
      "Morfemas: {}\n",
      "\n",
      "Token: the\n",
      "Lema: the\n",
      "Lexema: the\n",
      "Morfemas: {'Definite': 'Def', 'PronType': 'Art'}\n",
      "\n",
      "Token: cause\n",
      "Lema: cause\n",
      "Lexema: cause\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: .\n",
      "Lema: .\n",
      "Lexema: .\n",
      "Morfemas: {'PunctType': 'Peri'}\n",
      "\n",
      "Token: \n",
      "\n",
      "Lema: \n",
      "\n",
      "Lexema: \n",
      "\n",
      "Morfemas: {}\n",
      "\n",
      "Token: It\n",
      "Lema: it\n",
      "Lexema: It\n",
      "Morfemas: {'Case': 'Nom', 'Gender': 'Neut', 'Number': 'Sing', 'Person': '3', 'PronType': 'Prs'}\n",
      "\n",
      "Token: grew\n",
      "Lema: grow\n",
      "Lexema: grew\n",
      "Morfemas: {'Tense': 'Past', 'VerbForm': 'Fin'}\n",
      "\n",
      "Token: strength\n",
      "Lema: strength\n",
      "Lexema: strength\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: from\n",
      "Lema: from\n",
      "Lexema: from\n",
      "Morfemas: {}\n",
      "\n",
      "Token: the\n",
      "Lema: the\n",
      "Lexema: the\n",
      "Morfemas: {'Definite': 'Def', 'PronType': 'Art'}\n",
      "\n",
      "Token: young\n",
      "Lema: young\n",
      "Lexema: young\n",
      "Morfemas: {'Degree': 'Pos'}\n",
      "\n",
      "Token: people\n",
      "Lema: people\n",
      "Lexema: people\n",
      "Morfemas: {'Number': 'Plur'}\n",
      "\n",
      "Token: who\n",
      "Lema: who\n",
      "Lexema: who\n",
      "Morfemas: {}\n",
      "\n",
      "Token: rejected\n",
      "Lema: reject\n",
      "Lexema: rejected\n",
      "Morfemas: {'Tense': 'Past', 'VerbForm': 'Fin'}\n",
      "\n",
      "Token: the\n",
      "Lema: the\n",
      "Lexema: the\n",
      "Morfemas: {'Definite': 'Def', 'PronType': 'Art'}\n",
      "\n",
      "Token: myth\n",
      "Lema: myth\n",
      "Lexema: myth\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: of\n",
      "Lema: of\n",
      "Lexema: of\n",
      "Morfemas: {}\n",
      "\n",
      "Token: their\n",
      "Lema: their\n",
      "Lexema: their\n",
      "Morfemas: {'Number': 'Plur', 'Person': '3', 'Poss': 'Yes', 'PronType': 'Prs'}\n",
      "\n",
      "Token: generation\n",
      "Lema: generation\n",
      "Lexema: generation\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: ’s\n",
      "Lema: ’s\n",
      "Lexema: ’s\n",
      "Morfemas: {}\n",
      "\n",
      "Token: apathy\n",
      "Lema: apathy\n",
      "Lexema: apathy\n",
      "Morfemas: {'Degree': 'Pos'}\n",
      "\n",
      "Token: who\n",
      "Lema: who\n",
      "Lexema: who\n",
      "Morfemas: {}\n",
      "\n",
      "Token: left\n",
      "Lema: leave\n",
      "Lexema: left\n",
      "Morfemas: {'Tense': 'Past', 'VerbForm': 'Fin'}\n",
      "\n",
      "Token: their\n",
      "Lema: their\n",
      "Lexema: their\n",
      "Morfemas: {'Number': 'Plur', 'Person': '3', 'Poss': 'Yes', 'PronType': 'Prs'}\n",
      "\n",
      "Token: homes\n",
      "Lema: home\n",
      "Lexema: homes\n",
      "Morfemas: {'Number': 'Plur'}\n",
      "\n",
      "Token: and\n",
      "Lema: and\n",
      "Lexema: and\n",
      "Morfemas: {'ConjType': 'Cmp'}\n",
      "\n",
      "Token: their\n",
      "Lema: their\n",
      "Lexema: their\n",
      "Morfemas: {'Number': 'Plur', 'Person': '3', 'Poss': 'Yes', 'PronType': 'Prs'}\n",
      "\n",
      "Token: families\n",
      "Lema: family\n",
      "Lexema: families\n",
      "Morfemas: {'Number': 'Plur'}\n",
      "\n",
      "Token: for\n",
      "Lema: for\n",
      "Lexema: for\n",
      "Morfemas: {}\n",
      "\n",
      "Token: jobs\n",
      "Lema: job\n",
      "Lexema: jobs\n",
      "Morfemas: {'Number': 'Plur'}\n",
      "\n",
      "Token: that\n",
      "Lema: that\n",
      "Lexema: that\n",
      "Morfemas: {'PronType': 'Rel'}\n",
      "\n",
      "Token: offered\n",
      "Lema: offer\n",
      "Lexema: offered\n",
      "Morfemas: {'Tense': 'Past', 'VerbForm': 'Fin'}\n",
      "\n",
      "Token: little\n",
      "Lema: little\n",
      "Lexema: little\n",
      "Morfemas: {'Degree': 'Pos'}\n",
      "\n",
      "Token: pay\n",
      "Lema: pay\n",
      "Lexema: pay\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: and\n",
      "Lema: and\n",
      "Lexema: and\n",
      "Morfemas: {'ConjType': 'Cmp'}\n",
      "\n",
      "Token: less\n",
      "Lema: less\n",
      "Lexema: less\n",
      "Morfemas: {'Degree': 'Cmp'}\n",
      "\n",
      "Token: sleep\n",
      "Lema: sleep\n",
      "Lexema: sleep\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: .\n",
      "Lema: .\n",
      "Lexema: .\n",
      "Morfemas: {'PunctType': 'Peri'}\n",
      "\n",
      "Token: \n",
      "\n",
      "Lema: \n",
      "\n",
      "Lexema: \n",
      "\n",
      "Morfemas: {}\n",
      "\n",
      "Token: It\n",
      "Lema: it\n",
      "Lexema: It\n",
      "Morfemas: {'Case': 'Nom', 'Gender': 'Neut', 'Number': 'Sing', 'Person': '3', 'PronType': 'Prs'}\n",
      "\n",
      "Token: drew\n",
      "Lema: draw\n",
      "Lexema: drew\n",
      "Morfemas: {'Tense': 'Past', 'VerbForm': 'Fin'}\n",
      "\n",
      "Token: strength\n",
      "Lema: strength\n",
      "Lexema: strength\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: from\n",
      "Lema: from\n",
      "Lexema: from\n",
      "Morfemas: {}\n",
      "\n",
      "Token: the\n",
      "Lema: the\n",
      "Lexema: the\n",
      "Morfemas: {'Definite': 'Def', 'PronType': 'Art'}\n",
      "\n",
      "Token: not\n",
      "Lema: not\n",
      "Lexema: not\n",
      "Morfemas: {'Polarity': 'Neg'}\n",
      "\n",
      "Token: -\n",
      "Lema: -\n",
      "Lexema: -\n",
      "Morfemas: {'PunctType': 'Dash'}\n",
      "\n",
      "Token: so\n",
      "Lema: so\n",
      "Lexema: so\n",
      "Morfemas: {}\n",
      "\n",
      "Token: -\n",
      "Lema: -\n",
      "Lexema: -\n",
      "Morfemas: {'PunctType': 'Dash'}\n",
      "\n",
      "Token: young\n",
      "Lema: young\n",
      "Lexema: young\n",
      "Morfemas: {'Degree': 'Pos'}\n",
      "\n",
      "Token: people\n",
      "Lema: people\n",
      "Lexema: people\n",
      "Morfemas: {'Number': 'Plur'}\n",
      "\n",
      "Token: who\n",
      "Lema: who\n",
      "Lexema: who\n",
      "Morfemas: {}\n",
      "\n",
      "Token: braved\n",
      "Lema: brave\n",
      "Lexema: braved\n",
      "Morfemas: {'Tense': 'Past', 'VerbForm': 'Fin'}\n",
      "\n",
      "Token: the\n",
      "Lema: the\n",
      "Lexema: the\n",
      "Morfemas: {'Definite': 'Def', 'PronType': 'Art'}\n",
      "\n",
      "Token: bitter\n",
      "Lema: bitter\n",
      "Lexema: bitter\n",
      "Morfemas: {'Degree': 'Pos'}\n",
      "\n",
      "Token: cold\n",
      "Lema: cold\n",
      "Lexema: cold\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: and\n",
      "Lema: and\n",
      "Lexema: and\n",
      "Morfemas: {'ConjType': 'Cmp'}\n",
      "\n",
      "Token: scorching\n",
      "Lema: scorch\n",
      "Lexema: scorching\n",
      "Morfemas: {'Aspect': 'Prog', 'Tense': 'Pres', 'VerbForm': 'Part'}\n",
      "\n",
      "Token: heat\n",
      "Lema: heat\n",
      "Lexema: heat\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: to\n",
      "Lema: to\n",
      "Lexema: to\n",
      "Morfemas: {}\n",
      "\n",
      "Token: knock\n",
      "Lema: knock\n",
      "Lexema: knock\n",
      "Morfemas: {'VerbForm': 'Inf'}\n",
      "\n",
      "Token: on\n",
      "Lema: on\n",
      "Lexema: on\n",
      "Morfemas: {}\n",
      "\n",
      "Token: doors\n",
      "Lema: door\n",
      "Lexema: doors\n",
      "Morfemas: {'Number': 'Plur'}\n",
      "\n",
      "Token: of\n",
      "Lema: of\n",
      "Lexema: of\n",
      "Morfemas: {}\n",
      "\n",
      "Token: perfect\n",
      "Lema: perfect\n",
      "Lexema: perfect\n",
      "Morfemas: {'Degree': 'Pos'}\n",
      "\n",
      "Token: strangers\n",
      "Lema: stranger\n",
      "Lexema: strangers\n",
      "Morfemas: {'Number': 'Plur'}\n",
      "\n",
      "Token: ,\n",
      "Lema: ,\n",
      "Lexema: ,\n",
      "Morfemas: {'PunctType': 'Comm'}\n",
      "\n",
      "Token: and\n",
      "Lema: and\n",
      "Lexema: and\n",
      "Morfemas: {'ConjType': 'Cmp'}\n",
      "\n",
      "Token: from\n",
      "Lema: from\n",
      "Lexema: from\n",
      "Morfemas: {}\n",
      "\n",
      "Token: the\n",
      "Lema: the\n",
      "Lexema: the\n",
      "Morfemas: {'Definite': 'Def', 'PronType': 'Art'}\n",
      "\n",
      "Token: millions\n",
      "Lema: million\n",
      "Lexema: millions\n",
      "Morfemas: {'Number': 'Plur'}\n",
      "\n",
      "Token: of\n",
      "Lema: of\n",
      "Lexema: of\n",
      "Morfemas: {}\n",
      "\n",
      "Token: Americans\n",
      "Lema: Americans\n",
      "Lexema: Americans\n",
      "Morfemas: {'Number': 'Plur'}\n",
      "\n",
      "Token: who\n",
      "Lema: who\n",
      "Lexema: who\n",
      "Morfemas: {}\n",
      "\n",
      "Token: volunteered\n",
      "Lema: volunteer\n",
      "Lexema: volunteered\n",
      "Morfemas: {'Tense': 'Past', 'VerbForm': 'Fin'}\n",
      "\n",
      "Token: and\n",
      "Lema: and\n",
      "Lexema: and\n",
      "Morfemas: {'ConjType': 'Cmp'}\n",
      "\n",
      "Token: organized\n",
      "Lema: organize\n",
      "Lexema: organized\n",
      "Morfemas: {'Tense': 'Past', 'VerbForm': 'Fin'}\n",
      "\n",
      "Token: and\n",
      "Lema: and\n",
      "Lexema: and\n",
      "Morfemas: {'ConjType': 'Cmp'}\n",
      "\n",
      "Token: proved\n",
      "Lema: prove\n",
      "Lexema: proved\n",
      "Morfemas: {'Tense': 'Past', 'VerbForm': 'Fin'}\n",
      "\n",
      "Token: that\n",
      "Lema: that\n",
      "Lexema: that\n",
      "Morfemas: {}\n",
      "\n",
      "Token: more\n",
      "Lema: more\n",
      "Lexema: more\n",
      "Morfemas: {'Degree': 'Cmp'}\n",
      "\n",
      "Token: than\n",
      "Lema: than\n",
      "Lexema: than\n",
      "Morfemas: {}\n",
      "\n",
      "Token: two\n",
      "Lema: two\n",
      "Lexema: two\n",
      "Morfemas: {'NumType': 'Card'}\n",
      "\n",
      "Token: centuries\n",
      "Lema: century\n",
      "Lexema: centuries\n",
      "Morfemas: {'Number': 'Plur'}\n",
      "\n",
      "Token: later\n",
      "Lema: later\n",
      "Lexema: later\n",
      "Morfemas: {}\n",
      "\n",
      "Token: a\n",
      "Lema: a\n",
      "Lexema: a\n",
      "Morfemas: {'Definite': 'Ind', 'PronType': 'Art'}\n",
      "\n",
      "Token: government\n",
      "Lema: government\n",
      "Lexema: government\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: of\n",
      "Lema: of\n",
      "Lexema: of\n",
      "Morfemas: {}\n",
      "\n",
      "Token: the\n",
      "Lema: the\n",
      "Lexema: the\n",
      "Morfemas: {'Definite': 'Def', 'PronType': 'Art'}\n",
      "\n",
      "Token: people\n",
      "Lema: people\n",
      "Lexema: people\n",
      "Morfemas: {'Number': 'Plur'}\n",
      "\n",
      "Token: ,\n",
      "Lema: ,\n",
      "Lexema: ,\n",
      "Morfemas: {'PunctType': 'Comm'}\n",
      "\n",
      "Token: by\n",
      "Lema: by\n",
      "Lexema: by\n",
      "Morfemas: {}\n",
      "\n",
      "Token: the\n",
      "Lema: the\n",
      "Lexema: the\n",
      "Morfemas: {'Definite': 'Def', 'PronType': 'Art'}\n",
      "\n",
      "Token: people\n",
      "Lema: people\n",
      "Lexema: people\n",
      "Morfemas: {'Number': 'Plur'}\n",
      "\n",
      "Token: ,\n",
      "Lema: ,\n",
      "Lexema: ,\n",
      "Morfemas: {'PunctType': 'Comm'}\n",
      "\n",
      "Token: and\n",
      "Lema: and\n",
      "Lexema: and\n",
      "Morfemas: {'ConjType': 'Cmp'}\n",
      "\n",
      "Token: for\n",
      "Lema: for\n",
      "Lexema: for\n",
      "Morfemas: {}\n",
      "\n",
      "Token: the\n",
      "Lema: the\n",
      "Lexema: the\n",
      "Morfemas: {'Definite': 'Def', 'PronType': 'Art'}\n",
      "\n",
      "Token: people\n",
      "Lema: people\n",
      "Lexema: people\n",
      "Morfemas: {'Number': 'Plur'}\n",
      "\n",
      "Token: has\n",
      "Lema: have\n",
      "Lexema: has\n",
      "Morfemas: {'Mood': 'Ind', 'Number': 'Sing', 'Person': '3', 'Tense': 'Pres', 'VerbForm': 'Fin'}\n",
      "\n",
      "Token: not\n",
      "Lema: not\n",
      "Lexema: not\n",
      "Morfemas: {'Polarity': 'Neg'}\n",
      "\n",
      "Token: perished\n",
      "Lema: perish\n",
      "Lexema: perished\n",
      "Morfemas: {'Aspect': 'Perf', 'Tense': 'Past', 'VerbForm': 'Part'}\n",
      "\n",
      "Token: from\n",
      "Lema: from\n",
      "Lexema: from\n",
      "Morfemas: {}\n",
      "\n",
      "Token: the\n",
      "Lema: the\n",
      "Lexema: the\n",
      "Morfemas: {'Definite': 'Def', 'PronType': 'Art'}\n",
      "\n",
      "Token: Earth\n",
      "Lema: Earth\n",
      "Lexema: Earth\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: .\n",
      "Lema: .\n",
      "Lexema: .\n",
      "Morfemas: {'PunctType': 'Peri'}\n",
      "\n",
      "Token: \n",
      "\n",
      "Lema: \n",
      "\n",
      "Lexema: \n",
      "\n",
      "Morfemas: {}\n",
      "\n",
      "Token: This\n",
      "Lema: this\n",
      "Lexema: This\n",
      "Morfemas: {'Number': 'Sing', 'PronType': 'Dem'}\n",
      "\n",
      "Token: is\n",
      "Lema: be\n",
      "Lexema: is\n",
      "Morfemas: {'Mood': 'Ind', 'Number': 'Sing', 'Person': '3', 'Tense': 'Pres', 'VerbForm': 'Fin'}\n",
      "\n",
      "Token: your\n",
      "Lema: your\n",
      "Lexema: your\n",
      "Morfemas: {'Person': '2', 'Poss': 'Yes', 'PronType': 'Prs'}\n",
      "\n",
      "Token: victory\n",
      "Lema: victory\n",
      "Lexema: victory\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: .\n",
      "Lema: .\n",
      "Lexema: .\n",
      "Morfemas: {'PunctType': 'Peri'}\n",
      "\n",
      "Token: \n",
      "\n",
      "Lema: \n",
      "\n",
      "Lexema: \n",
      "\n",
      "Morfemas: {}\n",
      "\n",
      "Token: And\n",
      "Lema: and\n",
      "Lexema: And\n",
      "Morfemas: {'ConjType': 'Cmp'}\n",
      "\n",
      "Token: I\n",
      "Lema: I\n",
      "Lexema: I\n",
      "Morfemas: {'Case': 'Nom', 'Number': 'Sing', 'Person': '1', 'PronType': 'Prs'}\n",
      "\n",
      "Token: know\n",
      "Lema: know\n",
      "Lexema: know\n",
      "Morfemas: {'Tense': 'Pres', 'VerbForm': 'Fin'}\n",
      "\n",
      "Token: you\n",
      "Lema: you\n",
      "Lexema: you\n",
      "Morfemas: {'Case': 'Nom', 'Person': '2', 'PronType': 'Prs'}\n",
      "\n",
      "Token: did\n",
      "Lema: do\n",
      "Lexema: did\n",
      "Morfemas: {'Tense': 'Past', 'VerbForm': 'Fin'}\n",
      "\n",
      "Token: n’t\n",
      "Lema: not\n",
      "Lexema: n’t\n",
      "Morfemas: {}\n",
      "\n",
      "Token: do\n",
      "Lema: do\n",
      "Lexema: do\n",
      "Morfemas: {'VerbForm': 'Inf'}\n",
      "\n",
      "Token: this\n",
      "Lema: this\n",
      "Lexema: this\n",
      "Morfemas: {'Number': 'Sing', 'PronType': 'Dem'}\n",
      "\n",
      "Token: just\n",
      "Lema: just\n",
      "Lexema: just\n",
      "Morfemas: {}\n",
      "\n",
      "Token: to\n",
      "Lema: to\n",
      "Lexema: to\n",
      "Morfemas: {}\n",
      "\n",
      "Token: win\n",
      "Lema: win\n",
      "Lexema: win\n",
      "Morfemas: {'VerbForm': 'Inf'}\n",
      "\n",
      "Token: an\n",
      "Lema: an\n",
      "Lexema: an\n",
      "Morfemas: {'Definite': 'Ind', 'PronType': 'Art'}\n",
      "\n",
      "Token: election\n",
      "Lema: election\n",
      "Lexema: election\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: .\n",
      "Lema: .\n",
      "Lexema: .\n",
      "Morfemas: {'PunctType': 'Peri'}\n",
      "\n",
      "Token: And\n",
      "Lema: and\n",
      "Lexema: And\n",
      "Morfemas: {'ConjType': 'Cmp'}\n",
      "\n",
      "Token: I\n",
      "Lema: I\n",
      "Lexema: I\n",
      "Morfemas: {'Case': 'Nom', 'Number': 'Sing', 'Person': '1', 'PronType': 'Prs'}\n",
      "\n",
      "Token: know\n",
      "Lema: know\n",
      "Lexema: know\n",
      "Morfemas: {'Tense': 'Pres', 'VerbForm': 'Fin'}\n",
      "\n",
      "Token: you\n",
      "Lema: you\n",
      "Lexema: you\n",
      "Morfemas: {'Case': 'Nom', 'Person': '2', 'PronType': 'Prs'}\n",
      "\n",
      "Token: did\n",
      "Lema: do\n",
      "Lexema: did\n",
      "Morfemas: {'Tense': 'Past', 'VerbForm': 'Fin'}\n",
      "\n",
      "Token: n’t\n",
      "Lema: not\n",
      "Lexema: n’t\n",
      "Morfemas: {}\n",
      "\n",
      "Token: do\n",
      "Lema: do\n",
      "Lexema: do\n",
      "Morfemas: {'VerbForm': 'Inf'}\n",
      "\n",
      "Token: it\n",
      "Lema: it\n",
      "Lexema: it\n",
      "Morfemas: {'Case': 'Acc', 'Gender': 'Neut', 'Number': 'Sing', 'Person': '3', 'PronType': 'Prs'}\n",
      "\n",
      "Token: for\n",
      "Lema: for\n",
      "Lexema: for\n",
      "Morfemas: {}\n",
      "\n",
      "Token: me\n",
      "Lema: I\n",
      "Lexema: me\n",
      "Morfemas: {'Case': 'Acc', 'Number': 'Sing', 'Person': '1', 'PronType': 'Prs'}\n",
      "\n",
      "Token: .\n",
      "Lema: .\n",
      "Lexema: .\n",
      "Morfemas: {'PunctType': 'Peri'}\n",
      "\n",
      "Token: \n",
      "\n",
      "Lema: \n",
      "\n",
      "Lexema: \n",
      "\n",
      "Morfemas: {}\n",
      "\n",
      "Token: You\n",
      "Lema: you\n",
      "Lexema: You\n",
      "Morfemas: {'Case': 'Nom', 'Person': '2', 'PronType': 'Prs'}\n",
      "\n",
      "Token: did\n",
      "Lema: do\n",
      "Lexema: did\n",
      "Morfemas: {'Tense': 'Past', 'VerbForm': 'Fin'}\n",
      "\n",
      "Token: it\n",
      "Lema: it\n",
      "Lexema: it\n",
      "Morfemas: {'Case': 'Acc', 'Gender': 'Neut', 'Number': 'Sing', 'Person': '3', 'PronType': 'Prs'}\n",
      "\n",
      "Token: because\n",
      "Lema: because\n",
      "Lexema: because\n",
      "Morfemas: {}\n",
      "\n",
      "Token: you\n",
      "Lema: you\n",
      "Lexema: you\n",
      "Morfemas: {'Case': 'Nom', 'Person': '2', 'PronType': 'Prs'}\n",
      "\n",
      "Token: understand\n",
      "Lema: understand\n",
      "Lexema: understand\n",
      "Morfemas: {'Tense': 'Pres', 'VerbForm': 'Fin'}\n",
      "\n",
      "Token: the\n",
      "Lema: the\n",
      "Lexema: the\n",
      "Morfemas: {'Definite': 'Def', 'PronType': 'Art'}\n",
      "\n",
      "Token: enormity\n",
      "Lema: enormity\n",
      "Lexema: enormity\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: of\n",
      "Lema: of\n",
      "Lexema: of\n",
      "Morfemas: {}\n",
      "\n",
      "Token: the\n",
      "Lema: the\n",
      "Lexema: the\n",
      "Morfemas: {'Definite': 'Def', 'PronType': 'Art'}\n",
      "\n",
      "Token: task\n",
      "Lema: task\n",
      "Lexema: task\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: that\n",
      "Lema: that\n",
      "Lexema: that\n",
      "Morfemas: {'PronType': 'Rel'}\n",
      "\n",
      "Token: lies\n",
      "Lema: lie\n",
      "Lexema: lies\n",
      "Morfemas: {'Number': 'Sing', 'Person': '3', 'Tense': 'Pres', 'VerbForm': 'Fin'}\n",
      "\n",
      "Token: ahead\n",
      "Lema: ahead\n",
      "Lexema: ahead\n",
      "Morfemas: {}\n",
      "\n",
      "Token: .\n",
      "Lema: .\n",
      "Lexema: .\n",
      "Morfemas: {'PunctType': 'Peri'}\n",
      "\n",
      "Token: For\n",
      "Lema: for\n",
      "Lexema: For\n",
      "Morfemas: {}\n",
      "\n",
      "Token: even\n",
      "Lema: even\n",
      "Lexema: even\n",
      "Morfemas: {}\n",
      "\n",
      "Token: as\n",
      "Lema: as\n",
      "Lexema: as\n",
      "Morfemas: {}\n",
      "\n",
      "Token: we\n",
      "Lema: we\n",
      "Lexema: we\n",
      "Morfemas: {'Case': 'Nom', 'Number': 'Plur', 'Person': '1', 'PronType': 'Prs'}\n",
      "\n",
      "Token: celebrate\n",
      "Lema: celebrate\n",
      "Lexema: celebrate\n",
      "Morfemas: {'Tense': 'Pres', 'VerbForm': 'Fin'}\n",
      "\n",
      "Token: tonight\n",
      "Lema: tonight\n",
      "Lexema: tonight\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: ,\n",
      "Lema: ,\n",
      "Lexema: ,\n",
      "Morfemas: {'PunctType': 'Comm'}\n",
      "\n",
      "Token: we\n",
      "Lema: we\n",
      "Lexema: we\n",
      "Morfemas: {'Case': 'Nom', 'Number': 'Plur', 'Person': '1', 'PronType': 'Prs'}\n",
      "\n",
      "Token: know\n",
      "Lema: know\n",
      "Lexema: know\n",
      "Morfemas: {'Tense': 'Pres', 'VerbForm': 'Fin'}\n",
      "\n",
      "Token: the\n",
      "Lema: the\n",
      "Lexema: the\n",
      "Morfemas: {'Definite': 'Def', 'PronType': 'Art'}\n",
      "\n",
      "Token: challenges\n",
      "Lema: challenge\n",
      "Lexema: challenges\n",
      "Morfemas: {'Number': 'Plur'}\n",
      "\n",
      "Token: that\n",
      "Lema: that\n",
      "Lexema: that\n",
      "Morfemas: {'PronType': 'Rel'}\n",
      "\n",
      "Token: tomorrow\n",
      "Lema: tomorrow\n",
      "Lexema: tomorrow\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: will\n",
      "Lema: will\n",
      "Lexema: will\n",
      "Morfemas: {'VerbForm': 'Fin'}\n",
      "\n",
      "Token: bring\n",
      "Lema: bring\n",
      "Lexema: bring\n",
      "Morfemas: {'VerbForm': 'Inf'}\n",
      "\n",
      "Token: are\n",
      "Lema: be\n",
      "Lexema: are\n",
      "Morfemas: {'Mood': 'Ind', 'Tense': 'Pres', 'VerbForm': 'Fin'}\n",
      "\n",
      "Token: the\n",
      "Lema: the\n",
      "Lexema: the\n",
      "Morfemas: {'Definite': 'Def', 'PronType': 'Art'}\n",
      "\n",
      "Token: greatest\n",
      "Lema: great\n",
      "Lexema: greatest\n",
      "Morfemas: {'Degree': 'Sup'}\n",
      "\n",
      "Token: of\n",
      "Lema: of\n",
      "Lexema: of\n",
      "Morfemas: {}\n",
      "\n",
      "Token: our\n",
      "Lema: our\n",
      "Lexema: our\n",
      "Morfemas: {'Number': 'Plur', 'Person': '1', 'Poss': 'Yes', 'PronType': 'Prs'}\n",
      "\n",
      "Token: lifetime\n",
      "Lema: lifetime\n",
      "Lexema: lifetime\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: —\n",
      "Lema: —\n",
      "Lexema: —\n",
      "Morfemas: {}\n",
      "\n",
      "Token: two\n",
      "Lema: two\n",
      "Lexema: two\n",
      "Morfemas: {'NumType': 'Card'}\n",
      "\n",
      "Token: wars\n",
      "Lema: war\n",
      "Lexema: wars\n",
      "Morfemas: {'Number': 'Plur'}\n",
      "\n",
      "Token: ,\n",
      "Lema: ,\n",
      "Lexema: ,\n",
      "Morfemas: {'PunctType': 'Comm'}\n",
      "\n",
      "Token: a\n",
      "Lema: a\n",
      "Lexema: a\n",
      "Morfemas: {'Definite': 'Ind', 'PronType': 'Art'}\n",
      "\n",
      "Token: planet\n",
      "Lema: planet\n",
      "Lexema: planet\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: in\n",
      "Lema: in\n",
      "Lexema: in\n",
      "Morfemas: {}\n",
      "\n",
      "Token: peril\n",
      "Lema: peril\n",
      "Lexema: peril\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: ,\n",
      "Lema: ,\n",
      "Lexema: ,\n",
      "Morfemas: {'PunctType': 'Comm'}\n",
      "\n",
      "Token: the\n",
      "Lema: the\n",
      "Lexema: the\n",
      "Morfemas: {'Definite': 'Def', 'PronType': 'Art'}\n",
      "\n",
      "Token: worst\n",
      "Lema: bad\n",
      "Lexema: worst\n",
      "Morfemas: {'Degree': 'Sup'}\n",
      "\n",
      "Token: financial\n",
      "Lema: financial\n",
      "Lexema: financial\n",
      "Morfemas: {'Degree': 'Pos'}\n",
      "\n",
      "Token: crisis\n",
      "Lema: crisis\n",
      "Lexema: crisis\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: in\n",
      "Lema: in\n",
      "Lexema: in\n",
      "Morfemas: {}\n",
      "\n",
      "Token: a\n",
      "Lema: a\n",
      "Lexema: a\n",
      "Morfemas: {'Definite': 'Ind', 'PronType': 'Art'}\n",
      "\n",
      "Token: century\n",
      "Lema: century\n",
      "Lexema: century\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: .\n",
      "Lema: .\n",
      "Lexema: .\n",
      "Morfemas: {'PunctType': 'Peri'}\n",
      "\n",
      "Token: \n",
      "\n",
      "Lema: \n",
      "\n",
      "Lexema: \n",
      "\n",
      "Morfemas: {}\n",
      "\n",
      "Token: Even\n",
      "Lema: even\n",
      "Lexema: Even\n",
      "Morfemas: {}\n",
      "\n",
      "Token: as\n",
      "Lema: as\n",
      "Lexema: as\n",
      "Morfemas: {}\n",
      "\n",
      "Token: we\n",
      "Lema: we\n",
      "Lexema: we\n",
      "Morfemas: {'Case': 'Nom', 'Number': 'Plur', 'Person': '1', 'PronType': 'Prs'}\n",
      "\n",
      "Token: stand\n",
      "Lema: stand\n",
      "Lexema: stand\n",
      "Morfemas: {'Tense': 'Pres', 'VerbForm': 'Fin'}\n",
      "\n",
      "Token: here\n",
      "Lema: here\n",
      "Lexema: here\n",
      "Morfemas: {'PronType': 'Dem'}\n",
      "\n",
      "Token: tonight\n",
      "Lema: tonight\n",
      "Lexema: tonight\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: ,\n",
      "Lema: ,\n",
      "Lexema: ,\n",
      "Morfemas: {'PunctType': 'Comm'}\n",
      "\n",
      "Token: we\n",
      "Lema: we\n",
      "Lexema: we\n",
      "Morfemas: {'Case': 'Nom', 'Number': 'Plur', 'Person': '1', 'PronType': 'Prs'}\n",
      "\n",
      "Token: know\n",
      "Lema: know\n",
      "Lexema: know\n",
      "Morfemas: {'Tense': 'Pres', 'VerbForm': 'Fin'}\n",
      "\n",
      "Token: there\n",
      "Lema: there\n",
      "Lexema: there\n",
      "Morfemas: {}\n",
      "\n",
      "Token: are\n",
      "Lema: be\n",
      "Lexema: are\n",
      "Morfemas: {'Mood': 'Ind', 'Tense': 'Pres', 'VerbForm': 'Fin'}\n",
      "\n",
      "Token: brave\n",
      "Lema: brave\n",
      "Lexema: brave\n",
      "Morfemas: {'Degree': 'Pos'}\n",
      "\n",
      "Token: Americans\n",
      "Lema: Americans\n",
      "Lexema: Americans\n",
      "Morfemas: {'Number': 'Plur'}\n",
      "\n",
      "Token: waking\n",
      "Lema: wake\n",
      "Lexema: waking\n",
      "Morfemas: {'Aspect': 'Prog', 'Tense': 'Pres', 'VerbForm': 'Part'}\n",
      "\n",
      "Token: up\n",
      "Lema: up\n",
      "Lexema: up\n",
      "Morfemas: {}\n",
      "\n",
      "Token: in\n",
      "Lema: in\n",
      "Lexema: in\n",
      "Morfemas: {}\n",
      "\n",
      "Token: the\n",
      "Lema: the\n",
      "Lexema: the\n",
      "Morfemas: {'Definite': 'Def', 'PronType': 'Art'}\n",
      "\n",
      "Token: deserts\n",
      "Lema: desert\n",
      "Lexema: deserts\n",
      "Morfemas: {'Number': 'Plur'}\n",
      "\n",
      "Token: of\n",
      "Lema: of\n",
      "Lexema: of\n",
      "Morfemas: {}\n",
      "\n",
      "Token: Iraq\n",
      "Lema: Iraq\n",
      "Lexema: Iraq\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: and\n",
      "Lema: and\n",
      "Lexema: and\n",
      "Morfemas: {'ConjType': 'Cmp'}\n",
      "\n",
      "Token: the\n",
      "Lema: the\n",
      "Lexema: the\n",
      "Morfemas: {'Definite': 'Def', 'PronType': 'Art'}\n",
      "\n",
      "Token: mountains\n",
      "Lema: mountain\n",
      "Lexema: mountains\n",
      "Morfemas: {'Number': 'Plur'}\n",
      "\n",
      "Token: of\n",
      "Lema: of\n",
      "Lexema: of\n",
      "Morfemas: {}\n",
      "\n",
      "Token: Afghanistan\n",
      "Lema: Afghanistan\n",
      "Lexema: Afghanistan\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: to\n",
      "Lema: to\n",
      "Lexema: to\n",
      "Morfemas: {}\n",
      "\n",
      "Token: risk\n",
      "Lema: risk\n",
      "Lexema: risk\n",
      "Morfemas: {'VerbForm': 'Inf'}\n",
      "\n",
      "Token: their\n",
      "Lema: their\n",
      "Lexema: their\n",
      "Morfemas: {'Number': 'Plur', 'Person': '3', 'Poss': 'Yes', 'PronType': 'Prs'}\n",
      "\n",
      "Token: lives\n",
      "Lema: life\n",
      "Lexema: lives\n",
      "Morfemas: {'Number': 'Plur'}\n",
      "\n",
      "Token: for\n",
      "Lema: for\n",
      "Lexema: for\n",
      "Morfemas: {}\n",
      "\n",
      "Token: us\n",
      "Lema: we\n",
      "Lexema: us\n",
      "Morfemas: {'Case': 'Acc', 'Number': 'Plur', 'Person': '1', 'PronType': 'Prs'}\n",
      "\n",
      "Token: .\n",
      "Lema: .\n",
      "Lexema: .\n",
      "Morfemas: {'PunctType': 'Peri'}\n",
      "\n",
      "Token: \n",
      "\n",
      "Lema: \n",
      "\n",
      "Lexema: \n",
      "\n",
      "Morfemas: {}\n",
      "\n",
      "Token: There\n",
      "Lema: there\n",
      "Lexema: There\n",
      "Morfemas: {}\n",
      "\n",
      "Token: are\n",
      "Lema: be\n",
      "Lexema: are\n",
      "Morfemas: {'Mood': 'Ind', 'Tense': 'Pres', 'VerbForm': 'Fin'}\n",
      "\n",
      "Token: mothers\n",
      "Lema: mother\n",
      "Lexema: mothers\n",
      "Morfemas: {'Number': 'Plur'}\n",
      "\n",
      "Token: and\n",
      "Lema: and\n",
      "Lexema: and\n",
      "Morfemas: {'ConjType': 'Cmp'}\n",
      "\n",
      "Token: fathers\n",
      "Lema: father\n",
      "Lexema: fathers\n",
      "Morfemas: {'Number': 'Plur'}\n",
      "\n",
      "Token: who\n",
      "Lema: who\n",
      "Lexema: who\n",
      "Morfemas: {}\n",
      "\n",
      "Token: will\n",
      "Lema: will\n",
      "Lexema: will\n",
      "Morfemas: {'VerbForm': 'Fin'}\n",
      "\n",
      "Token: lie\n",
      "Lema: lie\n",
      "Lexema: lie\n",
      "Morfemas: {'VerbForm': 'Inf'}\n",
      "\n",
      "Token: awake\n",
      "Lema: awake\n",
      "Lexema: awake\n",
      "Morfemas: {'Degree': 'Pos'}\n",
      "\n",
      "Token: after\n",
      "Lema: after\n",
      "Lexema: after\n",
      "Morfemas: {}\n",
      "\n",
      "Token: the\n",
      "Lema: the\n",
      "Lexema: the\n",
      "Morfemas: {'Definite': 'Def', 'PronType': 'Art'}\n",
      "\n",
      "Token: children\n",
      "Lema: child\n",
      "Lexema: children\n",
      "Morfemas: {'Number': 'Plur'}\n",
      "\n",
      "Token: fall\n",
      "Lema: fall\n",
      "Lexema: fall\n",
      "Morfemas: {'Tense': 'Pres', 'VerbForm': 'Fin'}\n",
      "\n",
      "Token: asleep\n",
      "Lema: asleep\n",
      "Lexema: asleep\n",
      "Morfemas: {'Degree': 'Pos'}\n",
      "\n",
      "Token: and\n",
      "Lema: and\n",
      "Lexema: and\n",
      "Morfemas: {'ConjType': 'Cmp'}\n",
      "\n",
      "Token: wonder\n",
      "Lema: wonder\n",
      "Lexema: wonder\n",
      "Morfemas: {'Tense': 'Pres', 'VerbForm': 'Fin'}\n",
      "\n",
      "Token: how\n",
      "Lema: how\n",
      "Lexema: how\n",
      "Morfemas: {}\n",
      "\n",
      "Token: they\n",
      "Lema: they\n",
      "Lexema: they\n",
      "Morfemas: {'Case': 'Nom', 'Number': 'Plur', 'Person': '3', 'PronType': 'Prs'}\n",
      "\n",
      "Token: ’ll\n",
      "Lema: ’ll\n",
      "Lexema: ’ll\n",
      "Morfemas: {'VerbType': 'Mod'}\n",
      "\n",
      "Token: make\n",
      "Lema: make\n",
      "Lexema: make\n",
      "Morfemas: {'VerbForm': 'Inf'}\n",
      "\n",
      "Token: the\n",
      "Lema: the\n",
      "Lexema: the\n",
      "Morfemas: {'Definite': 'Def', 'PronType': 'Art'}\n",
      "\n",
      "Token: mortgage\n",
      "Lema: mortgage\n",
      "Lexema: mortgage\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: or\n",
      "Lema: or\n",
      "Lexema: or\n",
      "Morfemas: {'ConjType': 'Cmp'}\n",
      "\n",
      "Token: pay\n",
      "Lema: pay\n",
      "Lexema: pay\n",
      "Morfemas: {'VerbForm': 'Inf'}\n",
      "\n",
      "Token: their\n",
      "Lema: their\n",
      "Lexema: their\n",
      "Morfemas: {'Number': 'Plur', 'Person': '3', 'Poss': 'Yes', 'PronType': 'Prs'}\n",
      "\n",
      "Token: doctors\n",
      "Lema: doctor\n",
      "Lexema: doctors\n",
      "Morfemas: {'Number': 'Plur'}\n",
      "\n",
      "Token: ’\n",
      "Lema: ’\n",
      "Lexema: ’\n",
      "Morfemas: {}\n",
      "\n",
      "Token: bills\n",
      "Lema: bill\n",
      "Lexema: bills\n",
      "Morfemas: {'Number': 'Plur'}\n",
      "\n",
      "Token: or\n",
      "Lema: or\n",
      "Lexema: or\n",
      "Morfemas: {'ConjType': 'Cmp'}\n",
      "\n",
      "Token: save\n",
      "Lema: save\n",
      "Lexema: save\n",
      "Morfemas: {'VerbForm': 'Inf'}\n",
      "\n",
      "Token: enough\n",
      "Lema: enough\n",
      "Lexema: enough\n",
      "Morfemas: {'Degree': 'Pos'}\n",
      "\n",
      "Token: for\n",
      "Lema: for\n",
      "Lexema: for\n",
      "Morfemas: {}\n",
      "\n",
      "Token: their\n",
      "Lema: their\n",
      "Lexema: their\n",
      "Morfemas: {'Number': 'Plur', 'Person': '3', 'Poss': 'Yes', 'PronType': 'Prs'}\n",
      "\n",
      "Token: child\n",
      "Lema: child\n",
      "Lexema: child\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: ’s\n",
      "Lema: ’s\n",
      "Lexema: ’s\n",
      "Morfemas: {}\n",
      "\n",
      "Token: college\n",
      "Lema: college\n",
      "Lexema: college\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: education\n",
      "Lema: education\n",
      "Lexema: education\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: .\n",
      "Lema: .\n",
      "Lexema: .\n",
      "Morfemas: {'PunctType': 'Peri'}\n",
      "\n",
      "Token: \n",
      "\n",
      "Lema: \n",
      "\n",
      "Lexema: \n",
      "\n",
      "Morfemas: {}\n",
      "\n",
      "Token: There\n",
      "Lema: there\n",
      "Lexema: There\n",
      "Morfemas: {}\n",
      "\n",
      "Token: ’s\n",
      "Lema: ’\n",
      "Lexema: ’s\n",
      "Morfemas: {'Number': 'Sing', 'Person': '3', 'Tense': 'Pres', 'VerbForm': 'Fin'}\n",
      "\n",
      "Token: new\n",
      "Lema: new\n",
      "Lexema: new\n",
      "Morfemas: {'Degree': 'Pos'}\n",
      "\n",
      "Token: energy\n",
      "Lema: energy\n",
      "Lexema: energy\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: to\n",
      "Lema: to\n",
      "Lexema: to\n",
      "Morfemas: {}\n",
      "\n",
      "Token: harness\n",
      "Lema: harness\n",
      "Lexema: harness\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: ,\n",
      "Lema: ,\n",
      "Lexema: ,\n",
      "Morfemas: {'PunctType': 'Comm'}\n",
      "\n",
      "Token: new\n",
      "Lema: new\n",
      "Lexema: new\n",
      "Morfemas: {'Degree': 'Pos'}\n",
      "\n",
      "Token: jobs\n",
      "Lema: job\n",
      "Lexema: jobs\n",
      "Morfemas: {'Number': 'Plur'}\n",
      "\n",
      "Token: to\n",
      "Lema: to\n",
      "Lexema: to\n",
      "Morfemas: {}\n",
      "\n",
      "Token: be\n",
      "Lema: be\n",
      "Lexema: be\n",
      "Morfemas: {'VerbForm': 'Inf'}\n",
      "\n",
      "Token: created\n",
      "Lema: create\n",
      "Lexema: created\n",
      "Morfemas: {'Aspect': 'Perf', 'Tense': 'Past', 'VerbForm': 'Part'}\n",
      "\n",
      "Token: ,\n",
      "Lema: ,\n",
      "Lexema: ,\n",
      "Morfemas: {'PunctType': 'Comm'}\n",
      "\n",
      "Token: new\n",
      "Lema: new\n",
      "Lexema: new\n",
      "Morfemas: {'Degree': 'Pos'}\n",
      "\n",
      "Token: schools\n",
      "Lema: school\n",
      "Lexema: schools\n",
      "Morfemas: {'Number': 'Plur'}\n",
      "\n",
      "Token: to\n",
      "Lema: to\n",
      "Lexema: to\n",
      "Morfemas: {}\n",
      "\n",
      "Token: build\n",
      "Lema: build\n",
      "Lexema: build\n",
      "Morfemas: {'VerbForm': 'Inf'}\n",
      "\n",
      "Token: ,\n",
      "Lema: ,\n",
      "Lexema: ,\n",
      "Morfemas: {'PunctType': 'Comm'}\n",
      "\n",
      "Token: and\n",
      "Lema: and\n",
      "Lexema: and\n",
      "Morfemas: {'ConjType': 'Cmp'}\n",
      "\n",
      "Token: threats\n",
      "Lema: threat\n",
      "Lexema: threats\n",
      "Morfemas: {'Number': 'Plur'}\n",
      "\n",
      "Token: to\n",
      "Lema: to\n",
      "Lexema: to\n",
      "Morfemas: {}\n",
      "\n",
      "Token: meet\n",
      "Lema: meet\n",
      "Lexema: meet\n",
      "Morfemas: {'VerbForm': 'Inf'}\n",
      "\n",
      "Token: ,\n",
      "Lema: ,\n",
      "Lexema: ,\n",
      "Morfemas: {'PunctType': 'Comm'}\n",
      "\n",
      "Token: alliances\n",
      "Lema: alliance\n",
      "Lexema: alliances\n",
      "Morfemas: {'Number': 'Plur'}\n",
      "\n",
      "Token: to\n",
      "Lema: to\n",
      "Lexema: to\n",
      "Morfemas: {}\n",
      "\n",
      "Token: repair\n",
      "Lema: repair\n",
      "Lexema: repair\n",
      "Morfemas: {'VerbForm': 'Inf'}\n",
      "\n",
      "Token: .\n",
      "Lema: .\n",
      "Lexema: .\n",
      "Morfemas: {'PunctType': 'Peri'}\n",
      "\n",
      "Token: \n",
      "\n",
      "Lema: \n",
      "\n",
      "Lexema: \n",
      "\n",
      "Morfemas: {}\n",
      "\n",
      "Token: The\n",
      "Lema: the\n",
      "Lexema: The\n",
      "Morfemas: {'Definite': 'Def', 'PronType': 'Art'}\n",
      "\n",
      "Token: road\n",
      "Lema: road\n",
      "Lexema: road\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: ahead\n",
      "Lema: ahead\n",
      "Lexema: ahead\n",
      "Morfemas: {}\n",
      "\n",
      "Token: will\n",
      "Lema: will\n",
      "Lexema: will\n",
      "Morfemas: {'VerbForm': 'Fin'}\n",
      "\n",
      "Token: be\n",
      "Lema: be\n",
      "Lexema: be\n",
      "Morfemas: {'VerbForm': 'Inf'}\n",
      "\n",
      "Token: long\n",
      "Lema: long\n",
      "Lexema: long\n",
      "Morfemas: {'Degree': 'Pos'}\n",
      "\n",
      "Token: .\n",
      "Lema: .\n",
      "Lexema: .\n",
      "Morfemas: {'PunctType': 'Peri'}\n",
      "\n",
      "Token: Our\n",
      "Lema: our\n",
      "Lexema: Our\n",
      "Morfemas: {'Number': 'Plur', 'Person': '1', 'Poss': 'Yes', 'PronType': 'Prs'}\n",
      "\n",
      "Token: climb\n",
      "Lema: climb\n",
      "Lexema: climb\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: will\n",
      "Lema: will\n",
      "Lexema: will\n",
      "Morfemas: {'VerbForm': 'Fin'}\n",
      "\n",
      "Token: be\n",
      "Lema: be\n",
      "Lexema: be\n",
      "Morfemas: {'VerbForm': 'Inf'}\n",
      "\n",
      "Token: steep\n",
      "Lema: steep\n",
      "Lexema: steep\n",
      "Morfemas: {'Degree': 'Pos'}\n",
      "\n",
      "Token: .\n",
      "Lema: .\n",
      "Lexema: .\n",
      "Morfemas: {'PunctType': 'Peri'}\n",
      "\n",
      "Token: We\n",
      "Lema: we\n",
      "Lexema: We\n",
      "Morfemas: {'Case': 'Nom', 'Number': 'Plur', 'Person': '1', 'PronType': 'Prs'}\n",
      "\n",
      "Token: may\n",
      "Lema: may\n",
      "Lexema: may\n",
      "Morfemas: {'VerbForm': 'Fin'}\n",
      "\n",
      "Token: not\n",
      "Lema: not\n",
      "Lexema: not\n",
      "Morfemas: {'Polarity': 'Neg'}\n",
      "\n",
      "Token: get\n",
      "Lema: get\n",
      "Lexema: get\n",
      "Morfemas: {'VerbForm': 'Inf'}\n",
      "\n",
      "Token: there\n",
      "Lema: there\n",
      "Lexema: there\n",
      "Morfemas: {'PronType': 'Dem'}\n",
      "\n",
      "Token: in\n",
      "Lema: in\n",
      "Lexema: in\n",
      "Morfemas: {}\n",
      "\n",
      "Token: one\n",
      "Lema: one\n",
      "Lexema: one\n",
      "Morfemas: {'NumType': 'Card'}\n",
      "\n",
      "Token: year\n",
      "Lema: year\n",
      "Lexema: year\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: or\n",
      "Lema: or\n",
      "Lexema: or\n",
      "Morfemas: {'ConjType': 'Cmp'}\n",
      "\n",
      "Token: even\n",
      "Lema: even\n",
      "Lexema: even\n",
      "Morfemas: {}\n",
      "\n",
      "Token: in\n",
      "Lema: in\n",
      "Lexema: in\n",
      "Morfemas: {}\n",
      "\n",
      "Token: one\n",
      "Lema: one\n",
      "Lexema: one\n",
      "Morfemas: {'NumType': 'Card'}\n",
      "\n",
      "Token: term\n",
      "Lema: term\n",
      "Lexema: term\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: .\n",
      "Lema: .\n",
      "Lexema: .\n",
      "Morfemas: {'PunctType': 'Peri'}\n",
      "\n",
      "Token: But\n",
      "Lema: but\n",
      "Lexema: But\n",
      "Morfemas: {'ConjType': 'Cmp'}\n",
      "\n",
      "Token: ,\n",
      "Lema: ,\n",
      "Lexema: ,\n",
      "Morfemas: {'PunctType': 'Comm'}\n",
      "\n",
      "Token: America\n",
      "Lema: America\n",
      "Lexema: America\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: ,\n",
      "Lema: ,\n",
      "Lexema: ,\n",
      "Morfemas: {'PunctType': 'Comm'}\n",
      "\n",
      "Token: I\n",
      "Lema: I\n",
      "Lexema: I\n",
      "Morfemas: {'Case': 'Nom', 'Number': 'Sing', 'Person': '1', 'PronType': 'Prs'}\n",
      "\n",
      "Token: have\n",
      "Lema: have\n",
      "Lexema: have\n",
      "Morfemas: {'Mood': 'Ind', 'Tense': 'Pres', 'VerbForm': 'Fin'}\n",
      "\n",
      "Token: never\n",
      "Lema: never\n",
      "Lexema: never\n",
      "Morfemas: {}\n",
      "\n",
      "Token: been\n",
      "Lema: be\n",
      "Lexema: been\n",
      "Morfemas: {'Tense': 'Past', 'VerbForm': 'Part'}\n",
      "\n",
      "Token: more\n",
      "Lema: more\n",
      "Lexema: more\n",
      "Morfemas: {'Degree': 'Cmp'}\n",
      "\n",
      "Token: hopeful\n",
      "Lema: hopeful\n",
      "Lexema: hopeful\n",
      "Morfemas: {'Degree': 'Pos'}\n",
      "\n",
      "Token: than\n",
      "Lema: than\n",
      "Lexema: than\n",
      "Morfemas: {}\n",
      "\n",
      "Token: I\n",
      "Lema: I\n",
      "Lexema: I\n",
      "Morfemas: {'Case': 'Nom', 'Number': 'Sing', 'Person': '1', 'PronType': 'Prs'}\n",
      "\n",
      "Token: am\n",
      "Lema: be\n",
      "Lexema: am\n",
      "Morfemas: {'Mood': 'Ind', 'Number': 'Sing', 'Person': '1', 'Tense': 'Pres', 'VerbForm': 'Fin'}\n",
      "\n",
      "Token: tonight\n",
      "Lema: tonight\n",
      "Lexema: tonight\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: that\n",
      "Lema: that\n",
      "Lexema: that\n",
      "Morfemas: {}\n",
      "\n",
      "Token: we\n",
      "Lema: we\n",
      "Lexema: we\n",
      "Morfemas: {'Case': 'Nom', 'Number': 'Plur', 'Person': '1', 'PronType': 'Prs'}\n",
      "\n",
      "Token: will\n",
      "Lema: will\n",
      "Lexema: will\n",
      "Morfemas: {'VerbForm': 'Fin'}\n",
      "\n",
      "Token: get\n",
      "Lema: get\n",
      "Lexema: get\n",
      "Morfemas: {'VerbForm': 'Inf'}\n",
      "\n",
      "Token: there\n",
      "Lema: there\n",
      "Lexema: there\n",
      "Morfemas: {'PronType': 'Dem'}\n",
      "\n",
      "Token: .\n",
      "Lema: .\n",
      "Lexema: .\n",
      "Morfemas: {'PunctType': 'Peri'}\n",
      "\n",
      "Token: \n",
      "\n",
      "Lema: \n",
      "\n",
      "Lexema: \n",
      "\n",
      "Morfemas: {}\n",
      "\n",
      "Token: I\n",
      "Lema: I\n",
      "Lexema: I\n",
      "Morfemas: {'Case': 'Nom', 'Number': 'Sing', 'Person': '1', 'PronType': 'Prs'}\n",
      "\n",
      "Token: promise\n",
      "Lema: promise\n",
      "Lexema: promise\n",
      "Morfemas: {'Tense': 'Pres', 'VerbForm': 'Fin'}\n",
      "\n",
      "Token: you\n",
      "Lema: you\n",
      "Lexema: you\n",
      "Morfemas: {'Case': 'Acc', 'Person': '2', 'PronType': 'Prs'}\n",
      "\n",
      "Token: ,\n",
      "Lema: ,\n",
      "Lexema: ,\n",
      "Morfemas: {'PunctType': 'Comm'}\n",
      "\n",
      "Token: we\n",
      "Lema: we\n",
      "Lexema: we\n",
      "Morfemas: {'Case': 'Nom', 'Number': 'Plur', 'Person': '1', 'PronType': 'Prs'}\n",
      "\n",
      "Token: as\n",
      "Lema: as\n",
      "Lexema: as\n",
      "Morfemas: {}\n",
      "\n",
      "Token: a\n",
      "Lema: a\n",
      "Lexema: a\n",
      "Morfemas: {'Definite': 'Ind', 'PronType': 'Art'}\n",
      "\n",
      "Token: people\n",
      "Lema: people\n",
      "Lexema: people\n",
      "Morfemas: {'Number': 'Plur'}\n",
      "\n",
      "Token: will\n",
      "Lema: will\n",
      "Lexema: will\n",
      "Morfemas: {'VerbForm': 'Fin'}\n",
      "\n",
      "Token: get\n",
      "Lema: get\n",
      "Lexema: get\n",
      "Morfemas: {'VerbForm': 'Inf'}\n",
      "\n",
      "Token: there\n",
      "Lema: there\n",
      "Lexema: there\n",
      "Morfemas: {'PronType': 'Dem'}\n",
      "\n",
      "Token: .\n",
      "Lema: .\n",
      "Lexema: .\n",
      "Morfemas: {'PunctType': 'Peri'}\n",
      "\n",
      "Token: \n",
      "\n",
      "Lema: \n",
      "\n",
      "Lexema: \n",
      "\n",
      "Morfemas: {}\n",
      "\n",
      "Token: There\n",
      "Lema: there\n",
      "Lexema: There\n",
      "Morfemas: {}\n",
      "\n",
      "Token: will\n",
      "Lema: will\n",
      "Lexema: will\n",
      "Morfemas: {'VerbForm': 'Fin'}\n",
      "\n",
      "Token: be\n",
      "Lema: be\n",
      "Lexema: be\n",
      "Morfemas: {'VerbForm': 'Inf'}\n",
      "\n",
      "Token: setbacks\n",
      "Lema: setback\n",
      "Lexema: setbacks\n",
      "Morfemas: {'Number': 'Plur'}\n",
      "\n",
      "Token: and\n",
      "Lema: and\n",
      "Lexema: and\n",
      "Morfemas: {'ConjType': 'Cmp'}\n",
      "\n",
      "Token: false\n",
      "Lema: false\n",
      "Lexema: false\n",
      "Morfemas: {'Degree': 'Pos'}\n",
      "\n",
      "Token: starts\n",
      "Lema: start\n",
      "Lexema: starts\n",
      "Morfemas: {'Number': 'Plur'}\n",
      "\n",
      "Token: .\n",
      "Lema: .\n",
      "Lexema: .\n",
      "Morfemas: {'PunctType': 'Peri'}\n",
      "\n",
      "Token: There\n",
      "Lema: there\n",
      "Lexema: There\n",
      "Morfemas: {}\n",
      "\n",
      "Token: are\n",
      "Lema: be\n",
      "Lexema: are\n",
      "Morfemas: {'Mood': 'Ind', 'Tense': 'Pres', 'VerbForm': 'Fin'}\n",
      "\n",
      "Token: many\n",
      "Lema: many\n",
      "Lexema: many\n",
      "Morfemas: {'Degree': 'Pos'}\n",
      "\n",
      "Token: who\n",
      "Lema: who\n",
      "Lexema: who\n",
      "Morfemas: {}\n",
      "\n",
      "Token: wo\n",
      "Lema: will\n",
      "Lexema: wo\n",
      "Morfemas: {'VerbType': 'Mod'}\n",
      "\n",
      "Token: n’t\n",
      "Lema: not\n",
      "Lexema: n’t\n",
      "Morfemas: {}\n",
      "\n",
      "Token: agree\n",
      "Lema: agree\n",
      "Lexema: agree\n",
      "Morfemas: {'VerbForm': 'Inf'}\n",
      "\n",
      "Token: with\n",
      "Lema: with\n",
      "Lexema: with\n",
      "Morfemas: {}\n",
      "\n",
      "Token: every\n",
      "Lema: every\n",
      "Lexema: every\n",
      "Morfemas: {}\n",
      "\n",
      "Token: decision\n",
      "Lema: decision\n",
      "Lexema: decision\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: or\n",
      "Lema: or\n",
      "Lexema: or\n",
      "Morfemas: {'ConjType': 'Cmp'}\n",
      "\n",
      "Token: policy\n",
      "Lema: policy\n",
      "Lexema: policy\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: I\n",
      "Lema: I\n",
      "Lexema: I\n",
      "Morfemas: {'Case': 'Nom', 'Number': 'Sing', 'Person': '1', 'PronType': 'Prs'}\n",
      "\n",
      "Token: make\n",
      "Lema: make\n",
      "Lexema: make\n",
      "Morfemas: {'Tense': 'Pres', 'VerbForm': 'Fin'}\n",
      "\n",
      "Token: as\n",
      "Lema: as\n",
      "Lexema: as\n",
      "Morfemas: {}\n",
      "\n",
      "Token: president\n",
      "Lema: president\n",
      "Lexema: president\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: .\n",
      "Lema: .\n",
      "Lexema: .\n",
      "Morfemas: {'PunctType': 'Peri'}\n",
      "\n",
      "Token: And\n",
      "Lema: and\n",
      "Lexema: And\n",
      "Morfemas: {'ConjType': 'Cmp'}\n",
      "\n",
      "Token: we\n",
      "Lema: we\n",
      "Lexema: we\n",
      "Morfemas: {'Case': 'Nom', 'Number': 'Plur', 'Person': '1', 'PronType': 'Prs'}\n",
      "\n",
      "Token: know\n",
      "Lema: know\n",
      "Lexema: know\n",
      "Morfemas: {'Tense': 'Pres', 'VerbForm': 'Fin'}\n",
      "\n",
      "Token: the\n",
      "Lema: the\n",
      "Lexema: the\n",
      "Morfemas: {'Definite': 'Def', 'PronType': 'Art'}\n",
      "\n",
      "Token: government\n",
      "Lema: government\n",
      "Lexema: government\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: ca\n",
      "Lema: can\n",
      "Lexema: ca\n",
      "Morfemas: {'VerbType': 'Mod'}\n",
      "\n",
      "Token: n’t\n",
      "Lema: not\n",
      "Lexema: n’t\n",
      "Morfemas: {}\n",
      "\n",
      "Token: solve\n",
      "Lema: solve\n",
      "Lexema: solve\n",
      "Morfemas: {'VerbForm': 'Inf'}\n",
      "\n",
      "Token: every\n",
      "Lema: every\n",
      "Lexema: every\n",
      "Morfemas: {}\n",
      "\n",
      "Token: problem\n",
      "Lema: problem\n",
      "Lexema: problem\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: .\n",
      "Lema: .\n",
      "Lexema: .\n",
      "Morfemas: {'PunctType': 'Peri'}\n",
      "\n",
      "Token: \n",
      "\n",
      "Lema: \n",
      "\n",
      "Lexema: \n",
      "\n",
      "Morfemas: {}\n",
      "\n",
      "Token: But\n",
      "Lema: but\n",
      "Lexema: But\n",
      "Morfemas: {'ConjType': 'Cmp'}\n",
      "\n",
      "Token: I\n",
      "Lema: I\n",
      "Lexema: I\n",
      "Morfemas: {'Case': 'Nom', 'Number': 'Sing', 'Person': '1', 'PronType': 'Prs'}\n",
      "\n",
      "Token: will\n",
      "Lema: will\n",
      "Lexema: will\n",
      "Morfemas: {'VerbForm': 'Fin'}\n",
      "\n",
      "Token: always\n",
      "Lema: always\n",
      "Lexema: always\n",
      "Morfemas: {}\n",
      "\n",
      "Token: be\n",
      "Lema: be\n",
      "Lexema: be\n",
      "Morfemas: {'VerbForm': 'Inf'}\n",
      "\n",
      "Token: honest\n",
      "Lema: honest\n",
      "Lexema: honest\n",
      "Morfemas: {'Degree': 'Pos'}\n",
      "\n",
      "Token: with\n",
      "Lema: with\n",
      "Lexema: with\n",
      "Morfemas: {}\n",
      "\n",
      "Token: you\n",
      "Lema: you\n",
      "Lexema: you\n",
      "Morfemas: {'Case': 'Acc', 'Person': '2', 'PronType': 'Prs'}\n",
      "\n",
      "Token: about\n",
      "Lema: about\n",
      "Lexema: about\n",
      "Morfemas: {}\n",
      "\n",
      "Token: the\n",
      "Lema: the\n",
      "Lexema: the\n",
      "Morfemas: {'Definite': 'Def', 'PronType': 'Art'}\n",
      "\n",
      "Token: challenges\n",
      "Lema: challenge\n",
      "Lexema: challenges\n",
      "Morfemas: {'Number': 'Plur'}\n",
      "\n",
      "Token: we\n",
      "Lema: we\n",
      "Lexema: we\n",
      "Morfemas: {'Case': 'Nom', 'Number': 'Plur', 'Person': '1', 'PronType': 'Prs'}\n",
      "\n",
      "Token: face\n",
      "Lema: face\n",
      "Lexema: face\n",
      "Morfemas: {'Tense': 'Pres', 'VerbForm': 'Fin'}\n",
      "\n",
      "Token: .\n",
      "Lema: .\n",
      "Lexema: .\n",
      "Morfemas: {'PunctType': 'Peri'}\n",
      "\n",
      "Token: I\n",
      "Lema: I\n",
      "Lexema: I\n",
      "Morfemas: {'Case': 'Nom', 'Number': 'Sing', 'Person': '1', 'PronType': 'Prs'}\n",
      "\n",
      "Token: will\n",
      "Lema: will\n",
      "Lexema: will\n",
      "Morfemas: {'VerbForm': 'Fin'}\n",
      "\n",
      "Token: listen\n",
      "Lema: listen\n",
      "Lexema: listen\n",
      "Morfemas: {'VerbForm': 'Inf'}\n",
      "\n",
      "Token: to\n",
      "Lema: to\n",
      "Lexema: to\n",
      "Morfemas: {}\n",
      "\n",
      "Token: you\n",
      "Lema: you\n",
      "Lexema: you\n",
      "Morfemas: {'Case': 'Acc', 'Person': '2', 'PronType': 'Prs'}\n",
      "\n",
      "Token: ,\n",
      "Lema: ,\n",
      "Lexema: ,\n",
      "Morfemas: {'PunctType': 'Comm'}\n",
      "\n",
      "Token: especially\n",
      "Lema: especially\n",
      "Lexema: especially\n",
      "Morfemas: {}\n",
      "\n",
      "Token: when\n",
      "Lema: when\n",
      "Lexema: when\n",
      "Morfemas: {}\n",
      "\n",
      "Token: we\n",
      "Lema: we\n",
      "Lexema: we\n",
      "Morfemas: {'Case': 'Nom', 'Number': 'Plur', 'Person': '1', 'PronType': 'Prs'}\n",
      "\n",
      "Token: disagree\n",
      "Lema: disagree\n",
      "Lexema: disagree\n",
      "Morfemas: {'Tense': 'Pres', 'VerbForm': 'Fin'}\n",
      "\n",
      "Token: .\n",
      "Lema: .\n",
      "Lexema: .\n",
      "Morfemas: {'PunctType': 'Peri'}\n",
      "\n",
      "Token: And\n",
      "Lema: and\n",
      "Lexema: And\n",
      "Morfemas: {'ConjType': 'Cmp'}\n",
      "\n",
      "Token: ,\n",
      "Lema: ,\n",
      "Lexema: ,\n",
      "Morfemas: {'PunctType': 'Comm'}\n",
      "\n",
      "Token: above\n",
      "Lema: above\n",
      "Lexema: above\n",
      "Morfemas: {}\n",
      "\n",
      "Token: all\n",
      "Lema: all\n",
      "Lexema: all\n",
      "Morfemas: {}\n",
      "\n",
      "Token: ,\n",
      "Lema: ,\n",
      "Lexema: ,\n",
      "Morfemas: {'PunctType': 'Comm'}\n",
      "\n",
      "Token: I\n",
      "Lema: I\n",
      "Lexema: I\n",
      "Morfemas: {'Case': 'Nom', 'Number': 'Sing', 'Person': '1', 'PronType': 'Prs'}\n",
      "\n",
      "Token: will\n",
      "Lema: will\n",
      "Lexema: will\n",
      "Morfemas: {'VerbForm': 'Fin'}\n",
      "\n",
      "Token: ask\n",
      "Lema: ask\n",
      "Lexema: ask\n",
      "Morfemas: {'VerbForm': 'Inf'}\n",
      "\n",
      "Token: you\n",
      "Lema: you\n",
      "Lexema: you\n",
      "Morfemas: {'Case': 'Acc', 'Person': '2', 'PronType': 'Prs'}\n",
      "\n",
      "Token: to\n",
      "Lema: to\n",
      "Lexema: to\n",
      "Morfemas: {}\n",
      "\n",
      "Token: join\n",
      "Lema: join\n",
      "Lexema: join\n",
      "Morfemas: {'VerbForm': 'Inf'}\n",
      "\n",
      "Token: in\n",
      "Lema: in\n",
      "Lexema: in\n",
      "Morfemas: {}\n",
      "\n",
      "Token: the\n",
      "Lema: the\n",
      "Lexema: the\n",
      "Morfemas: {'Definite': 'Def', 'PronType': 'Art'}\n",
      "\n",
      "Token: work\n",
      "Lema: work\n",
      "Lexema: work\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: of\n",
      "Lema: of\n",
      "Lexema: of\n",
      "Morfemas: {}\n",
      "\n",
      "Token: remaking\n",
      "Lema: remake\n",
      "Lexema: remaking\n",
      "Morfemas: {'Aspect': 'Prog', 'Tense': 'Pres', 'VerbForm': 'Part'}\n",
      "\n",
      "Token: this\n",
      "Lema: this\n",
      "Lexema: this\n",
      "Morfemas: {'Number': 'Sing', 'PronType': 'Dem'}\n",
      "\n",
      "Token: nation\n",
      "Lema: nation\n",
      "Lexema: nation\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: ,\n",
      "Lema: ,\n",
      "Lexema: ,\n",
      "Morfemas: {'PunctType': 'Comm'}\n",
      "\n",
      "Token: the\n",
      "Lema: the\n",
      "Lexema: the\n",
      "Morfemas: {'Definite': 'Def', 'PronType': 'Art'}\n",
      "\n",
      "Token: only\n",
      "Lema: only\n",
      "Lexema: only\n",
      "Morfemas: {'Degree': 'Pos'}\n",
      "\n",
      "Token: way\n",
      "Lema: way\n",
      "Lexema: way\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: it\n",
      "Lema: it\n",
      "Lexema: it\n",
      "Morfemas: {'Gender': 'Neut', 'Number': 'Sing', 'Person': '3', 'PronType': 'Prs'}\n",
      "\n",
      "Token: ’s\n",
      "Lema: ’s\n",
      "Lexema: ’s\n",
      "Morfemas: {'Number': 'Sing', 'Person': '3', 'Tense': 'Pres', 'VerbForm': 'Fin'}\n",
      "\n",
      "Token: been\n",
      "Lema: be\n",
      "Lexema: been\n",
      "Morfemas: {'Tense': 'Past', 'VerbForm': 'Part'}\n",
      "\n",
      "Token: done\n",
      "Lema: do\n",
      "Lexema: done\n",
      "Morfemas: {'Aspect': 'Perf', 'Tense': 'Past', 'VerbForm': 'Part'}\n",
      "\n",
      "Token: in\n",
      "Lema: in\n",
      "Lexema: in\n",
      "Morfemas: {}\n",
      "\n",
      "Token: America\n",
      "Lema: America\n",
      "Lexema: America\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: for\n",
      "Lema: for\n",
      "Lexema: for\n",
      "Morfemas: {}\n",
      "\n",
      "Token: 221\n",
      "Lema: 221\n",
      "Lexema: 221\n",
      "Morfemas: {'NumType': 'Card'}\n",
      "\n",
      "Token: years\n",
      "Lema: year\n",
      "Lexema: years\n",
      "Morfemas: {'Number': 'Plur'}\n",
      "\n",
      "Token: —\n",
      "Lema: —\n",
      "Lexema: —\n",
      "Morfemas: {}\n",
      "\n",
      "Token: block\n",
      "Lema: block\n",
      "Lexema: block\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: by\n",
      "Lema: by\n",
      "Lexema: by\n",
      "Morfemas: {}\n",
      "\n",
      "Token: block\n",
      "Lema: block\n",
      "Lexema: block\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: ,\n",
      "Lema: ,\n",
      "Lexema: ,\n",
      "Morfemas: {'PunctType': 'Comm'}\n",
      "\n",
      "Token: brick\n",
      "Lema: brick\n",
      "Lexema: brick\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: by\n",
      "Lema: by\n",
      "Lexema: by\n",
      "Morfemas: {}\n",
      "\n",
      "Token: brick\n",
      "Lema: brick\n",
      "Lexema: brick\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: ,\n",
      "Lema: ,\n",
      "Lexema: ,\n",
      "Morfemas: {'PunctType': 'Comm'}\n",
      "\n",
      "Token: calloused\n",
      "Lema: calloused\n",
      "Lexema: calloused\n",
      "Morfemas: {'Degree': 'Pos'}\n",
      "\n",
      "Token: hand\n",
      "Lema: hand\n",
      "Lexema: hand\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: by\n",
      "Lema: by\n",
      "Lexema: by\n",
      "Morfemas: {}\n",
      "\n",
      "Token: calloused\n",
      "Lema: calloused\n",
      "Lexema: calloused\n",
      "Morfemas: {'Degree': 'Pos'}\n",
      "\n",
      "Token: hand\n",
      "Lema: hand\n",
      "Lexema: hand\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: .\n",
      "Lema: .\n",
      "Lexema: .\n",
      "Morfemas: {'PunctType': 'Peri'}\n",
      "\n",
      "Token: \n",
      "\n",
      "Lema: \n",
      "\n",
      "Lexema: \n",
      "\n",
      "Morfemas: {}\n",
      "\n",
      "Token: What\n",
      "Lema: what\n",
      "Lexema: What\n",
      "Morfemas: {}\n",
      "\n",
      "Token: began\n",
      "Lema: begin\n",
      "Lexema: began\n",
      "Morfemas: {'Tense': 'Past', 'VerbForm': 'Fin'}\n",
      "\n",
      "Token: 21\n",
      "Lema: 21\n",
      "Lexema: 21\n",
      "Morfemas: {'NumType': 'Card'}\n",
      "\n",
      "Token: months\n",
      "Lema: month\n",
      "Lexema: months\n",
      "Morfemas: {'Number': 'Plur'}\n",
      "\n",
      "Token: ago\n",
      "Lema: ago\n",
      "Lexema: ago\n",
      "Morfemas: {}\n",
      "\n",
      "Token: in\n",
      "Lema: in\n",
      "Lexema: in\n",
      "Morfemas: {}\n",
      "\n",
      "Token: the\n",
      "Lema: the\n",
      "Lexema: the\n",
      "Morfemas: {'Definite': 'Def', 'PronType': 'Art'}\n",
      "\n",
      "Token: depths\n",
      "Lema: depth\n",
      "Lexema: depths\n",
      "Morfemas: {'Number': 'Plur'}\n",
      "\n",
      "Token: of\n",
      "Lema: of\n",
      "Lexema: of\n",
      "Morfemas: {}\n",
      "\n",
      "Token: winter\n",
      "Lema: winter\n",
      "Lexema: winter\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: can\n",
      "Lema: can\n",
      "Lexema: can\n",
      "Morfemas: {'VerbForm': 'Fin'}\n",
      "\n",
      "Token: not\n",
      "Lema: not\n",
      "Lexema: not\n",
      "Morfemas: {'Polarity': 'Neg'}\n",
      "\n",
      "Token: end\n",
      "Lema: end\n",
      "Lexema: end\n",
      "Morfemas: {'VerbForm': 'Inf'}\n",
      "\n",
      "Token: on\n",
      "Lema: on\n",
      "Lexema: on\n",
      "Morfemas: {}\n",
      "\n",
      "Token: this\n",
      "Lema: this\n",
      "Lexema: this\n",
      "Morfemas: {'Number': 'Sing', 'PronType': 'Dem'}\n",
      "\n",
      "Token: autumn\n",
      "Lema: autumn\n",
      "Lexema: autumn\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: night\n",
      "Lema: night\n",
      "Lexema: night\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: .\n",
      "Lema: .\n",
      "Lexema: .\n",
      "Morfemas: {'PunctType': 'Peri'}\n",
      "\n",
      "Token: \n",
      "\n",
      "Lema: \n",
      "\n",
      "Lexema: \n",
      "\n",
      "Morfemas: {}\n",
      "\n",
      "Token: This\n",
      "Lema: this\n",
      "Lexema: This\n",
      "Morfemas: {'Number': 'Sing', 'PronType': 'Dem'}\n",
      "\n",
      "Token: victory\n",
      "Lema: victory\n",
      "Lexema: victory\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: alone\n",
      "Lema: alone\n",
      "Lexema: alone\n",
      "Morfemas: {}\n",
      "\n",
      "Token: is\n",
      "Lema: be\n",
      "Lexema: is\n",
      "Morfemas: {'Mood': 'Ind', 'Number': 'Sing', 'Person': '3', 'Tense': 'Pres', 'VerbForm': 'Fin'}\n",
      "\n",
      "Token: not\n",
      "Lema: not\n",
      "Lexema: not\n",
      "Morfemas: {'Polarity': 'Neg'}\n",
      "\n",
      "Token: the\n",
      "Lema: the\n",
      "Lexema: the\n",
      "Morfemas: {'Definite': 'Def', 'PronType': 'Art'}\n",
      "\n",
      "Token: change\n",
      "Lema: change\n",
      "Lexema: change\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: we\n",
      "Lema: we\n",
      "Lexema: we\n",
      "Morfemas: {'Case': 'Nom', 'Number': 'Plur', 'Person': '1', 'PronType': 'Prs'}\n",
      "\n",
      "Token: seek\n",
      "Lema: seek\n",
      "Lexema: seek\n",
      "Morfemas: {'Tense': 'Pres', 'VerbForm': 'Fin'}\n",
      "\n",
      "Token: .\n",
      "Lema: .\n",
      "Lexema: .\n",
      "Morfemas: {'PunctType': 'Peri'}\n",
      "\n",
      "Token: It\n",
      "Lema: it\n",
      "Lexema: It\n",
      "Morfemas: {'Case': 'Nom', 'Gender': 'Neut', 'Number': 'Sing', 'Person': '3', 'PronType': 'Prs'}\n",
      "\n",
      "Token: is\n",
      "Lema: be\n",
      "Lexema: is\n",
      "Morfemas: {'Mood': 'Ind', 'Number': 'Sing', 'Person': '3', 'Tense': 'Pres', 'VerbForm': 'Fin'}\n",
      "\n",
      "Token: only\n",
      "Lema: only\n",
      "Lexema: only\n",
      "Morfemas: {}\n",
      "\n",
      "Token: the\n",
      "Lema: the\n",
      "Lexema: the\n",
      "Morfemas: {'Definite': 'Def', 'PronType': 'Art'}\n",
      "\n",
      "Token: chance\n",
      "Lema: chance\n",
      "Lexema: chance\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: for\n",
      "Lema: for\n",
      "Lexema: for\n",
      "Morfemas: {}\n",
      "\n",
      "Token: us\n",
      "Lema: we\n",
      "Lexema: us\n",
      "Morfemas: {'Case': 'Acc', 'Number': 'Plur', 'Person': '1', 'PronType': 'Prs'}\n",
      "\n",
      "Token: to\n",
      "Lema: to\n",
      "Lexema: to\n",
      "Morfemas: {}\n",
      "\n",
      "Token: make\n",
      "Lema: make\n",
      "Lexema: make\n",
      "Morfemas: {'VerbForm': 'Inf'}\n",
      "\n",
      "Token: that\n",
      "Lema: that\n",
      "Lexema: that\n",
      "Morfemas: {'Number': 'Sing', 'PronType': 'Dem'}\n",
      "\n",
      "Token: change\n",
      "Lema: change\n",
      "Lexema: change\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: .\n",
      "Lema: .\n",
      "Lexema: .\n",
      "Morfemas: {'PunctType': 'Peri'}\n",
      "\n",
      "Token: And\n",
      "Lema: and\n",
      "Lexema: And\n",
      "Morfemas: {'ConjType': 'Cmp'}\n",
      "\n",
      "Token: that\n",
      "Lema: that\n",
      "Lexema: that\n",
      "Morfemas: {'Number': 'Sing', 'PronType': 'Dem'}\n",
      "\n",
      "Token: can\n",
      "Lema: can\n",
      "Lexema: can\n",
      "Morfemas: {'VerbForm': 'Fin'}\n",
      "\n",
      "Token: not\n",
      "Lema: not\n",
      "Lexema: not\n",
      "Morfemas: {'Polarity': 'Neg'}\n",
      "\n",
      "Token: happen\n",
      "Lema: happen\n",
      "Lexema: happen\n",
      "Morfemas: {'VerbForm': 'Inf'}\n",
      "\n",
      "Token: if\n",
      "Lema: if\n",
      "Lexema: if\n",
      "Morfemas: {}\n",
      "\n",
      "Token: we\n",
      "Lema: we\n",
      "Lexema: we\n",
      "Morfemas: {'Case': 'Nom', 'Number': 'Plur', 'Person': '1', 'PronType': 'Prs'}\n",
      "\n",
      "Token: go\n",
      "Lema: go\n",
      "Lexema: go\n",
      "Morfemas: {'Tense': 'Pres', 'VerbForm': 'Fin'}\n",
      "\n",
      "Token: back\n",
      "Lema: back\n",
      "Lexema: back\n",
      "Morfemas: {}\n",
      "\n",
      "Token: to\n",
      "Lema: to\n",
      "Lexema: to\n",
      "Morfemas: {}\n",
      "\n",
      "Token: the\n",
      "Lema: the\n",
      "Lexema: the\n",
      "Morfemas: {'Definite': 'Def', 'PronType': 'Art'}\n",
      "\n",
      "Token: way\n",
      "Lema: way\n",
      "Lexema: way\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: things\n",
      "Lema: thing\n",
      "Lexema: things\n",
      "Morfemas: {'Number': 'Plur'}\n",
      "\n",
      "Token: were\n",
      "Lema: be\n",
      "Lexema: were\n",
      "Morfemas: {'Mood': 'Ind', 'Tense': 'Past', 'VerbForm': 'Fin'}\n",
      "\n",
      "Token: .\n",
      "Lema: .\n",
      "Lexema: .\n",
      "Morfemas: {'PunctType': 'Peri'}\n",
      "\n",
      "Token: \n",
      "\n",
      "Lema: \n",
      "\n",
      "Lexema: \n",
      "\n",
      "Morfemas: {}\n",
      "\n",
      "Token: It\n",
      "Lema: it\n",
      "Lexema: It\n",
      "Morfemas: {'Case': 'Nom', 'Gender': 'Neut', 'Number': 'Sing', 'Person': '3', 'PronType': 'Prs'}\n",
      "\n",
      "Token: ca\n",
      "Lema: can\n",
      "Lexema: ca\n",
      "Morfemas: {'VerbType': 'Mod'}\n",
      "\n",
      "Token: n’t\n",
      "Lema: not\n",
      "Lexema: n’t\n",
      "Morfemas: {}\n",
      "\n",
      "Token: happen\n",
      "Lema: happen\n",
      "Lexema: happen\n",
      "Morfemas: {'VerbForm': 'Inf'}\n",
      "\n",
      "Token: without\n",
      "Lema: without\n",
      "Lexema: without\n",
      "Morfemas: {}\n",
      "\n",
      "Token: you\n",
      "Lema: you\n",
      "Lexema: you\n",
      "Morfemas: {'Case': 'Acc', 'Person': '2', 'PronType': 'Prs'}\n",
      "\n",
      "Token: ,\n",
      "Lema: ,\n",
      "Lexema: ,\n",
      "Morfemas: {'PunctType': 'Comm'}\n",
      "\n",
      "Token: without\n",
      "Lema: without\n",
      "Lexema: without\n",
      "Morfemas: {}\n",
      "\n",
      "Token: a\n",
      "Lema: a\n",
      "Lexema: a\n",
      "Morfemas: {'Definite': 'Ind', 'PronType': 'Art'}\n",
      "\n",
      "Token: new\n",
      "Lema: new\n",
      "Lexema: new\n",
      "Morfemas: {'Degree': 'Pos'}\n",
      "\n",
      "Token: spirit\n",
      "Lema: spirit\n",
      "Lexema: spirit\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: of\n",
      "Lema: of\n",
      "Lexema: of\n",
      "Morfemas: {}\n",
      "\n",
      "Token: service\n",
      "Lema: service\n",
      "Lexema: service\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: ,\n",
      "Lema: ,\n",
      "Lexema: ,\n",
      "Morfemas: {'PunctType': 'Comm'}\n",
      "\n",
      "Token: a\n",
      "Lema: a\n",
      "Lexema: a\n",
      "Morfemas: {'Definite': 'Ind', 'PronType': 'Art'}\n",
      "\n",
      "Token: new\n",
      "Lema: new\n",
      "Lexema: new\n",
      "Morfemas: {'Degree': 'Pos'}\n",
      "\n",
      "Token: spirit\n",
      "Lema: spirit\n",
      "Lexema: spirit\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: of\n",
      "Lema: of\n",
      "Lexema: of\n",
      "Morfemas: {}\n",
      "\n",
      "Token: sacrifice\n",
      "Lema: sacrifice\n",
      "Lexema: sacrifice\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: .\n",
      "Lema: .\n",
      "Lexema: .\n",
      "Morfemas: {'PunctType': 'Peri'}\n",
      "\n",
      "Token: \n",
      "\n",
      "Lema: \n",
      "\n",
      "Lexema: \n",
      "\n",
      "Morfemas: {}\n",
      "\n",
      "Token: So\n",
      "Lema: so\n",
      "Lexema: So\n",
      "Morfemas: {}\n",
      "\n",
      "Token: let\n",
      "Lema: let\n",
      "Lexema: let\n",
      "Morfemas: {'VerbForm': 'Inf'}\n",
      "\n",
      "Token: us\n",
      "Lema: we\n",
      "Lexema: us\n",
      "Morfemas: {'Case': 'Acc', 'Number': 'Plur', 'Person': '1', 'PronType': 'Prs'}\n",
      "\n",
      "Token: summon\n",
      "Lema: summon\n",
      "Lexema: summon\n",
      "Morfemas: {'VerbForm': 'Inf'}\n",
      "\n",
      "Token: a\n",
      "Lema: a\n",
      "Lexema: a\n",
      "Morfemas: {'Definite': 'Ind', 'PronType': 'Art'}\n",
      "\n",
      "Token: new\n",
      "Lema: new\n",
      "Lexema: new\n",
      "Morfemas: {'Degree': 'Pos'}\n",
      "\n",
      "Token: spirit\n",
      "Lema: spirit\n",
      "Lexema: spirit\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: of\n",
      "Lema: of\n",
      "Lexema: of\n",
      "Morfemas: {}\n",
      "\n",
      "Token: patriotism\n",
      "Lema: patriotism\n",
      "Lexema: patriotism\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: ,\n",
      "Lema: ,\n",
      "Lexema: ,\n",
      "Morfemas: {'PunctType': 'Comm'}\n",
      "\n",
      "Token: of\n",
      "Lema: of\n",
      "Lexema: of\n",
      "Morfemas: {}\n",
      "\n",
      "Token: responsibility\n",
      "Lema: responsibility\n",
      "Lexema: responsibility\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: ,\n",
      "Lema: ,\n",
      "Lexema: ,\n",
      "Morfemas: {'PunctType': 'Comm'}\n",
      "\n",
      "Token: where\n",
      "Lema: where\n",
      "Lexema: where\n",
      "Morfemas: {}\n",
      "\n",
      "Token: each\n",
      "Lema: each\n",
      "Lexema: each\n",
      "Morfemas: {}\n",
      "\n",
      "Token: of\n",
      "Lema: of\n",
      "Lexema: of\n",
      "Morfemas: {}\n",
      "\n",
      "Token: us\n",
      "Lema: we\n",
      "Lexema: us\n",
      "Morfemas: {'Case': 'Acc', 'Number': 'Plur', 'Person': '1', 'PronType': 'Prs'}\n",
      "\n",
      "Token: resolves\n",
      "Lema: resolve\n",
      "Lexema: resolves\n",
      "Morfemas: {'Number': 'Plur'}\n",
      "\n",
      "Token: to\n",
      "Lema: to\n",
      "Lexema: to\n",
      "Morfemas: {}\n",
      "\n",
      "Token: pitch\n",
      "Lema: pitch\n",
      "Lexema: pitch\n",
      "Morfemas: {'VerbForm': 'Inf'}\n",
      "\n",
      "Token: in\n",
      "Lema: in\n",
      "Lexema: in\n",
      "Morfemas: {}\n",
      "\n",
      "Token: and\n",
      "Lema: and\n",
      "Lexema: and\n",
      "Morfemas: {'ConjType': 'Cmp'}\n",
      "\n",
      "Token: work\n",
      "Lema: work\n",
      "Lexema: work\n",
      "Morfemas: {'VerbForm': 'Inf'}\n",
      "\n",
      "Token: harder\n",
      "Lema: hard\n",
      "Lexema: harder\n",
      "Morfemas: {'Degree': 'Cmp'}\n",
      "\n",
      "Token: and\n",
      "Lema: and\n",
      "Lexema: and\n",
      "Morfemas: {'ConjType': 'Cmp'}\n",
      "\n",
      "Token: look\n",
      "Lema: look\n",
      "Lexema: look\n",
      "Morfemas: {'VerbForm': 'Inf'}\n",
      "\n",
      "Token: after\n",
      "Lema: after\n",
      "Lexema: after\n",
      "Morfemas: {}\n",
      "\n",
      "Token: not\n",
      "Lema: not\n",
      "Lexema: not\n",
      "Morfemas: {'Polarity': 'Neg'}\n",
      "\n",
      "Token: only\n",
      "Lema: only\n",
      "Lexema: only\n",
      "Morfemas: {}\n",
      "\n",
      "Token: ourselves\n",
      "Lema: ourselves\n",
      "Lexema: ourselves\n",
      "Morfemas: {'Case': 'Acc', 'Number': 'Plur', 'Person': '1', 'PronType': 'Prs', 'Reflex': 'Yes'}\n",
      "\n",
      "Token: but\n",
      "Lema: but\n",
      "Lexema: but\n",
      "Morfemas: {'ConjType': 'Cmp'}\n",
      "\n",
      "Token: each\n",
      "Lema: each\n",
      "Lexema: each\n",
      "Morfemas: {}\n",
      "\n",
      "Token: other\n",
      "Lema: other\n",
      "Lexema: other\n",
      "Morfemas: {'Degree': 'Pos'}\n",
      "\n",
      "Token: .\n",
      "Lema: .\n",
      "Lexema: .\n",
      "Morfemas: {'PunctType': 'Peri'}\n",
      "\n",
      "Token: \n",
      "\n",
      "Lema: \n",
      "\n",
      "Lexema: \n",
      "\n",
      "Morfemas: {}\n",
      "\n",
      "Token: Let\n",
      "Lema: let\n",
      "Lexema: Let\n",
      "Morfemas: {'VerbForm': 'Inf'}\n",
      "\n",
      "Token: us\n",
      "Lema: we\n",
      "Lexema: us\n",
      "Morfemas: {'Case': 'Acc', 'Number': 'Plur', 'Person': '1', 'PronType': 'Prs'}\n",
      "\n",
      "Token: remember\n",
      "Lema: remember\n",
      "Lexema: remember\n",
      "Morfemas: {'VerbForm': 'Inf'}\n",
      "\n",
      "Token: that\n",
      "Lema: that\n",
      "Lexema: that\n",
      "Morfemas: {}\n",
      "\n",
      "Token: ,\n",
      "Lema: ,\n",
      "Lexema: ,\n",
      "Morfemas: {'PunctType': 'Comm'}\n",
      "\n",
      "Token: if\n",
      "Lema: if\n",
      "Lexema: if\n",
      "Morfemas: {}\n",
      "\n",
      "Token: this\n",
      "Lema: this\n",
      "Lexema: this\n",
      "Morfemas: {'Number': 'Sing', 'PronType': 'Dem'}\n",
      "\n",
      "Token: financial\n",
      "Lema: financial\n",
      "Lexema: financial\n",
      "Morfemas: {'Degree': 'Pos'}\n",
      "\n",
      "Token: crisis\n",
      "Lema: crisis\n",
      "Lexema: crisis\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: taught\n",
      "Lema: teach\n",
      "Lexema: taught\n",
      "Morfemas: {'Tense': 'Past', 'VerbForm': 'Fin'}\n",
      "\n",
      "Token: us\n",
      "Lema: we\n",
      "Lexema: us\n",
      "Morfemas: {'Case': 'Acc', 'Number': 'Plur', 'Person': '1', 'PronType': 'Prs'}\n",
      "\n",
      "Token: anything\n",
      "Lema: anything\n",
      "Lexema: anything\n",
      "Morfemas: {'Number': 'Sing', 'PronType': 'Ind'}\n",
      "\n",
      "Token: ,\n",
      "Lema: ,\n",
      "Lexema: ,\n",
      "Morfemas: {'PunctType': 'Comm'}\n",
      "\n",
      "Token: it\n",
      "Lema: it\n",
      "Lexema: it\n",
      "Morfemas: {'Case': 'Nom', 'Gender': 'Neut', 'Number': 'Sing', 'Person': '3', 'PronType': 'Prs'}\n",
      "\n",
      "Token: ’s\n",
      "Lema: ’\n",
      "Lexema: ’s\n",
      "Morfemas: {'Number': 'Sing', 'Person': '3', 'Tense': 'Pres', 'VerbForm': 'Fin'}\n",
      "\n",
      "Token: that\n",
      "Lema: that\n",
      "Lexema: that\n",
      "Morfemas: {}\n",
      "\n",
      "Token: we\n",
      "Lema: we\n",
      "Lexema: we\n",
      "Morfemas: {'Case': 'Nom', 'Number': 'Plur', 'Person': '1', 'PronType': 'Prs'}\n",
      "\n",
      "Token: can\n",
      "Lema: can\n",
      "Lexema: can\n",
      "Morfemas: {'VerbForm': 'Fin'}\n",
      "\n",
      "Token: not\n",
      "Lema: not\n",
      "Lexema: not\n",
      "Morfemas: {'Polarity': 'Neg'}\n",
      "\n",
      "Token: have\n",
      "Lema: have\n",
      "Lexema: have\n",
      "Morfemas: {'VerbForm': 'Inf'}\n",
      "\n",
      "Token: a\n",
      "Lema: a\n",
      "Lexema: a\n",
      "Morfemas: {'Definite': 'Ind', 'PronType': 'Art'}\n",
      "\n",
      "Token: thriving\n",
      "Lema: thriving\n",
      "Lexema: thriving\n",
      "Morfemas: {'Degree': 'Pos'}\n",
      "\n",
      "Token: Wall\n",
      "Lema: Wall\n",
      "Lexema: Wall\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: Street\n",
      "Lema: Street\n",
      "Lexema: Street\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: while\n",
      "Lema: while\n",
      "Lexema: while\n",
      "Morfemas: {}\n",
      "\n",
      "Token: Main\n",
      "Lema: Main\n",
      "Lexema: Main\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: Street\n",
      "Lema: Street\n",
      "Lexema: Street\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: suffers\n",
      "Lema: suffer\n",
      "Lexema: suffers\n",
      "Morfemas: {'Number': 'Sing', 'Person': '3', 'Tense': 'Pres', 'VerbForm': 'Fin'}\n",
      "\n",
      "Token: .\n",
      "Lema: .\n",
      "Lexema: .\n",
      "Morfemas: {'PunctType': 'Peri'}\n",
      "\n",
      "Token: \n",
      "\n",
      "Lema: \n",
      "\n",
      "Lexema: \n",
      "\n",
      "Morfemas: {}\n",
      "\n",
      "Token: In\n",
      "Lema: in\n",
      "Lexema: In\n",
      "Morfemas: {}\n",
      "\n",
      "Token: this\n",
      "Lema: this\n",
      "Lexema: this\n",
      "Morfemas: {'Number': 'Sing', 'PronType': 'Dem'}\n",
      "\n",
      "Token: country\n",
      "Lema: country\n",
      "Lexema: country\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: ,\n",
      "Lema: ,\n",
      "Lexema: ,\n",
      "Morfemas: {'PunctType': 'Comm'}\n",
      "\n",
      "Token: we\n",
      "Lema: we\n",
      "Lexema: we\n",
      "Morfemas: {'Case': 'Nom', 'Number': 'Plur', 'Person': '1', 'PronType': 'Prs'}\n",
      "\n",
      "Token: rise\n",
      "Lema: rise\n",
      "Lexema: rise\n",
      "Morfemas: {'Tense': 'Pres', 'VerbForm': 'Fin'}\n",
      "\n",
      "Token: or\n",
      "Lema: or\n",
      "Lexema: or\n",
      "Morfemas: {'ConjType': 'Cmp'}\n",
      "\n",
      "Token: fall\n",
      "Lema: fall\n",
      "Lexema: fall\n",
      "Morfemas: {'Tense': 'Pres', 'VerbForm': 'Fin'}\n",
      "\n",
      "Token: as\n",
      "Lema: as\n",
      "Lexema: as\n",
      "Morfemas: {}\n",
      "\n",
      "Token: one\n",
      "Lema: one\n",
      "Lexema: one\n",
      "Morfemas: {'NumType': 'Card'}\n",
      "\n",
      "Token: nation\n",
      "Lema: nation\n",
      "Lexema: nation\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: ,\n",
      "Lema: ,\n",
      "Lexema: ,\n",
      "Morfemas: {'PunctType': 'Comm'}\n",
      "\n",
      "Token: as\n",
      "Lema: as\n",
      "Lexema: as\n",
      "Morfemas: {}\n",
      "\n",
      "Token: one\n",
      "Lema: one\n",
      "Lexema: one\n",
      "Morfemas: {'NumType': 'Card'}\n",
      "\n",
      "Token: people\n",
      "Lema: people\n",
      "Lexema: people\n",
      "Morfemas: {'Number': 'Plur'}\n",
      "\n",
      "Token: .\n",
      "Lema: .\n",
      "Lexema: .\n",
      "Morfemas: {'PunctType': 'Peri'}\n",
      "\n",
      "Token: Let\n",
      "Lema: let\n",
      "Lexema: Let\n",
      "Morfemas: {'VerbForm': 'Inf'}\n",
      "\n",
      "Token: ’s\n",
      "Lema: ’s\n",
      "Lexema: ’s\n",
      "Morfemas: {'PronType': 'Prs'}\n",
      "\n",
      "Token: resist\n",
      "Lema: resist\n",
      "Lexema: resist\n",
      "Morfemas: {'VerbForm': 'Inf'}\n",
      "\n",
      "Token: the\n",
      "Lema: the\n",
      "Lexema: the\n",
      "Morfemas: {'Definite': 'Def', 'PronType': 'Art'}\n",
      "\n",
      "Token: temptation\n",
      "Lema: temptation\n",
      "Lexema: temptation\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: to\n",
      "Lema: to\n",
      "Lexema: to\n",
      "Morfemas: {}\n",
      "\n",
      "Token: fall\n",
      "Lema: fall\n",
      "Lexema: fall\n",
      "Morfemas: {'VerbForm': 'Inf'}\n",
      "\n",
      "Token: back\n",
      "Lema: back\n",
      "Lexema: back\n",
      "Morfemas: {}\n",
      "\n",
      "Token: on\n",
      "Lema: on\n",
      "Lexema: on\n",
      "Morfemas: {}\n",
      "\n",
      "Token: the\n",
      "Lema: the\n",
      "Lexema: the\n",
      "Morfemas: {'Definite': 'Def', 'PronType': 'Art'}\n",
      "\n",
      "Token: same\n",
      "Lema: same\n",
      "Lexema: same\n",
      "Morfemas: {'Degree': 'Pos'}\n",
      "\n",
      "Token: partisanship\n",
      "Lema: partisanship\n",
      "Lexema: partisanship\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: and\n",
      "Lema: and\n",
      "Lexema: and\n",
      "Morfemas: {'ConjType': 'Cmp'}\n",
      "\n",
      "Token: pettiness\n",
      "Lema: pettiness\n",
      "Lexema: pettiness\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: and\n",
      "Lema: and\n",
      "Lexema: and\n",
      "Morfemas: {'ConjType': 'Cmp'}\n",
      "\n",
      "Token: immaturity\n",
      "Lema: immaturity\n",
      "Lexema: immaturity\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: that\n",
      "Lema: that\n",
      "Lexema: that\n",
      "Morfemas: {'PronType': 'Rel'}\n",
      "\n",
      "Token: has\n",
      "Lema: have\n",
      "Lexema: has\n",
      "Morfemas: {'Mood': 'Ind', 'Number': 'Sing', 'Person': '3', 'Tense': 'Pres', 'VerbForm': 'Fin'}\n",
      "\n",
      "Token: poisoned\n",
      "Lema: poison\n",
      "Lexema: poisoned\n",
      "Morfemas: {'Aspect': 'Perf', 'Tense': 'Past', 'VerbForm': 'Part'}\n",
      "\n",
      "Token: our\n",
      "Lema: our\n",
      "Lexema: our\n",
      "Morfemas: {'Number': 'Plur', 'Person': '1', 'Poss': 'Yes', 'PronType': 'Prs'}\n",
      "\n",
      "Token: politics\n",
      "Lema: politic\n",
      "Lexema: politics\n",
      "Morfemas: {'Number': 'Plur'}\n",
      "\n",
      "Token: for\n",
      "Lema: for\n",
      "Lexema: for\n",
      "Morfemas: {}\n",
      "\n",
      "Token: so\n",
      "Lema: so\n",
      "Lexema: so\n",
      "Morfemas: {}\n",
      "\n",
      "Token: long\n",
      "Lema: long\n",
      "Lexema: long\n",
      "Morfemas: {}\n",
      "\n",
      "Token: .\n",
      "Lema: .\n",
      "Lexema: .\n",
      "Morfemas: {'PunctType': 'Peri'}\n",
      "\n",
      "Token: \n",
      "\n",
      "Lema: \n",
      "\n",
      "Lexema: \n",
      "\n",
      "Morfemas: {}\n",
      "\n",
      "Token: Let\n",
      "Lema: let\n",
      "Lexema: Let\n",
      "Morfemas: {'VerbForm': 'Inf'}\n",
      "\n",
      "Token: ’s\n",
      "Lema: ’s\n",
      "Lexema: ’s\n",
      "Morfemas: {'PronType': 'Prs'}\n",
      "\n",
      "Token: remember\n",
      "Lema: remember\n",
      "Lexema: remember\n",
      "Morfemas: {'VerbForm': 'Inf'}\n",
      "\n",
      "Token: that\n",
      "Lema: that\n",
      "Lexema: that\n",
      "Morfemas: {}\n",
      "\n",
      "Token: it\n",
      "Lema: it\n",
      "Lexema: it\n",
      "Morfemas: {'Case': 'Nom', 'Gender': 'Neut', 'Number': 'Sing', 'Person': '3', 'PronType': 'Prs'}\n",
      "\n",
      "Token: was\n",
      "Lema: be\n",
      "Lexema: was\n",
      "Morfemas: {'Mood': 'Ind', 'Number': 'Sing', 'Person': '3', 'Tense': 'Past', 'VerbForm': 'Fin'}\n",
      "\n",
      "Token: a\n",
      "Lema: a\n",
      "Lexema: a\n",
      "Morfemas: {'Definite': 'Ind', 'PronType': 'Art'}\n",
      "\n",
      "Token: man\n",
      "Lema: man\n",
      "Lexema: man\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: from\n",
      "Lema: from\n",
      "Lexema: from\n",
      "Morfemas: {}\n",
      "\n",
      "Token: this\n",
      "Lema: this\n",
      "Lexema: this\n",
      "Morfemas: {'Number': 'Sing', 'PronType': 'Dem'}\n",
      "\n",
      "Token: state\n",
      "Lema: state\n",
      "Lexema: state\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: who\n",
      "Lema: who\n",
      "Lexema: who\n",
      "Morfemas: {}\n",
      "\n",
      "Token: first\n",
      "Lema: first\n",
      "Lexema: first\n",
      "Morfemas: {}\n",
      "\n",
      "Token: carried\n",
      "Lema: carry\n",
      "Lexema: carried\n",
      "Morfemas: {'Tense': 'Past', 'VerbForm': 'Fin'}\n",
      "\n",
      "Token: the\n",
      "Lema: the\n",
      "Lexema: the\n",
      "Morfemas: {'Definite': 'Def', 'PronType': 'Art'}\n",
      "\n",
      "Token: banner\n",
      "Lema: banner\n",
      "Lexema: banner\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: of\n",
      "Lema: of\n",
      "Lexema: of\n",
      "Morfemas: {}\n",
      "\n",
      "Token: the\n",
      "Lema: the\n",
      "Lexema: the\n",
      "Morfemas: {'Definite': 'Def', 'PronType': 'Art'}\n",
      "\n",
      "Token: Republican\n",
      "Lema: Republican\n",
      "Lexema: Republican\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: Party\n",
      "Lema: Party\n",
      "Lexema: Party\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: to\n",
      "Lema: to\n",
      "Lexema: to\n",
      "Morfemas: {}\n",
      "\n",
      "Token: the\n",
      "Lema: the\n",
      "Lexema: the\n",
      "Morfemas: {'Definite': 'Def', 'PronType': 'Art'}\n",
      "\n",
      "Token: White\n",
      "Lema: White\n",
      "Lexema: White\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: House\n",
      "Lema: House\n",
      "Lexema: House\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: ,\n",
      "Lema: ,\n",
      "Lexema: ,\n",
      "Morfemas: {'PunctType': 'Comm'}\n",
      "\n",
      "Token: a\n",
      "Lema: a\n",
      "Lexema: a\n",
      "Morfemas: {'Definite': 'Ind', 'PronType': 'Art'}\n",
      "\n",
      "Token: party\n",
      "Lema: party\n",
      "Lexema: party\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: founded\n",
      "Lema: found\n",
      "Lexema: founded\n",
      "Morfemas: {'Aspect': 'Perf', 'Tense': 'Past', 'VerbForm': 'Part'}\n",
      "\n",
      "Token: on\n",
      "Lema: on\n",
      "Lexema: on\n",
      "Morfemas: {}\n",
      "\n",
      "Token: the\n",
      "Lema: the\n",
      "Lexema: the\n",
      "Morfemas: {'Definite': 'Def', 'PronType': 'Art'}\n",
      "\n",
      "Token: values\n",
      "Lema: value\n",
      "Lexema: values\n",
      "Morfemas: {'Number': 'Plur'}\n",
      "\n",
      "Token: of\n",
      "Lema: of\n",
      "Lexema: of\n",
      "Morfemas: {}\n",
      "\n",
      "Token: self\n",
      "Lema: self\n",
      "Lexema: self\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: -\n",
      "Lema: -\n",
      "Lexema: -\n",
      "Morfemas: {'PunctType': 'Dash'}\n",
      "\n",
      "Token: reliance\n",
      "Lema: reliance\n",
      "Lexema: reliance\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: and\n",
      "Lema: and\n",
      "Lexema: and\n",
      "Morfemas: {'ConjType': 'Cmp'}\n",
      "\n",
      "Token: individual\n",
      "Lema: individual\n",
      "Lexema: individual\n",
      "Morfemas: {'Degree': 'Pos'}\n",
      "\n",
      "Token: liberty\n",
      "Lema: liberty\n",
      "Lexema: liberty\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: and\n",
      "Lema: and\n",
      "Lexema: and\n",
      "Morfemas: {'ConjType': 'Cmp'}\n",
      "\n",
      "Token: national\n",
      "Lema: national\n",
      "Lexema: national\n",
      "Morfemas: {'Degree': 'Pos'}\n",
      "\n",
      "Token: unity\n",
      "Lema: unity\n",
      "Lexema: unity\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: .\n",
      "Lema: .\n",
      "Lexema: .\n",
      "Morfemas: {'PunctType': 'Peri'}\n",
      "\n",
      "Token: \n",
      "\n",
      "Lema: \n",
      "\n",
      "Lexema: \n",
      "\n",
      "Morfemas: {}\n",
      "\n",
      "Token: Those\n",
      "Lema: those\n",
      "Lexema: Those\n",
      "Morfemas: {'Number': 'Plur', 'PronType': 'Dem'}\n",
      "\n",
      "Token: are\n",
      "Lema: be\n",
      "Lexema: are\n",
      "Morfemas: {'Mood': 'Ind', 'Tense': 'Pres', 'VerbForm': 'Fin'}\n",
      "\n",
      "Token: values\n",
      "Lema: value\n",
      "Lexema: values\n",
      "Morfemas: {'Number': 'Plur'}\n",
      "\n",
      "Token: that\n",
      "Lema: that\n",
      "Lexema: that\n",
      "Morfemas: {'PronType': 'Rel'}\n",
      "\n",
      "Token: we\n",
      "Lema: we\n",
      "Lexema: we\n",
      "Morfemas: {'Case': 'Nom', 'Number': 'Plur', 'Person': '1', 'PronType': 'Prs'}\n",
      "\n",
      "Token: all\n",
      "Lema: all\n",
      "Lexema: all\n",
      "Morfemas: {}\n",
      "\n",
      "Token: share\n",
      "Lema: share\n",
      "Lexema: share\n",
      "Morfemas: {'Tense': 'Pres', 'VerbForm': 'Fin'}\n",
      "\n",
      "Token: .\n",
      "Lema: .\n",
      "Lexema: .\n",
      "Morfemas: {'PunctType': 'Peri'}\n",
      "\n",
      "Token: And\n",
      "Lema: and\n",
      "Lexema: And\n",
      "Morfemas: {'ConjType': 'Cmp'}\n",
      "\n",
      "Token: while\n",
      "Lema: while\n",
      "Lexema: while\n",
      "Morfemas: {}\n",
      "\n",
      "Token: the\n",
      "Lema: the\n",
      "Lexema: the\n",
      "Morfemas: {'Definite': 'Def', 'PronType': 'Art'}\n",
      "\n",
      "Token: Democratic\n",
      "Lema: Democratic\n",
      "Lexema: Democratic\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: Party\n",
      "Lema: Party\n",
      "Lexema: Party\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: has\n",
      "Lema: have\n",
      "Lexema: has\n",
      "Morfemas: {'Mood': 'Ind', 'Number': 'Sing', 'Person': '3', 'Tense': 'Pres', 'VerbForm': 'Fin'}\n",
      "\n",
      "Token: won\n",
      "Lema: win\n",
      "Lexema: won\n",
      "Morfemas: {'Aspect': 'Perf', 'Tense': 'Past', 'VerbForm': 'Part'}\n",
      "\n",
      "Token: a\n",
      "Lema: a\n",
      "Lexema: a\n",
      "Morfemas: {'Definite': 'Ind', 'PronType': 'Art'}\n",
      "\n",
      "Token: great\n",
      "Lema: great\n",
      "Lexema: great\n",
      "Morfemas: {'Degree': 'Pos'}\n",
      "\n",
      "Token: victory\n",
      "Lema: victory\n",
      "Lexema: victory\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: tonight\n",
      "Lema: tonight\n",
      "Lexema: tonight\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: ,\n",
      "Lema: ,\n",
      "Lexema: ,\n",
      "Morfemas: {'PunctType': 'Comm'}\n",
      "\n",
      "Token: we\n",
      "Lema: we\n",
      "Lexema: we\n",
      "Morfemas: {'Case': 'Nom', 'Number': 'Plur', 'Person': '1', 'PronType': 'Prs'}\n",
      "\n",
      "Token: do\n",
      "Lema: do\n",
      "Lexema: do\n",
      "Morfemas: {'Mood': 'Ind', 'Tense': 'Pres', 'VerbForm': 'Fin'}\n",
      "\n",
      "Token: so\n",
      "Lema: so\n",
      "Lexema: so\n",
      "Morfemas: {}\n",
      "\n",
      "Token: with\n",
      "Lema: with\n",
      "Lexema: with\n",
      "Morfemas: {}\n",
      "\n",
      "Token: a\n",
      "Lema: a\n",
      "Lexema: a\n",
      "Morfemas: {'Definite': 'Ind', 'PronType': 'Art'}\n",
      "\n",
      "Token: measure\n",
      "Lema: measure\n",
      "Lexema: measure\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: of\n",
      "Lema: of\n",
      "Lexema: of\n",
      "Morfemas: {}\n",
      "\n",
      "Token: humility\n",
      "Lema: humility\n",
      "Lexema: humility\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: and\n",
      "Lema: and\n",
      "Lexema: and\n",
      "Morfemas: {'ConjType': 'Cmp'}\n",
      "\n",
      "Token: determination\n",
      "Lema: determination\n",
      "Lexema: determination\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: to\n",
      "Lema: to\n",
      "Lexema: to\n",
      "Morfemas: {}\n",
      "\n",
      "Token: heal\n",
      "Lema: heal\n",
      "Lexema: heal\n",
      "Morfemas: {'VerbForm': 'Inf'}\n",
      "\n",
      "Token: the\n",
      "Lema: the\n",
      "Lexema: the\n",
      "Morfemas: {'Definite': 'Def', 'PronType': 'Art'}\n",
      "\n",
      "Token: divides\n",
      "Lema: divide\n",
      "Lexema: divides\n",
      "Morfemas: {'Number': 'Plur'}\n",
      "\n",
      "Token: that\n",
      "Lema: that\n",
      "Lexema: that\n",
      "Morfemas: {'PronType': 'Rel'}\n",
      "\n",
      "Token: have\n",
      "Lema: have\n",
      "Lexema: have\n",
      "Morfemas: {'Mood': 'Ind', 'Tense': 'Pres', 'VerbForm': 'Fin'}\n",
      "\n",
      "Token: held\n",
      "Lema: hold\n",
      "Lexema: held\n",
      "Morfemas: {'Aspect': 'Perf', 'Tense': 'Past', 'VerbForm': 'Part'}\n",
      "\n",
      "Token: back\n",
      "Lema: back\n",
      "Lexema: back\n",
      "Morfemas: {}\n",
      "\n",
      "Token: our\n",
      "Lema: our\n",
      "Lexema: our\n",
      "Morfemas: {'Number': 'Plur', 'Person': '1', 'Poss': 'Yes', 'PronType': 'Prs'}\n",
      "\n",
      "Token: progress\n",
      "Lema: progress\n",
      "Lexema: progress\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: .\n",
      "Lema: .\n",
      "Lexema: .\n",
      "Morfemas: {'PunctType': 'Peri'}\n",
      "\n",
      "Token: \n",
      "\n",
      "Lema: \n",
      "\n",
      "Lexema: \n",
      "\n",
      "Morfemas: {}\n",
      "\n",
      "Token: As\n",
      "Lema: as\n",
      "Lexema: As\n",
      "Morfemas: {}\n",
      "\n",
      "Token: Lincoln\n",
      "Lema: Lincoln\n",
      "Lexema: Lincoln\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: said\n",
      "Lema: say\n",
      "Lexema: said\n",
      "Morfemas: {'Tense': 'Past', 'VerbForm': 'Fin'}\n",
      "\n",
      "Token: to\n",
      "Lema: to\n",
      "Lexema: to\n",
      "Morfemas: {}\n",
      "\n",
      "Token: a\n",
      "Lema: a\n",
      "Lexema: a\n",
      "Morfemas: {'Definite': 'Ind', 'PronType': 'Art'}\n",
      "\n",
      "Token: nation\n",
      "Lema: nation\n",
      "Lexema: nation\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: far\n",
      "Lema: far\n",
      "Lexema: far\n",
      "Morfemas: {}\n",
      "\n",
      "Token: more\n",
      "Lema: more\n",
      "Lexema: more\n",
      "Morfemas: {'Degree': 'Cmp'}\n",
      "\n",
      "Token: divided\n",
      "Lema: divided\n",
      "Lexema: divided\n",
      "Morfemas: {'Degree': 'Pos'}\n",
      "\n",
      "Token: than\n",
      "Lema: than\n",
      "Lexema: than\n",
      "Morfemas: {}\n",
      "\n",
      "Token: ours\n",
      "Lema: our\n",
      "Lexema: ours\n",
      "Morfemas: {'Number': 'Plur'}\n",
      "\n",
      "Token: ,\n",
      "Lema: ,\n",
      "Lexema: ,\n",
      "Morfemas: {'PunctType': 'Comm'}\n",
      "\n",
      "Token: we\n",
      "Lema: we\n",
      "Lexema: we\n",
      "Morfemas: {'Case': 'Nom', 'Number': 'Plur', 'Person': '1', 'PronType': 'Prs'}\n",
      "\n",
      "Token: are\n",
      "Lema: be\n",
      "Lexema: are\n",
      "Morfemas: {'Mood': 'Ind', 'Tense': 'Pres', 'VerbForm': 'Fin'}\n",
      "\n",
      "Token: not\n",
      "Lema: not\n",
      "Lexema: not\n",
      "Morfemas: {'Polarity': 'Neg'}\n",
      "\n",
      "Token: enemies\n",
      "Lema: enemy\n",
      "Lexema: enemies\n",
      "Morfemas: {'Number': 'Plur'}\n",
      "\n",
      "Token: but\n",
      "Lema: but\n",
      "Lexema: but\n",
      "Morfemas: {'ConjType': 'Cmp'}\n",
      "\n",
      "Token: friends\n",
      "Lema: friend\n",
      "Lexema: friends\n",
      "Morfemas: {'Number': 'Plur'}\n",
      "\n",
      "Token: .\n",
      "Lema: .\n",
      "Lexema: .\n",
      "Morfemas: {'PunctType': 'Peri'}\n",
      "\n",
      "Token: Though\n",
      "Lema: though\n",
      "Lexema: Though\n",
      "Morfemas: {}\n",
      "\n",
      "Token: passion\n",
      "Lema: passion\n",
      "Lexema: passion\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: may\n",
      "Lema: may\n",
      "Lexema: may\n",
      "Morfemas: {'VerbForm': 'Fin'}\n",
      "\n",
      "Token: have\n",
      "Lema: have\n",
      "Lexema: have\n",
      "Morfemas: {'VerbForm': 'Inf'}\n",
      "\n",
      "Token: strained\n",
      "Lema: strain\n",
      "Lexema: strained\n",
      "Morfemas: {'Aspect': 'Perf', 'Tense': 'Past', 'VerbForm': 'Part'}\n",
      "\n",
      "Token: ,\n",
      "Lema: ,\n",
      "Lexema: ,\n",
      "Morfemas: {'PunctType': 'Comm'}\n",
      "\n",
      "Token: it\n",
      "Lema: it\n",
      "Lexema: it\n",
      "Morfemas: {'Case': 'Nom', 'Gender': 'Neut', 'Number': 'Sing', 'Person': '3', 'PronType': 'Prs'}\n",
      "\n",
      "Token: must\n",
      "Lema: must\n",
      "Lexema: must\n",
      "Morfemas: {'VerbForm': 'Fin'}\n",
      "\n",
      "Token: not\n",
      "Lema: not\n",
      "Lexema: not\n",
      "Morfemas: {'Polarity': 'Neg'}\n",
      "\n",
      "Token: break\n",
      "Lema: break\n",
      "Lexema: break\n",
      "Morfemas: {'VerbForm': 'Inf'}\n",
      "\n",
      "Token: our\n",
      "Lema: our\n",
      "Lexema: our\n",
      "Morfemas: {'Number': 'Plur', 'Person': '1', 'Poss': 'Yes', 'PronType': 'Prs'}\n",
      "\n",
      "Token: bonds\n",
      "Lema: bond\n",
      "Lexema: bonds\n",
      "Morfemas: {'Number': 'Plur'}\n",
      "\n",
      "Token: of\n",
      "Lema: of\n",
      "Lexema: of\n",
      "Morfemas: {}\n",
      "\n",
      "Token: affection\n",
      "Lema: affection\n",
      "Lexema: affection\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: .\n",
      "Lema: .\n",
      "Lexema: .\n",
      "Morfemas: {'PunctType': 'Peri'}\n",
      "\n",
      "Token: \n",
      "\n",
      "Lema: \n",
      "\n",
      "Lexema: \n",
      "\n",
      "Morfemas: {}\n",
      "\n",
      "Token: And\n",
      "Lema: and\n",
      "Lexema: And\n",
      "Morfemas: {'ConjType': 'Cmp'}\n",
      "\n",
      "Token: to\n",
      "Lema: to\n",
      "Lexema: to\n",
      "Morfemas: {}\n",
      "\n",
      "Token: those\n",
      "Lema: those\n",
      "Lexema: those\n",
      "Morfemas: {'Number': 'Plur', 'PronType': 'Dem'}\n",
      "\n",
      "Token: Americans\n",
      "Lema: Americans\n",
      "Lexema: Americans\n",
      "Morfemas: {'Number': 'Plur'}\n",
      "\n",
      "Token: whose\n",
      "Lema: whose\n",
      "Lexema: whose\n",
      "Morfemas: {'Poss': 'Yes'}\n",
      "\n",
      "Token: support\n",
      "Lema: support\n",
      "Lexema: support\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: I\n",
      "Lema: I\n",
      "Lexema: I\n",
      "Morfemas: {'Case': 'Nom', 'Number': 'Sing', 'Person': '1', 'PronType': 'Prs'}\n",
      "\n",
      "Token: have\n",
      "Lema: have\n",
      "Lexema: have\n",
      "Morfemas: {'Mood': 'Ind', 'Tense': 'Pres', 'VerbForm': 'Fin'}\n",
      "\n",
      "Token: yet\n",
      "Lema: yet\n",
      "Lexema: yet\n",
      "Morfemas: {}\n",
      "\n",
      "Token: to\n",
      "Lema: to\n",
      "Lexema: to\n",
      "Morfemas: {}\n",
      "\n",
      "Token: earn\n",
      "Lema: earn\n",
      "Lexema: earn\n",
      "Morfemas: {'VerbForm': 'Inf'}\n",
      "\n",
      "Token: ,\n",
      "Lema: ,\n",
      "Lexema: ,\n",
      "Morfemas: {'PunctType': 'Comm'}\n",
      "\n",
      "Token: I\n",
      "Lema: I\n",
      "Lexema: I\n",
      "Morfemas: {'Case': 'Nom', 'Number': 'Sing', 'Person': '1', 'PronType': 'Prs'}\n",
      "\n",
      "Token: may\n",
      "Lema: may\n",
      "Lexema: may\n",
      "Morfemas: {'VerbForm': 'Fin'}\n",
      "\n",
      "Token: not\n",
      "Lema: not\n",
      "Lexema: not\n",
      "Morfemas: {'Polarity': 'Neg'}\n",
      "\n",
      "Token: have\n",
      "Lema: have\n",
      "Lexema: have\n",
      "Morfemas: {'VerbForm': 'Inf'}\n",
      "\n",
      "Token: won\n",
      "Lema: win\n",
      "Lexema: won\n",
      "Morfemas: {'Aspect': 'Perf', 'Tense': 'Past', 'VerbForm': 'Part'}\n",
      "\n",
      "Token: your\n",
      "Lema: your\n",
      "Lexema: your\n",
      "Morfemas: {'Person': '2', 'Poss': 'Yes', 'PronType': 'Prs'}\n",
      "\n",
      "Token: vote\n",
      "Lema: vote\n",
      "Lexema: vote\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: tonight\n",
      "Lema: tonight\n",
      "Lexema: tonight\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: ,\n",
      "Lema: ,\n",
      "Lexema: ,\n",
      "Morfemas: {'PunctType': 'Comm'}\n",
      "\n",
      "Token: but\n",
      "Lema: but\n",
      "Lexema: but\n",
      "Morfemas: {'ConjType': 'Cmp'}\n",
      "\n",
      "Token: I\n",
      "Lema: I\n",
      "Lexema: I\n",
      "Morfemas: {'Case': 'Nom', 'Number': 'Sing', 'Person': '1', 'PronType': 'Prs'}\n",
      "\n",
      "Token: hear\n",
      "Lema: hear\n",
      "Lexema: hear\n",
      "Morfemas: {'Tense': 'Pres', 'VerbForm': 'Fin'}\n",
      "\n",
      "Token: your\n",
      "Lema: your\n",
      "Lexema: your\n",
      "Morfemas: {'Person': '2', 'Poss': 'Yes', 'PronType': 'Prs'}\n",
      "\n",
      "Token: voices\n",
      "Lema: voice\n",
      "Lexema: voices\n",
      "Morfemas: {'Number': 'Plur'}\n",
      "\n",
      "Token: .\n",
      "Lema: .\n",
      "Lexema: .\n",
      "Morfemas: {'PunctType': 'Peri'}\n",
      "\n",
      "Token: I\n",
      "Lema: I\n",
      "Lexema: I\n",
      "Morfemas: {'Case': 'Nom', 'Number': 'Sing', 'Person': '1', 'PronType': 'Prs'}\n",
      "\n",
      "Token: need\n",
      "Lema: need\n",
      "Lexema: need\n",
      "Morfemas: {'Tense': 'Pres', 'VerbForm': 'Fin'}\n",
      "\n",
      "Token: your\n",
      "Lema: your\n",
      "Lexema: your\n",
      "Morfemas: {'Person': '2', 'Poss': 'Yes', 'PronType': 'Prs'}\n",
      "\n",
      "Token: help\n",
      "Lema: help\n",
      "Lexema: help\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: .\n",
      "Lema: .\n",
      "Lexema: .\n",
      "Morfemas: {'PunctType': 'Peri'}\n",
      "\n",
      "Token: And\n",
      "Lema: and\n",
      "Lexema: And\n",
      "Morfemas: {'ConjType': 'Cmp'}\n",
      "\n",
      "Token: I\n",
      "Lema: I\n",
      "Lexema: I\n",
      "Morfemas: {'Case': 'Nom', 'Number': 'Sing', 'Person': '1', 'PronType': 'Prs'}\n",
      "\n",
      "Token: will\n",
      "Lema: will\n",
      "Lexema: will\n",
      "Morfemas: {'VerbForm': 'Fin'}\n",
      "\n",
      "Token: be\n",
      "Lema: be\n",
      "Lexema: be\n",
      "Morfemas: {'VerbForm': 'Inf'}\n",
      "\n",
      "Token: your\n",
      "Lema: your\n",
      "Lexema: your\n",
      "Morfemas: {'Person': '2', 'Poss': 'Yes', 'PronType': 'Prs'}\n",
      "\n",
      "Token: president\n",
      "Lema: president\n",
      "Lexema: president\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: ,\n",
      "Lema: ,\n",
      "Lexema: ,\n",
      "Morfemas: {'PunctType': 'Comm'}\n",
      "\n",
      "Token: too\n",
      "Lema: too\n",
      "Lexema: too\n",
      "Morfemas: {}\n",
      "\n",
      "Token: .\n",
      "Lema: .\n",
      "Lexema: .\n",
      "Morfemas: {'PunctType': 'Peri'}\n",
      "\n",
      "Token: \n",
      "\n",
      "Lema: \n",
      "\n",
      "Lexema: \n",
      "\n",
      "Morfemas: {}\n",
      "\n",
      "Token: And\n",
      "Lema: and\n",
      "Lexema: And\n",
      "Morfemas: {'ConjType': 'Cmp'}\n",
      "\n",
      "Token: to\n",
      "Lema: to\n",
      "Lexema: to\n",
      "Morfemas: {}\n",
      "\n",
      "Token: all\n",
      "Lema: all\n",
      "Lexema: all\n",
      "Morfemas: {}\n",
      "\n",
      "Token: those\n",
      "Lema: those\n",
      "Lexema: those\n",
      "Morfemas: {'Number': 'Plur', 'PronType': 'Dem'}\n",
      "\n",
      "Token: watching\n",
      "Lema: watch\n",
      "Lexema: watching\n",
      "Morfemas: {'Aspect': 'Prog', 'Tense': 'Pres', 'VerbForm': 'Part'}\n",
      "\n",
      "Token: tonight\n",
      "Lema: tonight\n",
      "Lexema: tonight\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: from\n",
      "Lema: from\n",
      "Lexema: from\n",
      "Morfemas: {}\n",
      "\n",
      "Token: beyond\n",
      "Lema: beyond\n",
      "Lexema: beyond\n",
      "Morfemas: {}\n",
      "\n",
      "Token: our\n",
      "Lema: our\n",
      "Lexema: our\n",
      "Morfemas: {'Number': 'Plur', 'Person': '1', 'Poss': 'Yes', 'PronType': 'Prs'}\n",
      "\n",
      "Token: shores\n",
      "Lema: shore\n",
      "Lexema: shores\n",
      "Morfemas: {'Number': 'Plur'}\n",
      "\n",
      "Token: ,\n",
      "Lema: ,\n",
      "Lexema: ,\n",
      "Morfemas: {'PunctType': 'Comm'}\n",
      "\n",
      "Token: from\n",
      "Lema: from\n",
      "Lexema: from\n",
      "Morfemas: {}\n",
      "\n",
      "Token: parliaments\n",
      "Lema: parliament\n",
      "Lexema: parliaments\n",
      "Morfemas: {'Number': 'Plur'}\n",
      "\n",
      "Token: and\n",
      "Lema: and\n",
      "Lexema: and\n",
      "Morfemas: {'ConjType': 'Cmp'}\n",
      "\n",
      "Token: palaces\n",
      "Lema: palace\n",
      "Lexema: palaces\n",
      "Morfemas: {'Number': 'Plur'}\n",
      "\n",
      "Token: ,\n",
      "Lema: ,\n",
      "Lexema: ,\n",
      "Morfemas: {'PunctType': 'Comm'}\n",
      "\n",
      "Token: to\n",
      "Lema: to\n",
      "Lexema: to\n",
      "Morfemas: {}\n",
      "\n",
      "Token: those\n",
      "Lema: those\n",
      "Lexema: those\n",
      "Morfemas: {'Number': 'Plur', 'PronType': 'Dem'}\n",
      "\n",
      "Token: who\n",
      "Lema: who\n",
      "Lexema: who\n",
      "Morfemas: {}\n",
      "\n",
      "Token: are\n",
      "Lema: be\n",
      "Lexema: are\n",
      "Morfemas: {'Mood': 'Ind', 'Tense': 'Pres', 'VerbForm': 'Fin'}\n",
      "\n",
      "Token: huddled\n",
      "Lema: huddle\n",
      "Lexema: huddled\n",
      "Morfemas: {'Aspect': 'Perf', 'Tense': 'Past', 'VerbForm': 'Part'}\n",
      "\n",
      "Token: around\n",
      "Lema: around\n",
      "Lexema: around\n",
      "Morfemas: {}\n",
      "\n",
      "Token: radios\n",
      "Lema: radio\n",
      "Lexema: radios\n",
      "Morfemas: {'Number': 'Plur'}\n",
      "\n",
      "Token: in\n",
      "Lema: in\n",
      "Lexema: in\n",
      "Morfemas: {}\n",
      "\n",
      "Token: the\n",
      "Lema: the\n",
      "Lexema: the\n",
      "Morfemas: {'Definite': 'Def', 'PronType': 'Art'}\n",
      "\n",
      "Token: forgotten\n",
      "Lema: forget\n",
      "Lexema: forgotten\n",
      "Morfemas: {'Aspect': 'Perf', 'Tense': 'Past', 'VerbForm': 'Part'}\n",
      "\n",
      "Token: corners\n",
      "Lema: corner\n",
      "Lexema: corners\n",
      "Morfemas: {'Number': 'Plur'}\n",
      "\n",
      "Token: of\n",
      "Lema: of\n",
      "Lexema: of\n",
      "Morfemas: {}\n",
      "\n",
      "Token: the\n",
      "Lema: the\n",
      "Lexema: the\n",
      "Morfemas: {'Definite': 'Def', 'PronType': 'Art'}\n",
      "\n",
      "Token: world\n",
      "Lema: world\n",
      "Lexema: world\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: ,\n",
      "Lema: ,\n",
      "Lexema: ,\n",
      "Morfemas: {'PunctType': 'Comm'}\n",
      "\n",
      "Token: our\n",
      "Lema: our\n",
      "Lexema: our\n",
      "Morfemas: {'Number': 'Plur', 'Person': '1', 'Poss': 'Yes', 'PronType': 'Prs'}\n",
      "\n",
      "Token: stories\n",
      "Lema: story\n",
      "Lexema: stories\n",
      "Morfemas: {'Number': 'Plur'}\n",
      "\n",
      "Token: are\n",
      "Lema: be\n",
      "Lexema: are\n",
      "Morfemas: {'Mood': 'Ind', 'Tense': 'Pres', 'VerbForm': 'Fin'}\n",
      "\n",
      "Token: singular\n",
      "Lema: singular\n",
      "Lexema: singular\n",
      "Morfemas: {'Degree': 'Pos'}\n",
      "\n",
      "Token: ,\n",
      "Lema: ,\n",
      "Lexema: ,\n",
      "Morfemas: {'PunctType': 'Comm'}\n",
      "\n",
      "Token: but\n",
      "Lema: but\n",
      "Lexema: but\n",
      "Morfemas: {'ConjType': 'Cmp'}\n",
      "\n",
      "Token: our\n",
      "Lema: our\n",
      "Lexema: our\n",
      "Morfemas: {'Number': 'Plur', 'Person': '1', 'Poss': 'Yes', 'PronType': 'Prs'}\n",
      "\n",
      "Token: destiny\n",
      "Lema: destiny\n",
      "Lexema: destiny\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: is\n",
      "Lema: be\n",
      "Lexema: is\n",
      "Morfemas: {'Mood': 'Ind', 'Number': 'Sing', 'Person': '3', 'Tense': 'Pres', 'VerbForm': 'Fin'}\n",
      "\n",
      "Token: shared\n",
      "Lema: share\n",
      "Lexema: shared\n",
      "Morfemas: {'Aspect': 'Perf', 'Tense': 'Past', 'VerbForm': 'Part'}\n",
      "\n",
      "Token: ,\n",
      "Lema: ,\n",
      "Lexema: ,\n",
      "Morfemas: {'PunctType': 'Comm'}\n",
      "\n",
      "Token: and\n",
      "Lema: and\n",
      "Lexema: and\n",
      "Morfemas: {'ConjType': 'Cmp'}\n",
      "\n",
      "Token: a\n",
      "Lema: a\n",
      "Lexema: a\n",
      "Morfemas: {'Definite': 'Ind', 'PronType': 'Art'}\n",
      "\n",
      "Token: new\n",
      "Lema: new\n",
      "Lexema: new\n",
      "Morfemas: {'Degree': 'Pos'}\n",
      "\n",
      "Token: dawn\n",
      "Lema: dawn\n",
      "Lexema: dawn\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: of\n",
      "Lema: of\n",
      "Lexema: of\n",
      "Morfemas: {}\n",
      "\n",
      "Token: American\n",
      "Lema: american\n",
      "Lexema: American\n",
      "Morfemas: {'Degree': 'Pos'}\n",
      "\n",
      "Token: leadership\n",
      "Lema: leadership\n",
      "Lexema: leadership\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: is\n",
      "Lema: be\n",
      "Lexema: is\n",
      "Morfemas: {'Mood': 'Ind', 'Number': 'Sing', 'Person': '3', 'Tense': 'Pres', 'VerbForm': 'Fin'}\n",
      "\n",
      "Token: at\n",
      "Lema: at\n",
      "Lexema: at\n",
      "Morfemas: {}\n",
      "\n",
      "Token: hand\n",
      "Lema: hand\n",
      "Lexema: hand\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: .\n",
      "Lema: .\n",
      "Lexema: .\n",
      "Morfemas: {'PunctType': 'Peri'}\n",
      "\n",
      "Token: \n",
      "\n",
      "Lema: \n",
      "\n",
      "Lexema: \n",
      "\n",
      "Morfemas: {}\n",
      "\n",
      "Token: To\n",
      "Lema: to\n",
      "Lexema: To\n",
      "Morfemas: {}\n",
      "\n",
      "Token: those\n",
      "Lema: those\n",
      "Lexema: those\n",
      "Morfemas: {'Number': 'Plur', 'PronType': 'Dem'}\n",
      "\n",
      "Token: —\n",
      "Lema: —\n",
      "Lexema: —\n",
      "Morfemas: {}\n",
      "\n",
      "Token: to\n",
      "Lema: to\n",
      "Lexema: to\n",
      "Morfemas: {}\n",
      "\n",
      "Token: those\n",
      "Lema: those\n",
      "Lexema: those\n",
      "Morfemas: {'Number': 'Plur', 'PronType': 'Dem'}\n",
      "\n",
      "Token: who\n",
      "Lema: who\n",
      "Lexema: who\n",
      "Morfemas: {}\n",
      "\n",
      "Token: would\n",
      "Lema: would\n",
      "Lexema: would\n",
      "Morfemas: {'VerbForm': 'Fin'}\n",
      "\n",
      "Token: tear\n",
      "Lema: tear\n",
      "Lexema: tear\n",
      "Morfemas: {'VerbForm': 'Inf'}\n",
      "\n",
      "Token: the\n",
      "Lema: the\n",
      "Lexema: the\n",
      "Morfemas: {'Definite': 'Def', 'PronType': 'Art'}\n",
      "\n",
      "Token: world\n",
      "Lema: world\n",
      "Lexema: world\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: down\n",
      "Lema: down\n",
      "Lexema: down\n",
      "Morfemas: {}\n",
      "\n",
      "Token: :\n",
      "Lema: :\n",
      "Lexema: :\n",
      "Morfemas: {}\n",
      "\n",
      "Token: We\n",
      "Lema: we\n",
      "Lexema: We\n",
      "Morfemas: {'Case': 'Nom', 'Number': 'Plur', 'Person': '1', 'PronType': 'Prs'}\n",
      "\n",
      "Token: will\n",
      "Lema: will\n",
      "Lexema: will\n",
      "Morfemas: {'VerbForm': 'Fin'}\n",
      "\n",
      "Token: defeat\n",
      "Lema: defeat\n",
      "Lexema: defeat\n",
      "Morfemas: {'VerbForm': 'Inf'}\n",
      "\n",
      "Token: you\n",
      "Lema: you\n",
      "Lexema: you\n",
      "Morfemas: {'Case': 'Acc', 'Person': '2', 'PronType': 'Prs'}\n",
      "\n",
      "Token: .\n",
      "Lema: .\n",
      "Lexema: .\n",
      "Morfemas: {'PunctType': 'Peri'}\n",
      "\n",
      "Token: To\n",
      "Lema: to\n",
      "Lexema: To\n",
      "Morfemas: {}\n",
      "\n",
      "Token: those\n",
      "Lema: those\n",
      "Lexema: those\n",
      "Morfemas: {'Number': 'Plur', 'PronType': 'Dem'}\n",
      "\n",
      "Token: who\n",
      "Lema: who\n",
      "Lexema: who\n",
      "Morfemas: {}\n",
      "\n",
      "Token: seek\n",
      "Lema: seek\n",
      "Lexema: seek\n",
      "Morfemas: {'Tense': 'Pres', 'VerbForm': 'Fin'}\n",
      "\n",
      "Token: peace\n",
      "Lema: peace\n",
      "Lexema: peace\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: and\n",
      "Lema: and\n",
      "Lexema: and\n",
      "Morfemas: {'ConjType': 'Cmp'}\n",
      "\n",
      "Token: security\n",
      "Lema: security\n",
      "Lexema: security\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: :\n",
      "Lema: :\n",
      "Lexema: :\n",
      "Morfemas: {}\n",
      "\n",
      "Token: We\n",
      "Lema: we\n",
      "Lexema: We\n",
      "Morfemas: {'Case': 'Nom', 'Number': 'Plur', 'Person': '1', 'PronType': 'Prs'}\n",
      "\n",
      "Token: support\n",
      "Lema: support\n",
      "Lexema: support\n",
      "Morfemas: {'Tense': 'Pres', 'VerbForm': 'Fin'}\n",
      "\n",
      "Token: you\n",
      "Lema: you\n",
      "Lexema: you\n",
      "Morfemas: {'Case': 'Acc', 'Person': '2', 'PronType': 'Prs'}\n",
      "\n",
      "Token: .\n",
      "Lema: .\n",
      "Lexema: .\n",
      "Morfemas: {'PunctType': 'Peri'}\n",
      "\n",
      "Token: And\n",
      "Lema: and\n",
      "Lexema: And\n",
      "Morfemas: {'ConjType': 'Cmp'}\n",
      "\n",
      "Token: to\n",
      "Lema: to\n",
      "Lexema: to\n",
      "Morfemas: {}\n",
      "\n",
      "Token: all\n",
      "Lema: all\n",
      "Lexema: all\n",
      "Morfemas: {}\n",
      "\n",
      "Token: those\n",
      "Lema: those\n",
      "Lexema: those\n",
      "Morfemas: {'Number': 'Plur', 'PronType': 'Dem'}\n",
      "\n",
      "Token: who\n",
      "Lema: who\n",
      "Lexema: who\n",
      "Morfemas: {}\n",
      "\n",
      "Token: have\n",
      "Lema: have\n",
      "Lexema: have\n",
      "Morfemas: {'Mood': 'Ind', 'Tense': 'Pres', 'VerbForm': 'Fin'}\n",
      "\n",
      "Token: wondered\n",
      "Lema: wonder\n",
      "Lexema: wondered\n",
      "Morfemas: {'Aspect': 'Perf', 'Tense': 'Past', 'VerbForm': 'Part'}\n",
      "\n",
      "Token: if\n",
      "Lema: if\n",
      "Lexema: if\n",
      "Morfemas: {}\n",
      "\n",
      "Token: America\n",
      "Lema: America\n",
      "Lexema: America\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: ’s\n",
      "Lema: ’s\n",
      "Lexema: ’s\n",
      "Morfemas: {}\n",
      "\n",
      "Token: beacon\n",
      "Lema: beacon\n",
      "Lexema: beacon\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: still\n",
      "Lema: still\n",
      "Lexema: still\n",
      "Morfemas: {}\n",
      "\n",
      "Token: burns\n",
      "Lema: burn\n",
      "Lexema: burns\n",
      "Morfemas: {'Number': 'Sing', 'Person': '3', 'Tense': 'Pres', 'VerbForm': 'Fin'}\n",
      "\n",
      "Token: as\n",
      "Lema: as\n",
      "Lexema: as\n",
      "Morfemas: {}\n",
      "\n",
      "Token: bright\n",
      "Lema: bright\n",
      "Lexema: bright\n",
      "Morfemas: {'Degree': 'Pos'}\n",
      "\n",
      "Token: :\n",
      "Lema: :\n",
      "Lexema: :\n",
      "Morfemas: {}\n",
      "\n",
      "Token: Tonight\n",
      "Lema: tonight\n",
      "Lexema: Tonight\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: we\n",
      "Lema: we\n",
      "Lexema: we\n",
      "Morfemas: {'Case': 'Nom', 'Number': 'Plur', 'Person': '1', 'PronType': 'Prs'}\n",
      "\n",
      "Token: proved\n",
      "Lema: prove\n",
      "Lexema: proved\n",
      "Morfemas: {'Tense': 'Past', 'VerbForm': 'Fin'}\n",
      "\n",
      "Token: once\n",
      "Lema: once\n",
      "Lexema: once\n",
      "Morfemas: {'NumType': 'Mult'}\n",
      "\n",
      "Token: more\n",
      "Lema: more\n",
      "Lexema: more\n",
      "Morfemas: {'Degree': 'Cmp'}\n",
      "\n",
      "Token: that\n",
      "Lema: that\n",
      "Lexema: that\n",
      "Morfemas: {}\n",
      "\n",
      "Token: the\n",
      "Lema: the\n",
      "Lexema: the\n",
      "Morfemas: {'Definite': 'Def', 'PronType': 'Art'}\n",
      "\n",
      "Token: true\n",
      "Lema: true\n",
      "Lexema: true\n",
      "Morfemas: {'Degree': 'Pos'}\n",
      "\n",
      "Token: strength\n",
      "Lema: strength\n",
      "Lexema: strength\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: of\n",
      "Lema: of\n",
      "Lexema: of\n",
      "Morfemas: {}\n",
      "\n",
      "Token: our\n",
      "Lema: our\n",
      "Lexema: our\n",
      "Morfemas: {'Number': 'Plur', 'Person': '1', 'Poss': 'Yes', 'PronType': 'Prs'}\n",
      "\n",
      "Token: nation\n",
      "Lema: nation\n",
      "Lexema: nation\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: comes\n",
      "Lema: come\n",
      "Lexema: comes\n",
      "Morfemas: {'Number': 'Sing', 'Person': '3', 'Tense': 'Pres', 'VerbForm': 'Fin'}\n",
      "\n",
      "Token: not\n",
      "Lema: not\n",
      "Lexema: not\n",
      "Morfemas: {'Polarity': 'Neg'}\n",
      "\n",
      "Token: from\n",
      "Lema: from\n",
      "Lexema: from\n",
      "Morfemas: {}\n",
      "\n",
      "Token: the\n",
      "Lema: the\n",
      "Lexema: the\n",
      "Morfemas: {'Definite': 'Def', 'PronType': 'Art'}\n",
      "\n",
      "Token: might\n",
      "Lema: might\n",
      "Lexema: might\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: of\n",
      "Lema: of\n",
      "Lexema: of\n",
      "Morfemas: {}\n",
      "\n",
      "Token: our\n",
      "Lema: our\n",
      "Lexema: our\n",
      "Morfemas: {'Number': 'Plur', 'Person': '1', 'Poss': 'Yes', 'PronType': 'Prs'}\n",
      "\n",
      "Token: arms\n",
      "Lema: arm\n",
      "Lexema: arms\n",
      "Morfemas: {'Number': 'Plur'}\n",
      "\n",
      "Token: or\n",
      "Lema: or\n",
      "Lexema: or\n",
      "Morfemas: {'ConjType': 'Cmp'}\n",
      "\n",
      "Token: the\n",
      "Lema: the\n",
      "Lexema: the\n",
      "Morfemas: {'Definite': 'Def', 'PronType': 'Art'}\n",
      "\n",
      "Token: scale\n",
      "Lema: scale\n",
      "Lexema: scale\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: of\n",
      "Lema: of\n",
      "Lexema: of\n",
      "Morfemas: {}\n",
      "\n",
      "Token: our\n",
      "Lema: our\n",
      "Lexema: our\n",
      "Morfemas: {'Number': 'Plur', 'Person': '1', 'Poss': 'Yes', 'PronType': 'Prs'}\n",
      "\n",
      "Token: wealth\n",
      "Lema: wealth\n",
      "Lexema: wealth\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: ,\n",
      "Lema: ,\n",
      "Lexema: ,\n",
      "Morfemas: {'PunctType': 'Comm'}\n",
      "\n",
      "Token: but\n",
      "Lema: but\n",
      "Lexema: but\n",
      "Morfemas: {'ConjType': 'Cmp'}\n",
      "\n",
      "Token: from\n",
      "Lema: from\n",
      "Lexema: from\n",
      "Morfemas: {}\n",
      "\n",
      "Token: the\n",
      "Lema: the\n",
      "Lexema: the\n",
      "Morfemas: {'Definite': 'Def', 'PronType': 'Art'}\n",
      "\n",
      "Token: enduring\n",
      "Lema: endure\n",
      "Lexema: enduring\n",
      "Morfemas: {'Aspect': 'Prog', 'Tense': 'Pres', 'VerbForm': 'Part'}\n",
      "\n",
      "Token: power\n",
      "Lema: power\n",
      "Lexema: power\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: of\n",
      "Lema: of\n",
      "Lexema: of\n",
      "Morfemas: {}\n",
      "\n",
      "Token: our\n",
      "Lema: our\n",
      "Lexema: our\n",
      "Morfemas: {'Number': 'Plur', 'Person': '1', 'Poss': 'Yes', 'PronType': 'Prs'}\n",
      "\n",
      "Token: ideals\n",
      "Lema: ideal\n",
      "Lexema: ideals\n",
      "Morfemas: {'Number': 'Plur'}\n",
      "\n",
      "Token: :\n",
      "Lema: :\n",
      "Lexema: :\n",
      "Morfemas: {}\n",
      "\n",
      "Token: democracy\n",
      "Lema: democracy\n",
      "Lexema: democracy\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: ,\n",
      "Lema: ,\n",
      "Lexema: ,\n",
      "Morfemas: {'PunctType': 'Comm'}\n",
      "\n",
      "Token: liberty\n",
      "Lema: liberty\n",
      "Lexema: liberty\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: ,\n",
      "Lema: ,\n",
      "Lexema: ,\n",
      "Morfemas: {'PunctType': 'Comm'}\n",
      "\n",
      "Token: opportunity\n",
      "Lema: opportunity\n",
      "Lexema: opportunity\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: and\n",
      "Lema: and\n",
      "Lexema: and\n",
      "Morfemas: {'ConjType': 'Cmp'}\n",
      "\n",
      "Token: unyielding\n",
      "Lema: unyielde\n",
      "Lexema: unyielding\n",
      "Morfemas: {'Aspect': 'Prog', 'Tense': 'Pres', 'VerbForm': 'Part'}\n",
      "\n",
      "Token: hope\n",
      "Lema: hope\n",
      "Lexema: hope\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: .\n",
      "Lema: .\n",
      "Lexema: .\n",
      "Morfemas: {'PunctType': 'Peri'}\n",
      "\n",
      "Token: \n",
      "\n",
      "Lema: \n",
      "\n",
      "Lexema: \n",
      "\n",
      "Morfemas: {}\n",
      "\n",
      "Token: That\n",
      "Lema: that\n",
      "Lexema: That\n",
      "Morfemas: {'Number': 'Sing', 'PronType': 'Dem'}\n",
      "\n",
      "Token: ’s\n",
      "Lema: ’\n",
      "Lexema: ’s\n",
      "Morfemas: {'Number': 'Sing', 'Person': '3', 'Tense': 'Pres', 'VerbForm': 'Fin'}\n",
      "\n",
      "Token: the\n",
      "Lema: the\n",
      "Lexema: the\n",
      "Morfemas: {'Definite': 'Def', 'PronType': 'Art'}\n",
      "\n",
      "Token: true\n",
      "Lema: true\n",
      "Lexema: true\n",
      "Morfemas: {'Degree': 'Pos'}\n",
      "\n",
      "Token: genius\n",
      "Lema: genius\n",
      "Lexema: genius\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: of\n",
      "Lema: of\n",
      "Lexema: of\n",
      "Morfemas: {}\n",
      "\n",
      "Token: America\n",
      "Lema: America\n",
      "Lexema: America\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: :\n",
      "Lema: :\n",
      "Lexema: :\n",
      "Morfemas: {}\n",
      "\n",
      "Token: that\n",
      "Lema: that\n",
      "Lexema: that\n",
      "Morfemas: {}\n",
      "\n",
      "Token: America\n",
      "Lema: America\n",
      "Lexema: America\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: can\n",
      "Lema: can\n",
      "Lexema: can\n",
      "Morfemas: {'VerbForm': 'Fin'}\n",
      "\n",
      "Token: change\n",
      "Lema: change\n",
      "Lexema: change\n",
      "Morfemas: {'VerbForm': 'Inf'}\n",
      "\n",
      "Token: .\n",
      "Lema: .\n",
      "Lexema: .\n",
      "Morfemas: {'PunctType': 'Peri'}\n",
      "\n",
      "Token: Our\n",
      "Lema: our\n",
      "Lexema: Our\n",
      "Morfemas: {'Number': 'Plur', 'Person': '1', 'Poss': 'Yes', 'PronType': 'Prs'}\n",
      "\n",
      "Token: union\n",
      "Lema: union\n",
      "Lexema: union\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: can\n",
      "Lema: can\n",
      "Lexema: can\n",
      "Morfemas: {'VerbForm': 'Fin'}\n",
      "\n",
      "Token: be\n",
      "Lema: be\n",
      "Lexema: be\n",
      "Morfemas: {'VerbForm': 'Inf'}\n",
      "\n",
      "Token: perfected\n",
      "Lema: perfect\n",
      "Lexema: perfected\n",
      "Morfemas: {'Aspect': 'Perf', 'Tense': 'Past', 'VerbForm': 'Part'}\n",
      "\n",
      "Token: .\n",
      "Lema: .\n",
      "Lexema: .\n",
      "Morfemas: {'PunctType': 'Peri'}\n",
      "\n",
      "Token: What\n",
      "Lema: what\n",
      "Lexema: What\n",
      "Morfemas: {}\n",
      "\n",
      "Token: we\n",
      "Lema: we\n",
      "Lexema: we\n",
      "Morfemas: {'Case': 'Nom', 'Number': 'Plur', 'Person': '1', 'PronType': 'Prs'}\n",
      "\n",
      "Token: ’ve\n",
      "Lema: ’ve\n",
      "Lexema: ’ve\n",
      "Morfemas: {'Tense': 'Pres', 'VerbForm': 'Fin'}\n",
      "\n",
      "Token: already\n",
      "Lema: already\n",
      "Lexema: already\n",
      "Morfemas: {}\n",
      "\n",
      "Token: achieved\n",
      "Lema: achieve\n",
      "Lexema: achieved\n",
      "Morfemas: {'Aspect': 'Perf', 'Tense': 'Past', 'VerbForm': 'Part'}\n",
      "\n",
      "Token: gives\n",
      "Lema: give\n",
      "Lexema: gives\n",
      "Morfemas: {'Number': 'Sing', 'Person': '3', 'Tense': 'Pres', 'VerbForm': 'Fin'}\n",
      "\n",
      "Token: us\n",
      "Lema: we\n",
      "Lexema: us\n",
      "Morfemas: {'Case': 'Acc', 'Number': 'Plur', 'Person': '1', 'PronType': 'Prs'}\n",
      "\n",
      "Token: hope\n",
      "Lema: hope\n",
      "Lexema: hope\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: for\n",
      "Lema: for\n",
      "Lexema: for\n",
      "Morfemas: {}\n",
      "\n",
      "Token: what\n",
      "Lema: what\n",
      "Lexema: what\n",
      "Morfemas: {}\n",
      "\n",
      "Token: we\n",
      "Lema: we\n",
      "Lexema: we\n",
      "Morfemas: {'Case': 'Nom', 'Number': 'Plur', 'Person': '1', 'PronType': 'Prs'}\n",
      "\n",
      "Token: can\n",
      "Lema: can\n",
      "Lexema: can\n",
      "Morfemas: {'VerbForm': 'Fin'}\n",
      "\n",
      "Token: and\n",
      "Lema: and\n",
      "Lexema: and\n",
      "Morfemas: {'ConjType': 'Cmp'}\n",
      "\n",
      "Token: must\n",
      "Lema: must\n",
      "Lexema: must\n",
      "Morfemas: {'VerbForm': 'Fin'}\n",
      "\n",
      "Token: achieve\n",
      "Lema: achieve\n",
      "Lexema: achieve\n",
      "Morfemas: {'VerbForm': 'Inf'}\n",
      "\n",
      "Token: tomorrow\n",
      "Lema: tomorrow\n",
      "Lexema: tomorrow\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: .\n",
      "Lema: .\n",
      "Lexema: .\n",
      "Morfemas: {'PunctType': 'Peri'}\n",
      "\n",
      "Token: \n",
      "\n",
      "Lema: \n",
      "\n",
      "Lexema: \n",
      "\n",
      "Morfemas: {}\n",
      "\n",
      "Token: This\n",
      "Lema: this\n",
      "Lexema: This\n",
      "Morfemas: {'Number': 'Sing', 'PronType': 'Dem'}\n",
      "\n",
      "Token: election\n",
      "Lema: election\n",
      "Lexema: election\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: had\n",
      "Lema: have\n",
      "Lexema: had\n",
      "Morfemas: {'Tense': 'Past', 'VerbForm': 'Fin'}\n",
      "\n",
      "Token: many\n",
      "Lema: many\n",
      "Lexema: many\n",
      "Morfemas: {'Degree': 'Pos'}\n",
      "\n",
      "Token: firsts\n",
      "Lema: first\n",
      "Lexema: firsts\n",
      "Morfemas: {'Number': 'Plur'}\n",
      "\n",
      "Token: and\n",
      "Lema: and\n",
      "Lexema: and\n",
      "Morfemas: {'ConjType': 'Cmp'}\n",
      "\n",
      "Token: many\n",
      "Lema: many\n",
      "Lexema: many\n",
      "Morfemas: {'Degree': 'Pos'}\n",
      "\n",
      "Token: stories\n",
      "Lema: story\n",
      "Lexema: stories\n",
      "Morfemas: {'Number': 'Plur'}\n",
      "\n",
      "Token: that\n",
      "Lema: that\n",
      "Lexema: that\n",
      "Morfemas: {'PronType': 'Rel'}\n",
      "\n",
      "Token: will\n",
      "Lema: will\n",
      "Lexema: will\n",
      "Morfemas: {'VerbForm': 'Fin'}\n",
      "\n",
      "Token: be\n",
      "Lema: be\n",
      "Lexema: be\n",
      "Morfemas: {'VerbForm': 'Inf'}\n",
      "\n",
      "Token: told\n",
      "Lema: tell\n",
      "Lexema: told\n",
      "Morfemas: {'Aspect': 'Perf', 'Tense': 'Past', 'VerbForm': 'Part'}\n",
      "\n",
      "Token: for\n",
      "Lema: for\n",
      "Lexema: for\n",
      "Morfemas: {}\n",
      "\n",
      "Token: generations\n",
      "Lema: generation\n",
      "Lexema: generations\n",
      "Morfemas: {'Number': 'Plur'}\n",
      "\n",
      "Token: .\n",
      "Lema: .\n",
      "Lexema: .\n",
      "Morfemas: {'PunctType': 'Peri'}\n",
      "\n",
      "Token: But\n",
      "Lema: but\n",
      "Lexema: But\n",
      "Morfemas: {'ConjType': 'Cmp'}\n",
      "\n",
      "Token: one\n",
      "Lema: one\n",
      "Lexema: one\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: that\n",
      "Lema: that\n",
      "Lexema: that\n",
      "Morfemas: {'PronType': 'Rel'}\n",
      "\n",
      "Token: ’s\n",
      "Lema: ’\n",
      "Lexema: ’s\n",
      "Morfemas: {'Number': 'Sing', 'Person': '3', 'Tense': 'Pres', 'VerbForm': 'Fin'}\n",
      "\n",
      "Token: on\n",
      "Lema: on\n",
      "Lexema: on\n",
      "Morfemas: {}\n",
      "\n",
      "Token: my\n",
      "Lema: my\n",
      "Lexema: my\n",
      "Morfemas: {'Number': 'Sing', 'Person': '1', 'Poss': 'Yes', 'PronType': 'Prs'}\n",
      "\n",
      "Token: mind\n",
      "Lema: mind\n",
      "Lexema: mind\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: tonight\n",
      "Lema: tonight\n",
      "Lexema: tonight\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: ’s\n",
      "Lema: ’\n",
      "Lexema: ’s\n",
      "Morfemas: {'Number': 'Sing', 'Person': '3', 'Tense': 'Pres', 'VerbForm': 'Fin'}\n",
      "\n",
      "Token: about\n",
      "Lema: about\n",
      "Lexema: about\n",
      "Morfemas: {}\n",
      "\n",
      "Token: a\n",
      "Lema: a\n",
      "Lexema: a\n",
      "Morfemas: {'Definite': 'Ind', 'PronType': 'Art'}\n",
      "\n",
      "Token: woman\n",
      "Lema: woman\n",
      "Lexema: woman\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: who\n",
      "Lema: who\n",
      "Lexema: who\n",
      "Morfemas: {}\n",
      "\n",
      "Token: cast\n",
      "Lema: cast\n",
      "Lexema: cast\n",
      "Morfemas: {'Tense': 'Past', 'VerbForm': 'Fin'}\n",
      "\n",
      "Token: her\n",
      "Lema: her\n",
      "Lexema: her\n",
      "Morfemas: {'Gender': 'Fem', 'Number': 'Sing', 'Person': '3', 'Poss': 'Yes', 'PronType': 'Prs'}\n",
      "\n",
      "Token: ballot\n",
      "Lema: ballot\n",
      "Lexema: ballot\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: in\n",
      "Lema: in\n",
      "Lexema: in\n",
      "Morfemas: {}\n",
      "\n",
      "Token: Atlanta\n",
      "Lema: Atlanta\n",
      "Lexema: Atlanta\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: .\n",
      "Lema: .\n",
      "Lexema: .\n",
      "Morfemas: {'PunctType': 'Peri'}\n",
      "\n",
      "Token: She\n",
      "Lema: she\n",
      "Lexema: She\n",
      "Morfemas: {'Case': 'Nom', 'Gender': 'Fem', 'Number': 'Sing', 'Person': '3', 'PronType': 'Prs'}\n",
      "\n",
      "Token: ’s\n",
      "Lema: ’\n",
      "Lexema: ’s\n",
      "Morfemas: {'Number': 'Sing', 'Person': '3', 'Tense': 'Pres', 'VerbForm': 'Fin'}\n",
      "\n",
      "Token: a\n",
      "Lema: a\n",
      "Lexema: a\n",
      "Morfemas: {'Definite': 'Ind', 'PronType': 'Art'}\n",
      "\n",
      "Token: lot\n",
      "Lema: lot\n",
      "Lexema: lot\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: like\n",
      "Lema: like\n",
      "Lexema: like\n",
      "Morfemas: {}\n",
      "\n",
      "Token: the\n",
      "Lema: the\n",
      "Lexema: the\n",
      "Morfemas: {'Definite': 'Def', 'PronType': 'Art'}\n",
      "\n",
      "Token: millions\n",
      "Lema: million\n",
      "Lexema: millions\n",
      "Morfemas: {'Number': 'Plur'}\n",
      "\n",
      "Token: of\n",
      "Lema: of\n",
      "Lexema: of\n",
      "Morfemas: {}\n",
      "\n",
      "Token: others\n",
      "Lema: other\n",
      "Lexema: others\n",
      "Morfemas: {'Number': 'Plur'}\n",
      "\n",
      "Token: who\n",
      "Lema: who\n",
      "Lexema: who\n",
      "Morfemas: {}\n",
      "\n",
      "Token: stood\n",
      "Lema: stand\n",
      "Lexema: stood\n",
      "Morfemas: {'Tense': 'Past', 'VerbForm': 'Fin'}\n",
      "\n",
      "Token: in\n",
      "Lema: in\n",
      "Lexema: in\n",
      "Morfemas: {}\n",
      "\n",
      "Token: line\n",
      "Lema: line\n",
      "Lexema: line\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: to\n",
      "Lema: to\n",
      "Lexema: to\n",
      "Morfemas: {}\n",
      "\n",
      "Token: make\n",
      "Lema: make\n",
      "Lexema: make\n",
      "Morfemas: {'VerbForm': 'Inf'}\n",
      "\n",
      "Token: their\n",
      "Lema: their\n",
      "Lexema: their\n",
      "Morfemas: {'Number': 'Plur', 'Person': '3', 'Poss': 'Yes', 'PronType': 'Prs'}\n",
      "\n",
      "Token: voice\n",
      "Lema: voice\n",
      "Lexema: voice\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: heard\n",
      "Lema: hear\n",
      "Lexema: heard\n",
      "Morfemas: {'Aspect': 'Perf', 'Tense': 'Past', 'VerbForm': 'Part'}\n",
      "\n",
      "Token: in\n",
      "Lema: in\n",
      "Lexema: in\n",
      "Morfemas: {}\n",
      "\n",
      "Token: this\n",
      "Lema: this\n",
      "Lexema: this\n",
      "Morfemas: {'Number': 'Sing', 'PronType': 'Dem'}\n",
      "\n",
      "Token: election\n",
      "Lema: election\n",
      "Lexema: election\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: except\n",
      "Lema: except\n",
      "Lexema: except\n",
      "Morfemas: {}\n",
      "\n",
      "Token: for\n",
      "Lema: for\n",
      "Lexema: for\n",
      "Morfemas: {}\n",
      "\n",
      "Token: one\n",
      "Lema: one\n",
      "Lexema: one\n",
      "Morfemas: {'NumType': 'Card'}\n",
      "\n",
      "Token: thing\n",
      "Lema: thing\n",
      "Lexema: thing\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: :\n",
      "Lema: :\n",
      "Lexema: :\n",
      "Morfemas: {}\n",
      "\n",
      "Token: Ann\n",
      "Lema: Ann\n",
      "Lexema: Ann\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: Nixon\n",
      "Lema: Nixon\n",
      "Lexema: Nixon\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: Cooper\n",
      "Lema: Cooper\n",
      "Lexema: Cooper\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: is\n",
      "Lema: be\n",
      "Lexema: is\n",
      "Morfemas: {'Mood': 'Ind', 'Number': 'Sing', 'Person': '3', 'Tense': 'Pres', 'VerbForm': 'Fin'}\n",
      "\n",
      "Token: 106\n",
      "Lema: 106\n",
      "Lexema: 106\n",
      "Morfemas: {'NumType': 'Card'}\n",
      "\n",
      "Token: years\n",
      "Lema: year\n",
      "Lexema: years\n",
      "Morfemas: {'Number': 'Plur'}\n",
      "\n",
      "Token: old\n",
      "Lema: old\n",
      "Lexema: old\n",
      "Morfemas: {'Degree': 'Pos'}\n",
      "\n",
      "Token: .\n",
      "Lema: .\n",
      "Lexema: .\n",
      "Morfemas: {'PunctType': 'Peri'}\n",
      "\n",
      "Token: \n",
      "\n",
      "Lema: \n",
      "\n",
      "Lexema: \n",
      "\n",
      "Morfemas: {}\n",
      "\n",
      "Token: She\n",
      "Lema: she\n",
      "Lexema: She\n",
      "Morfemas: {'Case': 'Nom', 'Gender': 'Fem', 'Number': 'Sing', 'Person': '3', 'PronType': 'Prs'}\n",
      "\n",
      "Token: was\n",
      "Lema: be\n",
      "Lexema: was\n",
      "Morfemas: {'Mood': 'Ind', 'Number': 'Sing', 'Person': '3', 'Tense': 'Past', 'VerbForm': 'Fin'}\n",
      "\n",
      "Token: born\n",
      "Lema: bear\n",
      "Lexema: born\n",
      "Morfemas: {'Aspect': 'Perf', 'Tense': 'Past', 'VerbForm': 'Part'}\n",
      "\n",
      "Token: just\n",
      "Lema: just\n",
      "Lexema: just\n",
      "Morfemas: {}\n",
      "\n",
      "Token: a\n",
      "Lema: a\n",
      "Lexema: a\n",
      "Morfemas: {'Definite': 'Ind', 'PronType': 'Art'}\n",
      "\n",
      "Token: generation\n",
      "Lema: generation\n",
      "Lexema: generation\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: past\n",
      "Lema: past\n",
      "Lexema: past\n",
      "Morfemas: {'Degree': 'Pos'}\n",
      "\n",
      "Token: slavery\n",
      "Lema: slavery\n",
      "Lexema: slavery\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: ;\n",
      "Lema: ;\n",
      "Lexema: ;\n",
      "Morfemas: {}\n",
      "\n",
      "Token: a\n",
      "Lema: a\n",
      "Lexema: a\n",
      "Morfemas: {'Definite': 'Ind', 'PronType': 'Art'}\n",
      "\n",
      "Token: time\n",
      "Lema: time\n",
      "Lexema: time\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: when\n",
      "Lema: when\n",
      "Lexema: when\n",
      "Morfemas: {}\n",
      "\n",
      "Token: there\n",
      "Lema: there\n",
      "Lexema: there\n",
      "Morfemas: {}\n",
      "\n",
      "Token: were\n",
      "Lema: be\n",
      "Lexema: were\n",
      "Morfemas: {'Mood': 'Ind', 'Tense': 'Past', 'VerbForm': 'Fin'}\n",
      "\n",
      "Token: no\n",
      "Lema: no\n",
      "Lexema: no\n",
      "Morfemas: {}\n",
      "\n",
      "Token: cars\n",
      "Lema: car\n",
      "Lexema: cars\n",
      "Morfemas: {'Number': 'Plur'}\n",
      "\n",
      "Token: on\n",
      "Lema: on\n",
      "Lexema: on\n",
      "Morfemas: {}\n",
      "\n",
      "Token: the\n",
      "Lema: the\n",
      "Lexema: the\n",
      "Morfemas: {'Definite': 'Def', 'PronType': 'Art'}\n",
      "\n",
      "Token: road\n",
      "Lema: road\n",
      "Lexema: road\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: or\n",
      "Lema: or\n",
      "Lexema: or\n",
      "Morfemas: {'ConjType': 'Cmp'}\n",
      "\n",
      "Token: planes\n",
      "Lema: plane\n",
      "Lexema: planes\n",
      "Morfemas: {'Number': 'Plur'}\n",
      "\n",
      "Token: in\n",
      "Lema: in\n",
      "Lexema: in\n",
      "Morfemas: {}\n",
      "\n",
      "Token: the\n",
      "Lema: the\n",
      "Lexema: the\n",
      "Morfemas: {'Definite': 'Def', 'PronType': 'Art'}\n",
      "\n",
      "Token: sky\n",
      "Lema: sky\n",
      "Lexema: sky\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: ;\n",
      "Lema: ;\n",
      "Lexema: ;\n",
      "Morfemas: {}\n",
      "\n",
      "Token: when\n",
      "Lema: when\n",
      "Lexema: when\n",
      "Morfemas: {}\n",
      "\n",
      "Token: someone\n",
      "Lema: someone\n",
      "Lexema: someone\n",
      "Morfemas: {'Number': 'Sing', 'PronType': 'Ind'}\n",
      "\n",
      "Token: like\n",
      "Lema: like\n",
      "Lexema: like\n",
      "Morfemas: {}\n",
      "\n",
      "Token: her\n",
      "Lema: she\n",
      "Lexema: her\n",
      "Morfemas: {'Case': 'Acc', 'Gender': 'Fem', 'Number': 'Sing', 'Person': '3', 'PronType': 'Prs'}\n",
      "\n",
      "Token: could\n",
      "Lema: could\n",
      "Lexema: could\n",
      "Morfemas: {'VerbForm': 'Fin'}\n",
      "\n",
      "Token: n’t\n",
      "Lema: not\n",
      "Lexema: n’t\n",
      "Morfemas: {}\n",
      "\n",
      "Token: vote\n",
      "Lema: vote\n",
      "Lexema: vote\n",
      "Morfemas: {'VerbForm': 'Inf'}\n",
      "\n",
      "Token: for\n",
      "Lema: for\n",
      "Lexema: for\n",
      "Morfemas: {}\n",
      "\n",
      "Token: two\n",
      "Lema: two\n",
      "Lexema: two\n",
      "Morfemas: {'NumType': 'Card'}\n",
      "\n",
      "Token: reasons\n",
      "Lema: reason\n",
      "Lexema: reasons\n",
      "Morfemas: {'Number': 'Plur'}\n",
      "\n",
      "Token: —\n",
      "Lema: —\n",
      "Lexema: —\n",
      "Morfemas: {}\n",
      "\n",
      "Token: because\n",
      "Lema: because\n",
      "Lexema: because\n",
      "Morfemas: {}\n",
      "\n",
      "Token: she\n",
      "Lema: she\n",
      "Lexema: she\n",
      "Morfemas: {'Case': 'Nom', 'Gender': 'Fem', 'Number': 'Sing', 'Person': '3', 'PronType': 'Prs'}\n",
      "\n",
      "Token: was\n",
      "Lema: be\n",
      "Lexema: was\n",
      "Morfemas: {'Mood': 'Ind', 'Number': 'Sing', 'Person': '3', 'Tense': 'Past', 'VerbForm': 'Fin'}\n",
      "\n",
      "Token: a\n",
      "Lema: a\n",
      "Lexema: a\n",
      "Morfemas: {'Definite': 'Ind', 'PronType': 'Art'}\n",
      "\n",
      "Token: woman\n",
      "Lema: woman\n",
      "Lexema: woman\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: and\n",
      "Lema: and\n",
      "Lexema: and\n",
      "Morfemas: {'ConjType': 'Cmp'}\n",
      "\n",
      "Token: because\n",
      "Lema: because\n",
      "Lexema: because\n",
      "Morfemas: {}\n",
      "\n",
      "Token: of\n",
      "Lema: of\n",
      "Lexema: of\n",
      "Morfemas: {}\n",
      "\n",
      "Token: the\n",
      "Lema: the\n",
      "Lexema: the\n",
      "Morfemas: {'Definite': 'Def', 'PronType': 'Art'}\n",
      "\n",
      "Token: color\n",
      "Lema: color\n",
      "Lexema: color\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: of\n",
      "Lema: of\n",
      "Lexema: of\n",
      "Morfemas: {}\n",
      "\n",
      "Token: her\n",
      "Lema: her\n",
      "Lexema: her\n",
      "Morfemas: {'Gender': 'Fem', 'Number': 'Sing', 'Person': '3', 'Poss': 'Yes', 'PronType': 'Prs'}\n",
      "\n",
      "Token: skin\n",
      "Lema: skin\n",
      "Lexema: skin\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: .\n",
      "Lema: .\n",
      "Lexema: .\n",
      "Morfemas: {'PunctType': 'Peri'}\n",
      "\n",
      "Token: \n",
      "\n",
      "Lema: \n",
      "\n",
      "Lexema: \n",
      "\n",
      "Morfemas: {}\n",
      "\n",
      "Token: And\n",
      "Lema: and\n",
      "Lexema: And\n",
      "Morfemas: {'ConjType': 'Cmp'}\n",
      "\n",
      "Token: tonight\n",
      "Lema: tonight\n",
      "Lexema: tonight\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: ,\n",
      "Lema: ,\n",
      "Lexema: ,\n",
      "Morfemas: {'PunctType': 'Comm'}\n",
      "\n",
      "Token: I\n",
      "Lema: I\n",
      "Lexema: I\n",
      "Morfemas: {'Case': 'Nom', 'Number': 'Sing', 'Person': '1', 'PronType': 'Prs'}\n",
      "\n",
      "Token: think\n",
      "Lema: think\n",
      "Lexema: think\n",
      "Morfemas: {'Tense': 'Pres', 'VerbForm': 'Fin'}\n",
      "\n",
      "Token: about\n",
      "Lema: about\n",
      "Lexema: about\n",
      "Morfemas: {}\n",
      "\n",
      "Token: all\n",
      "Lema: all\n",
      "Lexema: all\n",
      "Morfemas: {}\n",
      "\n",
      "Token: that\n",
      "Lema: that\n",
      "Lexema: that\n",
      "Morfemas: {'PronType': 'Rel'}\n",
      "\n",
      "Token: she\n",
      "Lema: she\n",
      "Lexema: she\n",
      "Morfemas: {'Case': 'Nom', 'Gender': 'Fem', 'Number': 'Sing', 'Person': '3', 'PronType': 'Prs'}\n",
      "\n",
      "Token: ’s\n",
      "Lema: ’s\n",
      "Lexema: ’s\n",
      "Morfemas: {'Tense': 'Pres', 'VerbForm': 'Fin'}\n",
      "\n",
      "Token: seen\n",
      "Lema: see\n",
      "Lexema: seen\n",
      "Morfemas: {'Aspect': 'Perf', 'Tense': 'Past', 'VerbForm': 'Part'}\n",
      "\n",
      "Token: throughout\n",
      "Lema: throughout\n",
      "Lexema: throughout\n",
      "Morfemas: {}\n",
      "\n",
      "Token: her\n",
      "Lema: her\n",
      "Lexema: her\n",
      "Morfemas: {'Gender': 'Fem', 'Number': 'Sing', 'Person': '3', 'Poss': 'Yes', 'PronType': 'Prs'}\n",
      "\n",
      "Token: century\n",
      "Lema: century\n",
      "Lexema: century\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: in\n",
      "Lema: in\n",
      "Lexema: in\n",
      "Morfemas: {}\n",
      "\n",
      "Token: America\n",
      "Lema: America\n",
      "Lexema: America\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: —\n",
      "Lema: —\n",
      "Lexema: —\n",
      "Morfemas: {}\n",
      "\n",
      "Token: the\n",
      "Lema: the\n",
      "Lexema: the\n",
      "Morfemas: {'Definite': 'Def', 'PronType': 'Art'}\n",
      "\n",
      "Token: heartache\n",
      "Lema: heartache\n",
      "Lexema: heartache\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: and\n",
      "Lema: and\n",
      "Lexema: and\n",
      "Morfemas: {'ConjType': 'Cmp'}\n",
      "\n",
      "Token: the\n",
      "Lema: the\n",
      "Lexema: the\n",
      "Morfemas: {'Definite': 'Def', 'PronType': 'Art'}\n",
      "\n",
      "Token: hope\n",
      "Lema: hope\n",
      "Lexema: hope\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: ;\n",
      "Lema: ;\n",
      "Lexema: ;\n",
      "Morfemas: {}\n",
      "\n",
      "Token: the\n",
      "Lema: the\n",
      "Lexema: the\n",
      "Morfemas: {'Definite': 'Def', 'PronType': 'Art'}\n",
      "\n",
      "Token: struggle\n",
      "Lema: struggle\n",
      "Lexema: struggle\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: and\n",
      "Lema: and\n",
      "Lexema: and\n",
      "Morfemas: {'ConjType': 'Cmp'}\n",
      "\n",
      "Token: the\n",
      "Lema: the\n",
      "Lexema: the\n",
      "Morfemas: {'Definite': 'Def', 'PronType': 'Art'}\n",
      "\n",
      "Token: progress\n",
      "Lema: progress\n",
      "Lexema: progress\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: ;\n",
      "Lema: ;\n",
      "Lexema: ;\n",
      "Morfemas: {}\n",
      "\n",
      "Token: the\n",
      "Lema: the\n",
      "Lexema: the\n",
      "Morfemas: {'Definite': 'Def', 'PronType': 'Art'}\n",
      "\n",
      "Token: times\n",
      "Lema: time\n",
      "Lexema: times\n",
      "Morfemas: {'Number': 'Plur'}\n",
      "\n",
      "Token: we\n",
      "Lema: we\n",
      "Lexema: we\n",
      "Morfemas: {'Case': 'Nom', 'Number': 'Plur', 'Person': '1', 'PronType': 'Prs'}\n",
      "\n",
      "Token: were\n",
      "Lema: be\n",
      "Lexema: were\n",
      "Morfemas: {'Mood': 'Ind', 'Tense': 'Past', 'VerbForm': 'Fin'}\n",
      "\n",
      "Token: told\n",
      "Lema: tell\n",
      "Lexema: told\n",
      "Morfemas: {'Aspect': 'Perf', 'Tense': 'Past', 'VerbForm': 'Part'}\n",
      "\n",
      "Token: that\n",
      "Lema: that\n",
      "Lexema: that\n",
      "Morfemas: {}\n",
      "\n",
      "Token: we\n",
      "Lema: we\n",
      "Lexema: we\n",
      "Morfemas: {'Case': 'Nom', 'Number': 'Plur', 'Person': '1', 'PronType': 'Prs'}\n",
      "\n",
      "Token: ca\n",
      "Lema: can\n",
      "Lexema: ca\n",
      "Morfemas: {'VerbType': 'Mod'}\n",
      "\n",
      "Token: n’t\n",
      "Lema: n’t\n",
      "Lexema: n’t\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: ,\n",
      "Lema: ,\n",
      "Lexema: ,\n",
      "Morfemas: {'PunctType': 'Comm'}\n",
      "\n",
      "Token: and\n",
      "Lema: and\n",
      "Lexema: and\n",
      "Morfemas: {'ConjType': 'Cmp'}\n",
      "\n",
      "Token: the\n",
      "Lema: the\n",
      "Lexema: the\n",
      "Morfemas: {'Definite': 'Def', 'PronType': 'Art'}\n",
      "\n",
      "Token: people\n",
      "Lema: people\n",
      "Lexema: people\n",
      "Morfemas: {'Number': 'Plur'}\n",
      "\n",
      "Token: who\n",
      "Lema: who\n",
      "Lexema: who\n",
      "Morfemas: {}\n",
      "\n",
      "Token: pressed\n",
      "Lema: press\n",
      "Lexema: pressed\n",
      "Morfemas: {'Tense': 'Past', 'VerbForm': 'Fin'}\n",
      "\n",
      "Token: on\n",
      "Lema: on\n",
      "Lexema: on\n",
      "Morfemas: {}\n",
      "\n",
      "Token: with\n",
      "Lema: with\n",
      "Lexema: with\n",
      "Morfemas: {}\n",
      "\n",
      "Token: that\n",
      "Lema: that\n",
      "Lexema: that\n",
      "Morfemas: {'Number': 'Sing', 'PronType': 'Dem'}\n",
      "\n",
      "Token: American\n",
      "Lema: american\n",
      "Lexema: American\n",
      "Morfemas: {'Degree': 'Pos'}\n",
      "\n",
      "Token: creed\n",
      "Lema: creed\n",
      "Lexema: creed\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: :\n",
      "Lema: :\n",
      "Lexema: :\n",
      "Morfemas: {}\n",
      "\n",
      "Token: Yes\n",
      "Lema: yes\n",
      "Lexema: Yes\n",
      "Morfemas: {}\n",
      "\n",
      "Token: we\n",
      "Lema: we\n",
      "Lexema: we\n",
      "Morfemas: {'Case': 'Nom', 'Number': 'Plur', 'Person': '1', 'PronType': 'Prs'}\n",
      "\n",
      "Token: can\n",
      "Lema: can\n",
      "Lexema: can\n",
      "Morfemas: {'VerbForm': 'Fin'}\n",
      "\n",
      "Token: .\n",
      "Lema: .\n",
      "Lexema: .\n",
      "Morfemas: {'PunctType': 'Peri'}\n",
      "\n",
      "Token: \n",
      "\n",
      "Lema: \n",
      "\n",
      "Lexema: \n",
      "\n",
      "Morfemas: {}\n",
      "\n",
      "Token: At\n",
      "Lema: at\n",
      "Lexema: At\n",
      "Morfemas: {}\n",
      "\n",
      "Token: a\n",
      "Lema: a\n",
      "Lexema: a\n",
      "Morfemas: {'Definite': 'Ind', 'PronType': 'Art'}\n",
      "\n",
      "Token: time\n",
      "Lema: time\n",
      "Lexema: time\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: when\n",
      "Lema: when\n",
      "Lexema: when\n",
      "Morfemas: {}\n",
      "\n",
      "Token: women\n",
      "Lema: woman\n",
      "Lexema: women\n",
      "Morfemas: {'Number': 'Plur'}\n",
      "\n",
      "Token: ’s\n",
      "Lema: ’s\n",
      "Lexema: ’s\n",
      "Morfemas: {}\n",
      "\n",
      "Token: voices\n",
      "Lema: voice\n",
      "Lexema: voices\n",
      "Morfemas: {'Number': 'Plur'}\n",
      "\n",
      "Token: were\n",
      "Lema: be\n",
      "Lexema: were\n",
      "Morfemas: {'Mood': 'Ind', 'Tense': 'Past', 'VerbForm': 'Fin'}\n",
      "\n",
      "Token: silenced\n",
      "Lema: silence\n",
      "Lexema: silenced\n",
      "Morfemas: {'Aspect': 'Perf', 'Tense': 'Past', 'VerbForm': 'Part'}\n",
      "\n",
      "Token: and\n",
      "Lema: and\n",
      "Lexema: and\n",
      "Morfemas: {'ConjType': 'Cmp'}\n",
      "\n",
      "Token: their\n",
      "Lema: their\n",
      "Lexema: their\n",
      "Morfemas: {'Number': 'Plur', 'Person': '3', 'Poss': 'Yes', 'PronType': 'Prs'}\n",
      "\n",
      "Token: hopes\n",
      "Lema: hope\n",
      "Lexema: hopes\n",
      "Morfemas: {'Number': 'Plur'}\n",
      "\n",
      "Token: dismissed\n",
      "Lema: dismiss\n",
      "Lexema: dismissed\n",
      "Morfemas: {'Aspect': 'Perf', 'Tense': 'Past', 'VerbForm': 'Part'}\n",
      "\n",
      "Token: ,\n",
      "Lema: ,\n",
      "Lexema: ,\n",
      "Morfemas: {'PunctType': 'Comm'}\n",
      "\n",
      "Token: she\n",
      "Lema: she\n",
      "Lexema: she\n",
      "Morfemas: {'Case': 'Nom', 'Gender': 'Fem', 'Number': 'Sing', 'Person': '3', 'PronType': 'Prs'}\n",
      "\n",
      "Token: lived\n",
      "Lema: live\n",
      "Lexema: lived\n",
      "Morfemas: {'Tense': 'Past', 'VerbForm': 'Fin'}\n",
      "\n",
      "Token: to\n",
      "Lema: to\n",
      "Lexema: to\n",
      "Morfemas: {}\n",
      "\n",
      "Token: see\n",
      "Lema: see\n",
      "Lexema: see\n",
      "Morfemas: {'VerbForm': 'Inf'}\n",
      "\n",
      "Token: them\n",
      "Lema: they\n",
      "Lexema: them\n",
      "Morfemas: {'Case': 'Acc', 'Number': 'Plur', 'Person': '3', 'PronType': 'Prs'}\n",
      "\n",
      "Token: stand\n",
      "Lema: stand\n",
      "Lexema: stand\n",
      "Morfemas: {'VerbForm': 'Inf'}\n",
      "\n",
      "Token: up\n",
      "Lema: up\n",
      "Lexema: up\n",
      "Morfemas: {}\n",
      "\n",
      "Token: and\n",
      "Lema: and\n",
      "Lexema: and\n",
      "Morfemas: {'ConjType': 'Cmp'}\n",
      "\n",
      "Token: speak\n",
      "Lema: speak\n",
      "Lexema: speak\n",
      "Morfemas: {'VerbForm': 'Inf'}\n",
      "\n",
      "Token: out\n",
      "Lema: out\n",
      "Lexema: out\n",
      "Morfemas: {}\n",
      "\n",
      "Token: and\n",
      "Lema: and\n",
      "Lexema: and\n",
      "Morfemas: {'ConjType': 'Cmp'}\n",
      "\n",
      "Token: reach\n",
      "Lema: reach\n",
      "Lexema: reach\n",
      "Morfemas: {'VerbForm': 'Inf'}\n",
      "\n",
      "Token: for\n",
      "Lema: for\n",
      "Lexema: for\n",
      "Morfemas: {}\n",
      "\n",
      "Token: the\n",
      "Lema: the\n",
      "Lexema: the\n",
      "Morfemas: {'Definite': 'Def', 'PronType': 'Art'}\n",
      "\n",
      "Token: ballot\n",
      "Lema: ballot\n",
      "Lexema: ballot\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: .\n",
      "Lema: .\n",
      "Lexema: .\n",
      "Morfemas: {'PunctType': 'Peri'}\n",
      "\n",
      "Token: Yes\n",
      "Lema: yes\n",
      "Lexema: Yes\n",
      "Morfemas: {}\n",
      "\n",
      "Token: we\n",
      "Lema: we\n",
      "Lexema: we\n",
      "Morfemas: {'Case': 'Nom', 'Number': 'Plur', 'Person': '1', 'PronType': 'Prs'}\n",
      "\n",
      "Token: can\n",
      "Lema: can\n",
      "Lexema: can\n",
      "Morfemas: {'VerbForm': 'Fin'}\n",
      "\n",
      "Token: .\n",
      "Lema: .\n",
      "Lexema: .\n",
      "Morfemas: {'PunctType': 'Peri'}\n",
      "\n",
      "Token: \n",
      "\n",
      "Lema: \n",
      "\n",
      "Lexema: \n",
      "\n",
      "Morfemas: {}\n",
      "\n",
      "Token: When\n",
      "Lema: when\n",
      "Lexema: When\n",
      "Morfemas: {}\n",
      "\n",
      "Token: there\n",
      "Lema: there\n",
      "Lexema: there\n",
      "Morfemas: {}\n",
      "\n",
      "Token: was\n",
      "Lema: be\n",
      "Lexema: was\n",
      "Morfemas: {'Mood': 'Ind', 'Number': 'Sing', 'Person': '3', 'Tense': 'Past', 'VerbForm': 'Fin'}\n",
      "\n",
      "Token: despair\n",
      "Lema: despair\n",
      "Lexema: despair\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: in\n",
      "Lema: in\n",
      "Lexema: in\n",
      "Morfemas: {}\n",
      "\n",
      "Token: the\n",
      "Lema: the\n",
      "Lexema: the\n",
      "Morfemas: {'Definite': 'Def', 'PronType': 'Art'}\n",
      "\n",
      "Token: dust\n",
      "Lema: dust\n",
      "Lexema: dust\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: bowl\n",
      "Lema: bowl\n",
      "Lexema: bowl\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: and\n",
      "Lema: and\n",
      "Lexema: and\n",
      "Morfemas: {'ConjType': 'Cmp'}\n",
      "\n",
      "Token: depression\n",
      "Lema: depression\n",
      "Lexema: depression\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: across\n",
      "Lema: across\n",
      "Lexema: across\n",
      "Morfemas: {}\n",
      "\n",
      "Token: the\n",
      "Lema: the\n",
      "Lexema: the\n",
      "Morfemas: {'Definite': 'Def', 'PronType': 'Art'}\n",
      "\n",
      "Token: land\n",
      "Lema: land\n",
      "Lexema: land\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: ,\n",
      "Lema: ,\n",
      "Lexema: ,\n",
      "Morfemas: {'PunctType': 'Comm'}\n",
      "\n",
      "Token: she\n",
      "Lema: she\n",
      "Lexema: she\n",
      "Morfemas: {'Case': 'Nom', 'Gender': 'Fem', 'Number': 'Sing', 'Person': '3', 'PronType': 'Prs'}\n",
      "\n",
      "Token: saw\n",
      "Lema: see\n",
      "Lexema: saw\n",
      "Morfemas: {'Tense': 'Past', 'VerbForm': 'Fin'}\n",
      "\n",
      "Token: a\n",
      "Lema: a\n",
      "Lexema: a\n",
      "Morfemas: {'Definite': 'Ind', 'PronType': 'Art'}\n",
      "\n",
      "Token: nation\n",
      "Lema: nation\n",
      "Lexema: nation\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: conquer\n",
      "Lema: conquer\n",
      "Lexema: conquer\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: fear\n",
      "Lema: fear\n",
      "Lexema: fear\n",
      "Morfemas: {'Tense': 'Pres', 'VerbForm': 'Fin'}\n",
      "\n",
      "Token: itself\n",
      "Lema: itself\n",
      "Lexema: itself\n",
      "Morfemas: {'Case': 'Acc', 'Gender': 'Neut', 'Number': 'Sing', 'Person': '3', 'PronType': 'Prs', 'Reflex': 'Yes'}\n",
      "\n",
      "Token: with\n",
      "Lema: with\n",
      "Lexema: with\n",
      "Morfemas: {}\n",
      "\n",
      "Token: a\n",
      "Lema: a\n",
      "Lexema: a\n",
      "Morfemas: {'Definite': 'Ind', 'PronType': 'Art'}\n",
      "\n",
      "Token: New\n",
      "Lema: New\n",
      "Lexema: New\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: Deal\n",
      "Lema: Deal\n",
      "Lexema: Deal\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: ,\n",
      "Lema: ,\n",
      "Lexema: ,\n",
      "Morfemas: {'PunctType': 'Comm'}\n",
      "\n",
      "Token: new\n",
      "Lema: new\n",
      "Lexema: new\n",
      "Morfemas: {'Degree': 'Pos'}\n",
      "\n",
      "Token: jobs\n",
      "Lema: job\n",
      "Lexema: jobs\n",
      "Morfemas: {'Number': 'Plur'}\n",
      "\n",
      "Token: ,\n",
      "Lema: ,\n",
      "Lexema: ,\n",
      "Morfemas: {'PunctType': 'Comm'}\n",
      "\n",
      "Token: a\n",
      "Lema: a\n",
      "Lexema: a\n",
      "Morfemas: {'Definite': 'Ind', 'PronType': 'Art'}\n",
      "\n",
      "Token: new\n",
      "Lema: new\n",
      "Lexema: new\n",
      "Morfemas: {'Degree': 'Pos'}\n",
      "\n",
      "Token: sense\n",
      "Lema: sense\n",
      "Lexema: sense\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: of\n",
      "Lema: of\n",
      "Lexema: of\n",
      "Morfemas: {}\n",
      "\n",
      "Token: common\n",
      "Lema: common\n",
      "Lexema: common\n",
      "Morfemas: {'Degree': 'Pos'}\n",
      "\n",
      "Token: purpose\n",
      "Lema: purpose\n",
      "Lexema: purpose\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: .\n",
      "Lema: .\n",
      "Lexema: .\n",
      "Morfemas: {'PunctType': 'Peri'}\n",
      "\n",
      "Token: Yes\n",
      "Lema: yes\n",
      "Lexema: Yes\n",
      "Morfemas: {}\n",
      "\n",
      "Token: we\n",
      "Lema: we\n",
      "Lexema: we\n",
      "Morfemas: {'Case': 'Nom', 'Number': 'Plur', 'Person': '1', 'PronType': 'Prs'}\n",
      "\n",
      "Token: can\n",
      "Lema: can\n",
      "Lexema: can\n",
      "Morfemas: {'VerbForm': 'Fin'}\n",
      "\n",
      "Token: .\n",
      "Lema: .\n",
      "Lexema: .\n",
      "Morfemas: {'PunctType': 'Peri'}\n",
      "\n",
      "Token: \n",
      "\n",
      "Lema: \n",
      "\n",
      "Lexema: \n",
      "\n",
      "Morfemas: {}\n",
      "\n",
      "Token: When\n",
      "Lema: when\n",
      "Lexema: When\n",
      "Morfemas: {}\n",
      "\n",
      "Token: the\n",
      "Lema: the\n",
      "Lexema: the\n",
      "Morfemas: {'Definite': 'Def', 'PronType': 'Art'}\n",
      "\n",
      "Token: bombs\n",
      "Lema: bomb\n",
      "Lexema: bombs\n",
      "Morfemas: {'Number': 'Plur'}\n",
      "\n",
      "Token: fell\n",
      "Lema: fall\n",
      "Lexema: fell\n",
      "Morfemas: {'Tense': 'Past', 'VerbForm': 'Fin'}\n",
      "\n",
      "Token: on\n",
      "Lema: on\n",
      "Lexema: on\n",
      "Morfemas: {}\n",
      "\n",
      "Token: our\n",
      "Lema: our\n",
      "Lexema: our\n",
      "Morfemas: {'Number': 'Plur', 'Person': '1', 'Poss': 'Yes', 'PronType': 'Prs'}\n",
      "\n",
      "Token: harbor\n",
      "Lema: harbor\n",
      "Lexema: harbor\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: and\n",
      "Lema: and\n",
      "Lexema: and\n",
      "Morfemas: {'ConjType': 'Cmp'}\n",
      "\n",
      "Token: tyranny\n",
      "Lema: tyranny\n",
      "Lexema: tyranny\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: threatened\n",
      "Lema: threaten\n",
      "Lexema: threatened\n",
      "Morfemas: {'Tense': 'Past', 'VerbForm': 'Fin'}\n",
      "\n",
      "Token: the\n",
      "Lema: the\n",
      "Lexema: the\n",
      "Morfemas: {'Definite': 'Def', 'PronType': 'Art'}\n",
      "\n",
      "Token: world\n",
      "Lema: world\n",
      "Lexema: world\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: ,\n",
      "Lema: ,\n",
      "Lexema: ,\n",
      "Morfemas: {'PunctType': 'Comm'}\n",
      "\n",
      "Token: she\n",
      "Lema: she\n",
      "Lexema: she\n",
      "Morfemas: {'Case': 'Nom', 'Gender': 'Fem', 'Number': 'Sing', 'Person': '3', 'PronType': 'Prs'}\n",
      "\n",
      "Token: was\n",
      "Lema: be\n",
      "Lexema: was\n",
      "Morfemas: {'Mood': 'Ind', 'Number': 'Sing', 'Person': '3', 'Tense': 'Past', 'VerbForm': 'Fin'}\n",
      "\n",
      "Token: there\n",
      "Lema: there\n",
      "Lexema: there\n",
      "Morfemas: {'PronType': 'Dem'}\n",
      "\n",
      "Token: to\n",
      "Lema: to\n",
      "Lexema: to\n",
      "Morfemas: {}\n",
      "\n",
      "Token: witness\n",
      "Lema: witness\n",
      "Lexema: witness\n",
      "Morfemas: {'VerbForm': 'Inf'}\n",
      "\n",
      "Token: a\n",
      "Lema: a\n",
      "Lexema: a\n",
      "Morfemas: {'Definite': 'Ind', 'PronType': 'Art'}\n",
      "\n",
      "Token: generation\n",
      "Lema: generation\n",
      "Lexema: generation\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: rise\n",
      "Lema: rise\n",
      "Lexema: rise\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: to\n",
      "Lema: to\n",
      "Lexema: to\n",
      "Morfemas: {}\n",
      "\n",
      "Token: greatness\n",
      "Lema: greatness\n",
      "Lexema: greatness\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: and\n",
      "Lema: and\n",
      "Lexema: and\n",
      "Morfemas: {'ConjType': 'Cmp'}\n",
      "\n",
      "Token: a\n",
      "Lema: a\n",
      "Lexema: a\n",
      "Morfemas: {'Definite': 'Ind', 'PronType': 'Art'}\n",
      "\n",
      "Token: democracy\n",
      "Lema: democracy\n",
      "Lexema: democracy\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: was\n",
      "Lema: be\n",
      "Lexema: was\n",
      "Morfemas: {'Mood': 'Ind', 'Number': 'Sing', 'Person': '3', 'Tense': 'Past', 'VerbForm': 'Fin'}\n",
      "\n",
      "Token: saved\n",
      "Lema: save\n",
      "Lexema: saved\n",
      "Morfemas: {'Aspect': 'Perf', 'Tense': 'Past', 'VerbForm': 'Part'}\n",
      "\n",
      "Token: .\n",
      "Lema: .\n",
      "Lexema: .\n",
      "Morfemas: {'PunctType': 'Peri'}\n",
      "\n",
      "Token: Yes\n",
      "Lema: yes\n",
      "Lexema: Yes\n",
      "Morfemas: {}\n",
      "\n",
      "Token: we\n",
      "Lema: we\n",
      "Lexema: we\n",
      "Morfemas: {'Case': 'Nom', 'Number': 'Plur', 'Person': '1', 'PronType': 'Prs'}\n",
      "\n",
      "Token: can\n",
      "Lema: can\n",
      "Lexema: can\n",
      "Morfemas: {'VerbForm': 'Fin'}\n",
      "\n",
      "Token: .\n",
      "Lema: .\n",
      "Lexema: .\n",
      "Morfemas: {'PunctType': 'Peri'}\n",
      "\n",
      "Token: \n",
      "\n",
      "Lema: \n",
      "\n",
      "Lexema: \n",
      "\n",
      "Morfemas: {}\n",
      "\n",
      "Token: She\n",
      "Lema: she\n",
      "Lexema: She\n",
      "Morfemas: {'Case': 'Nom', 'Gender': 'Fem', 'Number': 'Sing', 'Person': '3', 'PronType': 'Prs'}\n",
      "\n",
      "Token: was\n",
      "Lema: be\n",
      "Lexema: was\n",
      "Morfemas: {'Mood': 'Ind', 'Number': 'Sing', 'Person': '3', 'Tense': 'Past', 'VerbForm': 'Fin'}\n",
      "\n",
      "Token: there\n",
      "Lema: there\n",
      "Lexema: there\n",
      "Morfemas: {'PronType': 'Dem'}\n",
      "\n",
      "Token: for\n",
      "Lema: for\n",
      "Lexema: for\n",
      "Morfemas: {}\n",
      "\n",
      "Token: the\n",
      "Lema: the\n",
      "Lexema: the\n",
      "Morfemas: {'Definite': 'Def', 'PronType': 'Art'}\n",
      "\n",
      "Token: buses\n",
      "Lema: bus\n",
      "Lexema: buses\n",
      "Morfemas: {'Number': 'Plur'}\n",
      "\n",
      "Token: in\n",
      "Lema: in\n",
      "Lexema: in\n",
      "Morfemas: {}\n",
      "\n",
      "Token: Montgomery\n",
      "Lema: Montgomery\n",
      "Lexema: Montgomery\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: ,\n",
      "Lema: ,\n",
      "Lexema: ,\n",
      "Morfemas: {'PunctType': 'Comm'}\n",
      "\n",
      "Token: the\n",
      "Lema: the\n",
      "Lexema: the\n",
      "Morfemas: {'Definite': 'Def', 'PronType': 'Art'}\n",
      "\n",
      "Token: hoses\n",
      "Lema: hose\n",
      "Lexema: hoses\n",
      "Morfemas: {'Number': 'Plur'}\n",
      "\n",
      "Token: in\n",
      "Lema: in\n",
      "Lexema: in\n",
      "Morfemas: {}\n",
      "\n",
      "Token: Birmingham\n",
      "Lema: Birmingham\n",
      "Lexema: Birmingham\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: ,\n",
      "Lema: ,\n",
      "Lexema: ,\n",
      "Morfemas: {'PunctType': 'Comm'}\n",
      "\n",
      "Token: a\n",
      "Lema: a\n",
      "Lexema: a\n",
      "Morfemas: {'Definite': 'Ind', 'PronType': 'Art'}\n",
      "\n",
      "Token: bridge\n",
      "Lema: bridge\n",
      "Lexema: bridge\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: in\n",
      "Lema: in\n",
      "Lexema: in\n",
      "Morfemas: {}\n",
      "\n",
      "Token: Selma\n",
      "Lema: Selma\n",
      "Lexema: Selma\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: ,\n",
      "Lema: ,\n",
      "Lexema: ,\n",
      "Morfemas: {'PunctType': 'Comm'}\n",
      "\n",
      "Token: and\n",
      "Lema: and\n",
      "Lexema: and\n",
      "Morfemas: {'ConjType': 'Cmp'}\n",
      "\n",
      "Token: a\n",
      "Lema: a\n",
      "Lexema: a\n",
      "Morfemas: {'Definite': 'Ind', 'PronType': 'Art'}\n",
      "\n",
      "Token: preacher\n",
      "Lema: preacher\n",
      "Lexema: preacher\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: from\n",
      "Lema: from\n",
      "Lexema: from\n",
      "Morfemas: {}\n",
      "\n",
      "Token: Atlanta\n",
      "Lema: Atlanta\n",
      "Lexema: Atlanta\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: who\n",
      "Lema: who\n",
      "Lexema: who\n",
      "Morfemas: {}\n",
      "\n",
      "Token: told\n",
      "Lema: tell\n",
      "Lexema: told\n",
      "Morfemas: {'Tense': 'Past', 'VerbForm': 'Fin'}\n",
      "\n",
      "Token: a\n",
      "Lema: a\n",
      "Lexema: a\n",
      "Morfemas: {'Definite': 'Ind', 'PronType': 'Art'}\n",
      "\n",
      "Token: people\n",
      "Lema: people\n",
      "Lexema: people\n",
      "Morfemas: {'Number': 'Plur'}\n",
      "\n",
      "Token: that\n",
      "Lema: that\n",
      "Lexema: that\n",
      "Morfemas: {}\n",
      "\n",
      "Token: “\n",
      "Lema: \"\n",
      "Lexema: “\n",
      "Morfemas: {'PunctSide': 'Ini', 'PunctType': 'Quot'}\n",
      "\n",
      "Token: We\n",
      "Lema: we\n",
      "Lexema: We\n",
      "Morfemas: {'Case': 'Nom', 'Number': 'Plur', 'Person': '1', 'PronType': 'Prs'}\n",
      "\n",
      "Token: Shall\n",
      "Lema: shall\n",
      "Lexema: Shall\n",
      "Morfemas: {'VerbType': 'Mod'}\n",
      "\n",
      "Token: Overcome\n",
      "Lema: overcome\n",
      "Lexema: Overcome\n",
      "Morfemas: {'VerbForm': 'Inf'}\n",
      "\n",
      "Token: .\n",
      "Lema: .\n",
      "Lexema: .\n",
      "Morfemas: {'PunctType': 'Peri'}\n",
      "\n",
      "Token: ”\n",
      "Lema: \"\n",
      "Lexema: ”\n",
      "Morfemas: {'PunctSide': 'Fin', 'PunctType': 'Quot'}\n",
      "\n",
      "Token: Yes\n",
      "Lema: yes\n",
      "Lexema: Yes\n",
      "Morfemas: {}\n",
      "\n",
      "Token: we\n",
      "Lema: we\n",
      "Lexema: we\n",
      "Morfemas: {'Case': 'Nom', 'Number': 'Plur', 'Person': '1', 'PronType': 'Prs'}\n",
      "\n",
      "Token: can\n",
      "Lema: can\n",
      "Lexema: can\n",
      "Morfemas: {'VerbForm': 'Fin'}\n",
      "\n",
      "Token: .\n",
      "Lema: .\n",
      "Lexema: .\n",
      "Morfemas: {'PunctType': 'Peri'}\n",
      "\n",
      "Token: \n",
      "\n",
      "Lema: \n",
      "\n",
      "Lexema: \n",
      "\n",
      "Morfemas: {}\n",
      "\n",
      "Token: A\n",
      "Lema: a\n",
      "Lexema: A\n",
      "Morfemas: {'Definite': 'Ind', 'PronType': 'Art'}\n",
      "\n",
      "Token: man\n",
      "Lema: man\n",
      "Lexema: man\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: touched\n",
      "Lema: touch\n",
      "Lexema: touched\n",
      "Morfemas: {'Tense': 'Past', 'VerbForm': 'Fin'}\n",
      "\n",
      "Token: down\n",
      "Lema: down\n",
      "Lexema: down\n",
      "Morfemas: {}\n",
      "\n",
      "Token: on\n",
      "Lema: on\n",
      "Lexema: on\n",
      "Morfemas: {}\n",
      "\n",
      "Token: the\n",
      "Lema: the\n",
      "Lexema: the\n",
      "Morfemas: {'Definite': 'Def', 'PronType': 'Art'}\n",
      "\n",
      "Token: moon\n",
      "Lema: moon\n",
      "Lexema: moon\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: ,\n",
      "Lema: ,\n",
      "Lexema: ,\n",
      "Morfemas: {'PunctType': 'Comm'}\n",
      "\n",
      "Token: a\n",
      "Lema: a\n",
      "Lexema: a\n",
      "Morfemas: {'Definite': 'Ind', 'PronType': 'Art'}\n",
      "\n",
      "Token: wall\n",
      "Lema: wall\n",
      "Lexema: wall\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: came\n",
      "Lema: come\n",
      "Lexema: came\n",
      "Morfemas: {'Tense': 'Past', 'VerbForm': 'Fin'}\n",
      "\n",
      "Token: down\n",
      "Lema: down\n",
      "Lexema: down\n",
      "Morfemas: {}\n",
      "\n",
      "Token: in\n",
      "Lema: in\n",
      "Lexema: in\n",
      "Morfemas: {}\n",
      "\n",
      "Token: Berlin\n",
      "Lema: Berlin\n",
      "Lexema: Berlin\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: ,\n",
      "Lema: ,\n",
      "Lexema: ,\n",
      "Morfemas: {'PunctType': 'Comm'}\n",
      "\n",
      "Token: a\n",
      "Lema: a\n",
      "Lexema: a\n",
      "Morfemas: {'Definite': 'Ind', 'PronType': 'Art'}\n",
      "\n",
      "Token: world\n",
      "Lema: world\n",
      "Lexema: world\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: was\n",
      "Lema: be\n",
      "Lexema: was\n",
      "Morfemas: {'Mood': 'Ind', 'Number': 'Sing', 'Person': '3', 'Tense': 'Past', 'VerbForm': 'Fin'}\n",
      "\n",
      "Token: connected\n",
      "Lema: connect\n",
      "Lexema: connected\n",
      "Morfemas: {'Aspect': 'Perf', 'Tense': 'Past', 'VerbForm': 'Part'}\n",
      "\n",
      "Token: by\n",
      "Lema: by\n",
      "Lexema: by\n",
      "Morfemas: {}\n",
      "\n",
      "Token: our\n",
      "Lema: our\n",
      "Lexema: our\n",
      "Morfemas: {'Number': 'Plur', 'Person': '1', 'Poss': 'Yes', 'PronType': 'Prs'}\n",
      "\n",
      "Token: own\n",
      "Lema: own\n",
      "Lexema: own\n",
      "Morfemas: {'Degree': 'Pos'}\n",
      "\n",
      "Token: science\n",
      "Lema: science\n",
      "Lexema: science\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: and\n",
      "Lema: and\n",
      "Lexema: and\n",
      "Morfemas: {'ConjType': 'Cmp'}\n",
      "\n",
      "Token: imagination\n",
      "Lema: imagination\n",
      "Lexema: imagination\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: .\n",
      "Lema: .\n",
      "Lexema: .\n",
      "Morfemas: {'PunctType': 'Peri'}\n",
      "\n",
      "Token: \n",
      "\n",
      "Lema: \n",
      "\n",
      "Lexema: \n",
      "\n",
      "Morfemas: {}\n",
      "\n",
      "Token: And\n",
      "Lema: and\n",
      "Lexema: And\n",
      "Morfemas: {'ConjType': 'Cmp'}\n",
      "\n",
      "Token: this\n",
      "Lema: this\n",
      "Lexema: this\n",
      "Morfemas: {'Number': 'Sing', 'PronType': 'Dem'}\n",
      "\n",
      "Token: year\n",
      "Lema: year\n",
      "Lexema: year\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: ,\n",
      "Lema: ,\n",
      "Lexema: ,\n",
      "Morfemas: {'PunctType': 'Comm'}\n",
      "\n",
      "Token: in\n",
      "Lema: in\n",
      "Lexema: in\n",
      "Morfemas: {}\n",
      "\n",
      "Token: this\n",
      "Lema: this\n",
      "Lexema: this\n",
      "Morfemas: {'Number': 'Sing', 'PronType': 'Dem'}\n",
      "\n",
      "Token: election\n",
      "Lema: election\n",
      "Lexema: election\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: ,\n",
      "Lema: ,\n",
      "Lexema: ,\n",
      "Morfemas: {'PunctType': 'Comm'}\n",
      "\n",
      "Token: she\n",
      "Lema: she\n",
      "Lexema: she\n",
      "Morfemas: {'Case': 'Nom', 'Gender': 'Fem', 'Number': 'Sing', 'Person': '3', 'PronType': 'Prs'}\n",
      "\n",
      "Token: touched\n",
      "Lema: touch\n",
      "Lexema: touched\n",
      "Morfemas: {'Tense': 'Past', 'VerbForm': 'Fin'}\n",
      "\n",
      "Token: her\n",
      "Lema: her\n",
      "Lexema: her\n",
      "Morfemas: {'Gender': 'Fem', 'Number': 'Sing', 'Person': '3', 'Poss': 'Yes', 'PronType': 'Prs'}\n",
      "\n",
      "Token: finger\n",
      "Lema: finger\n",
      "Lexema: finger\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: to\n",
      "Lema: to\n",
      "Lexema: to\n",
      "Morfemas: {}\n",
      "\n",
      "Token: a\n",
      "Lema: a\n",
      "Lexema: a\n",
      "Morfemas: {'Definite': 'Ind', 'PronType': 'Art'}\n",
      "\n",
      "Token: screen\n",
      "Lema: screen\n",
      "Lexema: screen\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: ,\n",
      "Lema: ,\n",
      "Lexema: ,\n",
      "Morfemas: {'PunctType': 'Comm'}\n",
      "\n",
      "Token: and\n",
      "Lema: and\n",
      "Lexema: and\n",
      "Morfemas: {'ConjType': 'Cmp'}\n",
      "\n",
      "Token: cast\n",
      "Lema: cast\n",
      "Lexema: cast\n",
      "Morfemas: {'Tense': 'Past', 'VerbForm': 'Fin'}\n",
      "\n",
      "Token: her\n",
      "Lema: her\n",
      "Lexema: her\n",
      "Morfemas: {'Gender': 'Fem', 'Number': 'Sing', 'Person': '3', 'Poss': 'Yes', 'PronType': 'Prs'}\n",
      "\n",
      "Token: vote\n",
      "Lema: vote\n",
      "Lexema: vote\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: ,\n",
      "Lema: ,\n",
      "Lexema: ,\n",
      "Morfemas: {'PunctType': 'Comm'}\n",
      "\n",
      "Token: because\n",
      "Lema: because\n",
      "Lexema: because\n",
      "Morfemas: {}\n",
      "\n",
      "Token: after\n",
      "Lema: after\n",
      "Lexema: after\n",
      "Morfemas: {}\n",
      "\n",
      "Token: 106\n",
      "Lema: 106\n",
      "Lexema: 106\n",
      "Morfemas: {'NumType': 'Card'}\n",
      "\n",
      "Token: years\n",
      "Lema: year\n",
      "Lexema: years\n",
      "Morfemas: {'Number': 'Plur'}\n",
      "\n",
      "Token: in\n",
      "Lema: in\n",
      "Lexema: in\n",
      "Morfemas: {}\n",
      "\n",
      "Token: America\n",
      "Lema: America\n",
      "Lexema: America\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: ,\n",
      "Lema: ,\n",
      "Lexema: ,\n",
      "Morfemas: {'PunctType': 'Comm'}\n",
      "\n",
      "Token: through\n",
      "Lema: through\n",
      "Lexema: through\n",
      "Morfemas: {}\n",
      "\n",
      "Token: the\n",
      "Lema: the\n",
      "Lexema: the\n",
      "Morfemas: {'Definite': 'Def', 'PronType': 'Art'}\n",
      "\n",
      "Token: best\n",
      "Lema: good\n",
      "Lexema: best\n",
      "Morfemas: {'Degree': 'Sup'}\n",
      "\n",
      "Token: of\n",
      "Lema: of\n",
      "Lexema: of\n",
      "Morfemas: {}\n",
      "\n",
      "Token: times\n",
      "Lema: time\n",
      "Lexema: times\n",
      "Morfemas: {'Number': 'Plur'}\n",
      "\n",
      "Token: and\n",
      "Lema: and\n",
      "Lexema: and\n",
      "Morfemas: {'ConjType': 'Cmp'}\n",
      "\n",
      "Token: the\n",
      "Lema: the\n",
      "Lexema: the\n",
      "Morfemas: {'Definite': 'Def', 'PronType': 'Art'}\n",
      "\n",
      "Token: darkest\n",
      "Lema: darkest\n",
      "Lexema: darkest\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: of\n",
      "Lema: of\n",
      "Lexema: of\n",
      "Morfemas: {}\n",
      "\n",
      "Token: hours\n",
      "Lema: hour\n",
      "Lexema: hours\n",
      "Morfemas: {'Number': 'Plur'}\n",
      "\n",
      "Token: ,\n",
      "Lema: ,\n",
      "Lexema: ,\n",
      "Morfemas: {'PunctType': 'Comm'}\n",
      "\n",
      "Token: she\n",
      "Lema: she\n",
      "Lexema: she\n",
      "Morfemas: {'Case': 'Nom', 'Gender': 'Fem', 'Number': 'Sing', 'Person': '3', 'PronType': 'Prs'}\n",
      "\n",
      "Token: knows\n",
      "Lema: know\n",
      "Lexema: knows\n",
      "Morfemas: {'Number': 'Sing', 'Person': '3', 'Tense': 'Pres', 'VerbForm': 'Fin'}\n",
      "\n",
      "Token: how\n",
      "Lema: how\n",
      "Lexema: how\n",
      "Morfemas: {}\n",
      "\n",
      "Token: America\n",
      "Lema: America\n",
      "Lexema: America\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: can\n",
      "Lema: can\n",
      "Lexema: can\n",
      "Morfemas: {'VerbForm': 'Fin'}\n",
      "\n",
      "Token: change\n",
      "Lema: change\n",
      "Lexema: change\n",
      "Morfemas: {'VerbForm': 'Inf'}\n",
      "\n",
      "Token: .\n",
      "Lema: .\n",
      "Lexema: .\n",
      "Morfemas: {'PunctType': 'Peri'}\n",
      "\n",
      "Token: \n",
      "\n",
      "Lema: \n",
      "\n",
      "Lexema: \n",
      "\n",
      "Morfemas: {}\n",
      "\n",
      "Token: Yes\n",
      "Lema: yes\n",
      "Lexema: Yes\n",
      "Morfemas: {}\n",
      "\n",
      "Token: we\n",
      "Lema: we\n",
      "Lexema: we\n",
      "Morfemas: {'Case': 'Nom', 'Number': 'Plur', 'Person': '1', 'PronType': 'Prs'}\n",
      "\n",
      "Token: can\n",
      "Lema: can\n",
      "Lexema: can\n",
      "Morfemas: {'VerbForm': 'Fin'}\n",
      "\n",
      "Token: .\n",
      "Lema: .\n",
      "Lexema: .\n",
      "Morfemas: {'PunctType': 'Peri'}\n",
      "\n",
      "Token: \n",
      "\n",
      "Lema: \n",
      "\n",
      "Lexema: \n",
      "\n",
      "Morfemas: {}\n",
      "\n",
      "Token: America\n",
      "Lema: America\n",
      "Lexema: America\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: ,\n",
      "Lema: ,\n",
      "Lexema: ,\n",
      "Morfemas: {'PunctType': 'Comm'}\n",
      "\n",
      "Token: we\n",
      "Lema: we\n",
      "Lexema: we\n",
      "Morfemas: {'Case': 'Nom', 'Number': 'Plur', 'Person': '1', 'PronType': 'Prs'}\n",
      "\n",
      "Token: have\n",
      "Lema: have\n",
      "Lexema: have\n",
      "Morfemas: {'Mood': 'Ind', 'Tense': 'Pres', 'VerbForm': 'Fin'}\n",
      "\n",
      "Token: come\n",
      "Lema: come\n",
      "Lexema: come\n",
      "Morfemas: {'Aspect': 'Perf', 'Tense': 'Past', 'VerbForm': 'Part'}\n",
      "\n",
      "Token: so\n",
      "Lema: so\n",
      "Lexema: so\n",
      "Morfemas: {}\n",
      "\n",
      "Token: far\n",
      "Lema: far\n",
      "Lexema: far\n",
      "Morfemas: {}\n",
      "\n",
      "Token: .\n",
      "Lema: .\n",
      "Lexema: .\n",
      "Morfemas: {'PunctType': 'Peri'}\n",
      "\n",
      "Token: We\n",
      "Lema: we\n",
      "Lexema: We\n",
      "Morfemas: {'Case': 'Nom', 'Number': 'Plur', 'Person': '1', 'PronType': 'Prs'}\n",
      "\n",
      "Token: have\n",
      "Lema: have\n",
      "Lexema: have\n",
      "Morfemas: {'Mood': 'Ind', 'Tense': 'Pres', 'VerbForm': 'Fin'}\n",
      "\n",
      "Token: seen\n",
      "Lema: see\n",
      "Lexema: seen\n",
      "Morfemas: {'Aspect': 'Perf', 'Tense': 'Past', 'VerbForm': 'Part'}\n",
      "\n",
      "Token: so\n",
      "Lema: so\n",
      "Lexema: so\n",
      "Morfemas: {}\n",
      "\n",
      "Token: much\n",
      "Lema: much\n",
      "Lexema: much\n",
      "Morfemas: {'Degree': 'Pos'}\n",
      "\n",
      "Token: .\n",
      "Lema: .\n",
      "Lexema: .\n",
      "Morfemas: {'PunctType': 'Peri'}\n",
      "\n",
      "Token: But\n",
      "Lema: but\n",
      "Lexema: But\n",
      "Morfemas: {'ConjType': 'Cmp'}\n",
      "\n",
      "Token: there\n",
      "Lema: there\n",
      "Lexema: there\n",
      "Morfemas: {}\n",
      "\n",
      "Token: is\n",
      "Lema: be\n",
      "Lexema: is\n",
      "Morfemas: {'Mood': 'Ind', 'Number': 'Sing', 'Person': '3', 'Tense': 'Pres', 'VerbForm': 'Fin'}\n",
      "\n",
      "Token: so\n",
      "Lema: so\n",
      "Lexema: so\n",
      "Morfemas: {}\n",
      "\n",
      "Token: much\n",
      "Lema: much\n",
      "Lexema: much\n",
      "Morfemas: {}\n",
      "\n",
      "Token: more\n",
      "Lema: more\n",
      "Lexema: more\n",
      "Morfemas: {'Degree': 'Cmp'}\n",
      "\n",
      "Token: to\n",
      "Lema: to\n",
      "Lexema: to\n",
      "Morfemas: {}\n",
      "\n",
      "Token: do\n",
      "Lema: do\n",
      "Lexema: do\n",
      "Morfemas: {'VerbForm': 'Inf'}\n",
      "\n",
      "Token: .\n",
      "Lema: .\n",
      "Lexema: .\n",
      "Morfemas: {'PunctType': 'Peri'}\n",
      "\n",
      "Token: So\n",
      "Lema: so\n",
      "Lexema: So\n",
      "Morfemas: {}\n",
      "\n",
      "Token: tonight\n",
      "Lema: tonight\n",
      "Lexema: tonight\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: ,\n",
      "Lema: ,\n",
      "Lexema: ,\n",
      "Morfemas: {'PunctType': 'Comm'}\n",
      "\n",
      "Token: let\n",
      "Lema: let\n",
      "Lexema: let\n",
      "Morfemas: {'VerbForm': 'Inf'}\n",
      "\n",
      "Token: us\n",
      "Lema: we\n",
      "Lexema: us\n",
      "Morfemas: {'Case': 'Acc', 'Number': 'Plur', 'Person': '1', 'PronType': 'Prs'}\n",
      "\n",
      "Token: ask\n",
      "Lema: ask\n",
      "Lexema: ask\n",
      "Morfemas: {'VerbForm': 'Inf'}\n",
      "\n",
      "Token: ourselves\n",
      "Lema: ourselves\n",
      "Lexema: ourselves\n",
      "Morfemas: {'Case': 'Acc', 'Number': 'Plur', 'Person': '1', 'PronType': 'Prs', 'Reflex': 'Yes'}\n",
      "\n",
      "Token: —\n",
      "Lema: —\n",
      "Lexema: —\n",
      "Morfemas: {}\n",
      "\n",
      "Token: if\n",
      "Lema: if\n",
      "Lexema: if\n",
      "Morfemas: {}\n",
      "\n",
      "Token: our\n",
      "Lema: our\n",
      "Lexema: our\n",
      "Morfemas: {'Number': 'Plur', 'Person': '1', 'Poss': 'Yes', 'PronType': 'Prs'}\n",
      "\n",
      "Token: children\n",
      "Lema: child\n",
      "Lexema: children\n",
      "Morfemas: {'Number': 'Plur'}\n",
      "\n",
      "Token: should\n",
      "Lema: should\n",
      "Lexema: should\n",
      "Morfemas: {'VerbForm': 'Fin'}\n",
      "\n",
      "Token: live\n",
      "Lema: live\n",
      "Lexema: live\n",
      "Morfemas: {'VerbForm': 'Inf'}\n",
      "\n",
      "Token: to\n",
      "Lema: to\n",
      "Lexema: to\n",
      "Morfemas: {}\n",
      "\n",
      "Token: see\n",
      "Lema: see\n",
      "Lexema: see\n",
      "Morfemas: {'VerbForm': 'Inf'}\n",
      "\n",
      "Token: the\n",
      "Lema: the\n",
      "Lexema: the\n",
      "Morfemas: {'Definite': 'Def', 'PronType': 'Art'}\n",
      "\n",
      "Token: next\n",
      "Lema: next\n",
      "Lexema: next\n",
      "Morfemas: {'Degree': 'Pos'}\n",
      "\n",
      "Token: century\n",
      "Lema: century\n",
      "Lexema: century\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: ;\n",
      "Lema: ;\n",
      "Lexema: ;\n",
      "Morfemas: {}\n",
      "\n",
      "Token: if\n",
      "Lema: if\n",
      "Lexema: if\n",
      "Morfemas: {}\n",
      "\n",
      "Token: my\n",
      "Lema: my\n",
      "Lexema: my\n",
      "Morfemas: {'Number': 'Sing', 'Person': '1', 'Poss': 'Yes', 'PronType': 'Prs'}\n",
      "\n",
      "Token: daughters\n",
      "Lema: daughter\n",
      "Lexema: daughters\n",
      "Morfemas: {'Number': 'Plur'}\n",
      "\n",
      "Token: should\n",
      "Lema: should\n",
      "Lexema: should\n",
      "Morfemas: {'VerbForm': 'Fin'}\n",
      "\n",
      "Token: be\n",
      "Lema: be\n",
      "Lexema: be\n",
      "Morfemas: {'VerbForm': 'Inf'}\n",
      "\n",
      "Token: so\n",
      "Lema: so\n",
      "Lexema: so\n",
      "Morfemas: {}\n",
      "\n",
      "Token: lucky\n",
      "Lema: lucky\n",
      "Lexema: lucky\n",
      "Morfemas: {'Degree': 'Pos'}\n",
      "\n",
      "Token: to\n",
      "Lema: to\n",
      "Lexema: to\n",
      "Morfemas: {}\n",
      "\n",
      "Token: live\n",
      "Lema: live\n",
      "Lexema: live\n",
      "Morfemas: {'VerbForm': 'Inf'}\n",
      "\n",
      "Token: as\n",
      "Lema: as\n",
      "Lexema: as\n",
      "Morfemas: {}\n",
      "\n",
      "Token: long\n",
      "Lema: long\n",
      "Lexema: long\n",
      "Morfemas: {}\n",
      "\n",
      "Token: as\n",
      "Lema: as\n",
      "Lexema: as\n",
      "Morfemas: {}\n",
      "\n",
      "Token: Ann\n",
      "Lema: Ann\n",
      "Lexema: Ann\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: Nixon\n",
      "Lema: Nixon\n",
      "Lexema: Nixon\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: Cooper\n",
      "Lema: Cooper\n",
      "Lexema: Cooper\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: ,\n",
      "Lema: ,\n",
      "Lexema: ,\n",
      "Morfemas: {'PunctType': 'Comm'}\n",
      "\n",
      "Token: what\n",
      "Lema: what\n",
      "Lexema: what\n",
      "Morfemas: {}\n",
      "\n",
      "Token: change\n",
      "Lema: change\n",
      "Lexema: change\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: will\n",
      "Lema: will\n",
      "Lexema: will\n",
      "Morfemas: {'VerbForm': 'Fin'}\n",
      "\n",
      "Token: they\n",
      "Lema: they\n",
      "Lexema: they\n",
      "Morfemas: {'Case': 'Nom', 'Number': 'Plur', 'Person': '3', 'PronType': 'Prs'}\n",
      "\n",
      "Token: see\n",
      "Lema: see\n",
      "Lexema: see\n",
      "Morfemas: {'VerbForm': 'Inf'}\n",
      "\n",
      "Token: ?\n",
      "Lema: ?\n",
      "Lexema: ?\n",
      "Morfemas: {'PunctType': 'Peri'}\n",
      "\n",
      "Token: What\n",
      "Lema: what\n",
      "Lexema: What\n",
      "Morfemas: {}\n",
      "\n",
      "Token: progress\n",
      "Lema: progress\n",
      "Lexema: progress\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: will\n",
      "Lema: will\n",
      "Lexema: will\n",
      "Morfemas: {'VerbForm': 'Fin'}\n",
      "\n",
      "Token: we\n",
      "Lema: we\n",
      "Lexema: we\n",
      "Morfemas: {'Case': 'Nom', 'Number': 'Plur', 'Person': '1', 'PronType': 'Prs'}\n",
      "\n",
      "Token: have\n",
      "Lema: have\n",
      "Lexema: have\n",
      "Morfemas: {'VerbForm': 'Inf'}\n",
      "\n",
      "Token: made\n",
      "Lema: make\n",
      "Lexema: made\n",
      "Morfemas: {'Aspect': 'Perf', 'Tense': 'Past', 'VerbForm': 'Part'}\n",
      "\n",
      "Token: ?\n",
      "Lema: ?\n",
      "Lexema: ?\n",
      "Morfemas: {'PunctType': 'Peri'}\n",
      "\n",
      "Token: \n",
      "\n",
      "Lema: \n",
      "\n",
      "Lexema: \n",
      "\n",
      "Morfemas: {}\n",
      "\n",
      "Token: This\n",
      "Lema: this\n",
      "Lexema: This\n",
      "Morfemas: {'Number': 'Sing', 'PronType': 'Dem'}\n",
      "\n",
      "Token: is\n",
      "Lema: be\n",
      "Lexema: is\n",
      "Morfemas: {'Mood': 'Ind', 'Number': 'Sing', 'Person': '3', 'Tense': 'Pres', 'VerbForm': 'Fin'}\n",
      "\n",
      "Token: our\n",
      "Lema: our\n",
      "Lexema: our\n",
      "Morfemas: {'Number': 'Plur', 'Person': '1', 'Poss': 'Yes', 'PronType': 'Prs'}\n",
      "\n",
      "Token: chance\n",
      "Lema: chance\n",
      "Lexema: chance\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: to\n",
      "Lema: to\n",
      "Lexema: to\n",
      "Morfemas: {}\n",
      "\n",
      "Token: answer\n",
      "Lema: answer\n",
      "Lexema: answer\n",
      "Morfemas: {'VerbForm': 'Inf'}\n",
      "\n",
      "Token: that\n",
      "Lema: that\n",
      "Lexema: that\n",
      "Morfemas: {'Number': 'Sing', 'PronType': 'Dem'}\n",
      "\n",
      "Token: call\n",
      "Lema: call\n",
      "Lexema: call\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: .\n",
      "Lema: .\n",
      "Lexema: .\n",
      "Morfemas: {'PunctType': 'Peri'}\n",
      "\n",
      "Token: This\n",
      "Lema: this\n",
      "Lexema: This\n",
      "Morfemas: {'Number': 'Sing', 'PronType': 'Dem'}\n",
      "\n",
      "Token: is\n",
      "Lema: be\n",
      "Lexema: is\n",
      "Morfemas: {'Mood': 'Ind', 'Number': 'Sing', 'Person': '3', 'Tense': 'Pres', 'VerbForm': 'Fin'}\n",
      "\n",
      "Token: our\n",
      "Lema: our\n",
      "Lexema: our\n",
      "Morfemas: {'Number': 'Plur', 'Person': '1', 'Poss': 'Yes', 'PronType': 'Prs'}\n",
      "\n",
      "Token: moment\n",
      "Lema: moment\n",
      "Lexema: moment\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: .\n",
      "Lema: .\n",
      "Lexema: .\n",
      "Morfemas: {'PunctType': 'Peri'}\n",
      "\n",
      "Token: \n",
      "\n",
      "Lema: \n",
      "\n",
      "Lexema: \n",
      "\n",
      "Morfemas: {}\n",
      "\n",
      "Token: This\n",
      "Lema: this\n",
      "Lexema: This\n",
      "Morfemas: {'Number': 'Sing', 'PronType': 'Dem'}\n",
      "\n",
      "Token: is\n",
      "Lema: be\n",
      "Lexema: is\n",
      "Morfemas: {'Mood': 'Ind', 'Number': 'Sing', 'Person': '3', 'Tense': 'Pres', 'VerbForm': 'Fin'}\n",
      "\n",
      "Token: our\n",
      "Lema: our\n",
      "Lexema: our\n",
      "Morfemas: {'Number': 'Plur', 'Person': '1', 'Poss': 'Yes', 'PronType': 'Prs'}\n",
      "\n",
      "Token: time\n",
      "Lema: time\n",
      "Lexema: time\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: ,\n",
      "Lema: ,\n",
      "Lexema: ,\n",
      "Morfemas: {'PunctType': 'Comm'}\n",
      "\n",
      "Token: to\n",
      "Lema: to\n",
      "Lexema: to\n",
      "Morfemas: {}\n",
      "\n",
      "Token: put\n",
      "Lema: put\n",
      "Lexema: put\n",
      "Morfemas: {'VerbForm': 'Inf'}\n",
      "\n",
      "Token: our\n",
      "Lema: our\n",
      "Lexema: our\n",
      "Morfemas: {'Number': 'Plur', 'Person': '1', 'Poss': 'Yes', 'PronType': 'Prs'}\n",
      "\n",
      "Token: people\n",
      "Lema: people\n",
      "Lexema: people\n",
      "Morfemas: {'Number': 'Plur'}\n",
      "\n",
      "Token: back\n",
      "Lema: back\n",
      "Lexema: back\n",
      "Morfemas: {}\n",
      "\n",
      "Token: to\n",
      "Lema: to\n",
      "Lexema: to\n",
      "Morfemas: {}\n",
      "\n",
      "Token: work\n",
      "Lema: work\n",
      "Lexema: work\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: and\n",
      "Lema: and\n",
      "Lexema: and\n",
      "Morfemas: {'ConjType': 'Cmp'}\n",
      "\n",
      "Token: open\n",
      "Lema: open\n",
      "Lexema: open\n",
      "Morfemas: {'Degree': 'Pos'}\n",
      "\n",
      "Token: doors\n",
      "Lema: door\n",
      "Lexema: doors\n",
      "Morfemas: {'Number': 'Plur'}\n",
      "\n",
      "Token: of\n",
      "Lema: of\n",
      "Lexema: of\n",
      "Morfemas: {}\n",
      "\n",
      "Token: opportunity\n",
      "Lema: opportunity\n",
      "Lexema: opportunity\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: for\n",
      "Lema: for\n",
      "Lexema: for\n",
      "Morfemas: {}\n",
      "\n",
      "Token: our\n",
      "Lema: our\n",
      "Lexema: our\n",
      "Morfemas: {'Number': 'Plur', 'Person': '1', 'Poss': 'Yes', 'PronType': 'Prs'}\n",
      "\n",
      "Token: kids\n",
      "Lema: kid\n",
      "Lexema: kids\n",
      "Morfemas: {'Number': 'Plur'}\n",
      "\n",
      "Token: ;\n",
      "Lema: ;\n",
      "Lexema: ;\n",
      "Morfemas: {}\n",
      "\n",
      "Token: to\n",
      "Lema: to\n",
      "Lexema: to\n",
      "Morfemas: {}\n",
      "\n",
      "Token: restore\n",
      "Lema: restore\n",
      "Lexema: restore\n",
      "Morfemas: {'VerbForm': 'Inf'}\n",
      "\n",
      "Token: prosperity\n",
      "Lema: prosperity\n",
      "Lexema: prosperity\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: and\n",
      "Lema: and\n",
      "Lexema: and\n",
      "Morfemas: {'ConjType': 'Cmp'}\n",
      "\n",
      "Token: promote\n",
      "Lema: promote\n",
      "Lexema: promote\n",
      "Morfemas: {'VerbForm': 'Inf'}\n",
      "\n",
      "Token: the\n",
      "Lema: the\n",
      "Lexema: the\n",
      "Morfemas: {'Definite': 'Def', 'PronType': 'Art'}\n",
      "\n",
      "Token: cause\n",
      "Lema: cause\n",
      "Lexema: cause\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: of\n",
      "Lema: of\n",
      "Lexema: of\n",
      "Morfemas: {}\n",
      "\n",
      "Token: peace\n",
      "Lema: peace\n",
      "Lexema: peace\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: ;\n",
      "Lema: ;\n",
      "Lexema: ;\n",
      "Morfemas: {}\n",
      "\n",
      "Token: to\n",
      "Lema: to\n",
      "Lexema: to\n",
      "Morfemas: {}\n",
      "\n",
      "Token: reclaim\n",
      "Lema: reclaim\n",
      "Lexema: reclaim\n",
      "Morfemas: {'VerbForm': 'Inf'}\n",
      "\n",
      "Token: the\n",
      "Lema: the\n",
      "Lexema: the\n",
      "Morfemas: {'Definite': 'Def', 'PronType': 'Art'}\n",
      "\n",
      "Token: American\n",
      "Lema: american\n",
      "Lexema: American\n",
      "Morfemas: {'Degree': 'Pos'}\n",
      "\n",
      "Token: dream\n",
      "Lema: dream\n",
      "Lexema: dream\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: and\n",
      "Lema: and\n",
      "Lexema: and\n",
      "Morfemas: {'ConjType': 'Cmp'}\n",
      "\n",
      "Token: reaffirm\n",
      "Lema: reaffirm\n",
      "Lexema: reaffirm\n",
      "Morfemas: {'VerbForm': 'Inf'}\n",
      "\n",
      "Token: that\n",
      "Lema: that\n",
      "Lexema: that\n",
      "Morfemas: {'Number': 'Sing', 'PronType': 'Dem'}\n",
      "\n",
      "Token: fundamental\n",
      "Lema: fundamental\n",
      "Lexema: fundamental\n",
      "Morfemas: {'Degree': 'Pos'}\n",
      "\n",
      "Token: truth\n",
      "Lema: truth\n",
      "Lexema: truth\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: ,\n",
      "Lema: ,\n",
      "Lexema: ,\n",
      "Morfemas: {'PunctType': 'Comm'}\n",
      "\n",
      "Token: that\n",
      "Lema: that\n",
      "Lexema: that\n",
      "Morfemas: {}\n",
      "\n",
      "Token: ,\n",
      "Lema: ,\n",
      "Lexema: ,\n",
      "Morfemas: {'PunctType': 'Comm'}\n",
      "\n",
      "Token: out\n",
      "Lema: out\n",
      "Lexema: out\n",
      "Morfemas: {}\n",
      "\n",
      "Token: of\n",
      "Lema: of\n",
      "Lexema: of\n",
      "Morfemas: {}\n",
      "\n",
      "Token: many\n",
      "Lema: many\n",
      "Lexema: many\n",
      "Morfemas: {'Degree': 'Pos'}\n",
      "\n",
      "Token: ,\n",
      "Lema: ,\n",
      "Lexema: ,\n",
      "Morfemas: {'PunctType': 'Comm'}\n",
      "\n",
      "Token: we\n",
      "Lema: we\n",
      "Lexema: we\n",
      "Morfemas: {'Case': 'Nom', 'Number': 'Plur', 'Person': '1', 'PronType': 'Prs'}\n",
      "\n",
      "Token: are\n",
      "Lema: be\n",
      "Lexema: are\n",
      "Morfemas: {'Mood': 'Ind', 'Tense': 'Pres', 'VerbForm': 'Fin'}\n",
      "\n",
      "Token: one\n",
      "Lema: one\n",
      "Lexema: one\n",
      "Morfemas: {'NumType': 'Card'}\n",
      "\n",
      "Token: ;\n",
      "Lema: ;\n",
      "Lexema: ;\n",
      "Morfemas: {}\n",
      "\n",
      "Token: that\n",
      "Lema: that\n",
      "Lexema: that\n",
      "Morfemas: {}\n",
      "\n",
      "Token: while\n",
      "Lema: while\n",
      "Lexema: while\n",
      "Morfemas: {}\n",
      "\n",
      "Token: we\n",
      "Lema: we\n",
      "Lexema: we\n",
      "Morfemas: {'Case': 'Nom', 'Number': 'Plur', 'Person': '1', 'PronType': 'Prs'}\n",
      "\n",
      "Token: breathe\n",
      "Lema: breathe\n",
      "Lexema: breathe\n",
      "Morfemas: {'Tense': 'Pres', 'VerbForm': 'Fin'}\n",
      "\n",
      "Token: ,\n",
      "Lema: ,\n",
      "Lexema: ,\n",
      "Morfemas: {'PunctType': 'Comm'}\n",
      "\n",
      "Token: we\n",
      "Lema: we\n",
      "Lexema: we\n",
      "Morfemas: {'Case': 'Nom', 'Number': 'Plur', 'Person': '1', 'PronType': 'Prs'}\n",
      "\n",
      "Token: hope\n",
      "Lema: hope\n",
      "Lexema: hope\n",
      "Morfemas: {'Tense': 'Pres', 'VerbForm': 'Fin'}\n",
      "\n",
      "Token: .\n",
      "Lema: .\n",
      "Lexema: .\n",
      "Morfemas: {'PunctType': 'Peri'}\n",
      "\n",
      "Token: And\n",
      "Lema: and\n",
      "Lexema: And\n",
      "Morfemas: {'ConjType': 'Cmp'}\n",
      "\n",
      "Token: where\n",
      "Lema: where\n",
      "Lexema: where\n",
      "Morfemas: {}\n",
      "\n",
      "Token: we\n",
      "Lema: we\n",
      "Lexema: we\n",
      "Morfemas: {'Case': 'Nom', 'Number': 'Plur', 'Person': '1', 'PronType': 'Prs'}\n",
      "\n",
      "Token: are\n",
      "Lema: be\n",
      "Lexema: are\n",
      "Morfemas: {'Mood': 'Ind', 'Tense': 'Pres', 'VerbForm': 'Fin'}\n",
      "\n",
      "Token: met\n",
      "Lema: meet\n",
      "Lexema: met\n",
      "Morfemas: {'Aspect': 'Perf', 'Tense': 'Past', 'VerbForm': 'Part'}\n",
      "\n",
      "Token: with\n",
      "Lema: with\n",
      "Lexema: with\n",
      "Morfemas: {}\n",
      "\n",
      "Token: cynicism\n",
      "Lema: cynicism\n",
      "Lexema: cynicism\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: and\n",
      "Lema: and\n",
      "Lexema: and\n",
      "Morfemas: {'ConjType': 'Cmp'}\n",
      "\n",
      "Token: doubts\n",
      "Lema: doubt\n",
      "Lexema: doubts\n",
      "Morfemas: {'Number': 'Plur'}\n",
      "\n",
      "Token: and\n",
      "Lema: and\n",
      "Lexema: and\n",
      "Morfemas: {'ConjType': 'Cmp'}\n",
      "\n",
      "Token: those\n",
      "Lema: those\n",
      "Lexema: those\n",
      "Morfemas: {'Number': 'Plur', 'PronType': 'Dem'}\n",
      "\n",
      "Token: who\n",
      "Lema: who\n",
      "Lexema: who\n",
      "Morfemas: {}\n",
      "\n",
      "Token: tell\n",
      "Lema: tell\n",
      "Lexema: tell\n",
      "Morfemas: {'Tense': 'Pres', 'VerbForm': 'Fin'}\n",
      "\n",
      "Token: us\n",
      "Lema: we\n",
      "Lexema: us\n",
      "Morfemas: {'Case': 'Acc', 'Number': 'Plur', 'Person': '1', 'PronType': 'Prs'}\n",
      "\n",
      "Token: that\n",
      "Lema: that\n",
      "Lexema: that\n",
      "Morfemas: {}\n",
      "\n",
      "Token: we\n",
      "Lema: we\n",
      "Lexema: we\n",
      "Morfemas: {'Case': 'Nom', 'Number': 'Plur', 'Person': '1', 'PronType': 'Prs'}\n",
      "\n",
      "Token: ca\n",
      "Lema: can\n",
      "Lexema: ca\n",
      "Morfemas: {'VerbType': 'Mod'}\n",
      "\n",
      "Token: n’t\n",
      "Lema: not\n",
      "Lexema: n’t\n",
      "Morfemas: {}\n",
      "\n",
      "Token: ,\n",
      "Lema: ,\n",
      "Lexema: ,\n",
      "Morfemas: {'PunctType': 'Comm'}\n",
      "\n",
      "Token: we\n",
      "Lema: we\n",
      "Lexema: we\n",
      "Morfemas: {'Case': 'Nom', 'Number': 'Plur', 'Person': '1', 'PronType': 'Prs'}\n",
      "\n",
      "Token: will\n",
      "Lema: will\n",
      "Lexema: will\n",
      "Morfemas: {'VerbForm': 'Fin'}\n",
      "\n",
      "Token: respond\n",
      "Lema: respond\n",
      "Lexema: respond\n",
      "Morfemas: {'VerbForm': 'Inf'}\n",
      "\n",
      "Token: with\n",
      "Lema: with\n",
      "Lexema: with\n",
      "Morfemas: {}\n",
      "\n",
      "Token: that\n",
      "Lema: that\n",
      "Lexema: that\n",
      "Morfemas: {'Number': 'Sing', 'PronType': 'Dem'}\n",
      "\n",
      "Token: timeless\n",
      "Lema: timeless\n",
      "Lexema: timeless\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: creed\n",
      "Lema: creed\n",
      "Lexema: creed\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: that\n",
      "Lema: that\n",
      "Lexema: that\n",
      "Morfemas: {'PronType': 'Rel'}\n",
      "\n",
      "Token: sums\n",
      "Lema: sum\n",
      "Lexema: sums\n",
      "Morfemas: {'Number': 'Sing', 'Person': '3', 'Tense': 'Pres', 'VerbForm': 'Fin'}\n",
      "\n",
      "Token: up\n",
      "Lema: up\n",
      "Lexema: up\n",
      "Morfemas: {}\n",
      "\n",
      "Token: the\n",
      "Lema: the\n",
      "Lexema: the\n",
      "Morfemas: {'Definite': 'Def', 'PronType': 'Art'}\n",
      "\n",
      "Token: spirit\n",
      "Lema: spirit\n",
      "Lexema: spirit\n",
      "Morfemas: {'Number': 'Sing'}\n",
      "\n",
      "Token: of\n",
      "Lema: of\n",
      "Lexema: of\n",
      "Morfemas: {}\n",
      "\n",
      "Token: a\n",
      "Lema: a\n",
      "Lexema: a\n",
      "Morfemas: {'Definite': 'Ind', 'PronType': 'Art'}\n",
      "\n",
      "Token: people\n",
      "Lema: people\n",
      "Lexema: people\n",
      "Morfemas: {'Number': 'Plur'}\n",
      "\n",
      "Token: :\n",
      "Lema: :\n",
      "Lexema: :\n",
      "Morfemas: {}\n",
      "\n",
      "Token: Yes\n",
      "Lema: yes\n",
      "Lexema: Yes\n",
      "Morfemas: {}\n",
      "\n",
      "Token: ,\n",
      "Lema: ,\n",
      "Lexema: ,\n",
      "Morfemas: {'PunctType': 'Comm'}\n",
      "\n",
      "Token: we\n",
      "Lema: we\n",
      "Lexema: we\n",
      "Morfemas: {'Case': 'Nom', 'Number': 'Plur', 'Person': '1', 'PronType': 'Prs'}\n",
      "\n",
      "Token: can\n",
      "Lema: can\n",
      "Lexema: can\n",
      "Morfemas: {'VerbForm': 'Fin'}\n",
      "\n",
      "Token: .\n",
      "Lema: .\n",
      "Lexema: .\n",
      "Morfemas: {'PunctType': 'Peri'}\n",
      "\n",
      "Token: [\n",
      "Lema: [\n",
      "Lexema: [\n",
      "Morfemas: {}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print('Token:', token.text)\n",
    "    print('Lema:', token.lemma_)\n",
    "    print('Lexema:', token.lex.text)\n",
    "    print('Morfemas:', token.morph.to_dict())\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size: 14pt; font-weight: bold; color: #0098cd;\">Pregunta 5.</span>\n",
    "<span style=\"font-size: 14pt; font-weight: bold; color: #0098cd;\">¿Cómo puedes identificar/eliminar las stop words?</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[If, there, is, anyone, out, there, who, still, that, is, a, where, all, are, who, still, if, the, of, our, is, in, our, who, still, the, of, our, is, your, It, ’s, the, by, that, around, and, in, this, has, never, by, who, three, and, four, many, for, the, first, in, their, because, they, that, this, must, be, that, their, could, be, that, It, ’s, the, by, and, and, and, and, not, who, a, to, the, that, we, have, never, been, just, a, of, or, a, of, and, We, are, and, always, will, be, the, of, It, ’s, the, that, those, who, ’ve, been, for, so, by, so, many, to, be, and, and, about, what, we, can, to, put, their, on, the, of, and, it, once, more, toward, the, of, a, It, ’s, been, a, but, because, of, what, we, did, on, this, in, this, at, this, has, to, more, We, did, n’t, with, much, or, many, Our, was, not, in, the, of, It, in, the, of, and, the, of, and, the, front, of, It, was, by, and, who, into, what, they, had, to, give, and, and, to, the, It, from, the, who, the, of, their, ’s, who, their, and, their, for, that, and, less, It, from, the, not, so, who, the, and, to, on, of, and, from, the, of, who, and, and, that, more, than, two, a, of, the, by, the, and, for, the, has, not, from, the, This, is, your, And, I, you, did, n’t, do, this, just, to, an, And, I, you, did, n’t, do, it, for, me, You, did, it, because, you, the, of, the, that, For, even, as, we, we, the, that, will, are, the, of, our, two, a, in, the, in, a, Even, as, we, here, we, there, are, up, in, the, of, and, the, of, to, their, for, us, There, are, and, who, will, after, the, and, how, they, ’ll, make, the, or, their, or, enough, for, their, ’s, There, ’s, to, to, be, to, and, to, to, The, will, be, Our, will, be, We, may, not, get, there, in, one, or, even, in, one, But, I, have, never, been, more, than, I, am, that, we, will, get, there, I, you, we, as, a, will, get, there, There, will, be, and, There, are, many, who, n’t, with, every, or, I, make, as, And, we, the, ca, n’t, every, But, I, will, always, be, with, you, about, the, we, I, will, to, you, when, we, And, above, all, I, will, you, to, in, the, of, this, the, only, it, ’s, been, done, in, for, by, by, by, What, in, the, of, can, not, on, this, This, alone, is, not, the, we, It, is, only, the, for, us, to, make, that, And, that, can, not, if, we, go, back, to, the, were, It, ca, n’t, without, you, without, a, of, a, of, So, us, a, of, of, where, each, of, us, to, in, and, and, after, not, only, ourselves, but, each, other, us, that, if, this, us, anything, it, ’s, that, we, can, not, have, a, while, In, this, we, or, as, one, as, one, ’s, the, to, back, on, the, same, and, and, that, has, our, for, so, ’s, that, it, was, a, from, this, who, first, the, of, the, to, the, a, on, the, of, and, and, Those, are, that, we, all, And, while, the, has, a, we, do, so, with, a, of, and, to, the, that, have, back, our, As, to, a, more, than, ours, we, are, not, but, Though, may, have, it, must, not, our, of, And, to, those, whose, I, have, yet, to, I, may, not, have, your, but, I, your, I, your, And, I, will, be, your, too, And, to, all, those, from, beyond, our, from, and, to, those, who, are, around, in, the, of, the, our, are, but, our, is, and, a, of, is, at, To, those, to, those, who, would, the, down, We, will, you, To, those, who, and, We, you, And, to, all, those, who, have, if, ’s, still, as, we, once, more, that, the, of, our, not, from, the, might, of, our, or, the, of, our, but, from, the, of, our, and, That, ’s, the, of, that, can, Our, can, be, What, we, ’ve, already, us, for, what, we, can, and, must, This, had, many, and, many, that, will, be, for, But, one, that, ’s, on, my, ’s, about, a, who, her, in, She, ’s, a, the, of, others, who, in, to, make, their, in, this, except, for, one, is, She, was, just, a, a, when, there, were, no, on, the, or, in, the, when, someone, her, could, n’t, for, two, because, she, was, a, and, because, of, the, of, her, And, I, about, all, that, she, ’s, throughout, her, in, the, and, the, the, and, the, the, we, were, that, we, ca, n’t, and, the, who, on, with, that, we, can, At, a, when, ’s, were, and, their, she, to, see, them, up, and, out, and, for, the, we, can, When, there, was, in, the, and, across, the, she, a, itself, with, a, a, of, we, can, When, the, on, our, and, the, she, was, there, to, a, to, and, a, was, we, can, She, was, there, for, the, in, the, in, a, in, and, a, from, who, a, that, We, we, can, A, down, on, the, a, down, in, a, was, by, our, own, and, And, this, in, this, she, her, to, a, and, her, because, after, in, through, the, of, and, the, of, she, how, can, we, can, we, have, so, We, have, so, much, But, there, is, so, much, more, to, do, So, us, ourselves, if, our, should, to, see, the, next, if, my, should, be, so, to, as, as, what, will, they, see, What, will, we, have, made, This, is, our, to, that, call, This, is, our, This, is, our, to, put, our, back, to, and, of, for, our, to, and, the, of, to, the, and, that, that, out, of, many, we, are, one, that, while, we, we, And, where, we, are, with, and, and, those, who, us, that, we, ca, n’t, we, will, with, that, that, up, the, of, a, we, can]\n"
     ]
    }
   ],
   "source": [
    "stop_words = []\n",
    "for token in doc:\n",
    "    if token.is_stop == True:\n",
    "        stop_words.append(token)\n",
    "print(stop_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Incluye aquí, debajo de la línea, la explicación de tu respuesta</b>\n",
    "<hr>\n",
    " "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una stopword es una palabra común que suele eliminarse de un texto durante la fase de preprocesamiento del procesamiento del lenguaje natural (PLN) porque no aportan información para el análisis del texto. Las stopwords son palabras que aparecen con frecuencia en el lenguaje e incluyen palabras como \"el\", \"un\", \"una\", \"en\", \"de\", \"y\", \"es\", \"en\", etc. Estas palabras no tienen un significado por sí solas y no suelen ser útiles para determinar el tema o el sentimiento de un texto.\n",
    "\n",
    "Eliminar las palabras clave puede ayudar a reducir la dimensionalidad de los datos del texto y facilitar y agilizar su procesamiento. Sin embargo, es importante tener en cuenta que la eliminación de las palabras clave a veces puede eliminar el contexto y el significado importantes de un texto. Por lo tanto, la decisión de eliminar o no las palabras clave depende del caso de uso específico y de los objetivos del análisis.\n",
    "\n",
    "La mayoría de las bibliotecas de PNL, incluidas como NLTK y spaCy en Python, proporcionan una lista de palabras clave comunes que se pueden utilizar para eliminarlas de un texto. Estas bibliotecas también suelen ofrecer la posibilidad de añadir o eliminar palabras clave adicionales según sea necesario."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size: 14pt; font-weight: bold; color: #0098cd;\">Pregunta 6.</span>\n",
    "<span style=\"font-size: 14pt; font-weight: bold; color: #0098cd;\">¿Qué atributo del token contiene la etiqueta NER?</span>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parece ser que las stopwords no tienene etiqueta NER, por lo que buscaremos sin tenerlas en cuenta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "“ \n",
      "Hello \n",
      ", \n",
      "Chicago GPE\n",
      ". \n",
      "\n",
      " \n",
      "doubts \n",
      "America GPE\n",
      "place \n",
      "things \n",
      "possible \n",
      ", \n",
      "wonders \n",
      "dream \n",
      "founders \n",
      "alive \n",
      "time \n",
      ", \n",
      "questions \n",
      "power \n",
      "democracy \n",
      ", \n",
      "tonight TIME\n",
      "answer \n",
      ". \n",
      "\n",
      " \n",
      "answer \n",
      "told \n",
      "lines \n",
      "stretched \n",
      "schools \n",
      "churches \n",
      "numbers \n",
      "nation \n",
      "seen \n",
      ", \n",
      "people \n",
      "waited \n",
      "hours TIME\n",
      "hours TIME\n",
      ", \n",
      "time \n",
      "lives \n",
      ", \n",
      "believed \n",
      "time \n",
      "different \n",
      ", \n",
      "voices \n",
      "difference \n",
      ". \n",
      "\n",
      " \n",
      "answer \n",
      "spoken \n",
      "young \n",
      "old \n",
      ", \n",
      "rich \n",
      "poor \n",
      ", \n",
      "Democrat NORP\n",
      "Republican NORP\n",
      ", \n",
      "black \n",
      ", \n",
      "white \n",
      ", \n",
      "Hispanic NORP\n",
      ", \n",
      "Asian NORP\n",
      ", \n",
      "Native NORP\n",
      "American NORP\n",
      ", \n",
      "gay \n",
      ", \n",
      "straight \n",
      ", \n",
      "disabled \n",
      "disabled \n",
      ". \n",
      "Americans NORP\n",
      "sent \n",
      "message \n",
      "world \n",
      "collection \n",
      "individuals \n",
      "collection \n",
      "red \n",
      "states \n",
      "blue \n",
      "states \n",
      ". \n",
      "\n",
      " \n",
      ", \n",
      ", \n",
      "United GPE\n",
      "States GPE\n",
      "America GPE\n",
      ". \n",
      "\n",
      " \n",
      "answer \n",
      "led \n",
      "told \n",
      "long \n",
      "cynical \n",
      "fearful \n",
      "doubtful \n",
      "achieve \n",
      "hands \n",
      "arc \n",
      "history \n",
      "bend \n",
      "hope \n",
      "better \n",
      "day \n",
      ". \n",
      "\n",
      " \n",
      "long \n",
      "time \n",
      "coming \n",
      ", \n",
      "tonight TIME\n",
      ", \n",
      "date \n",
      "election \n",
      "defining \n",
      "moment \n",
      "change \n",
      "come \n",
      "America GPE\n",
      ". \n",
      "\n",
      " \n",
      "[ \n",
      "read \n",
      "] \n",
      "\n",
      "\n",
      " \n",
      "start \n",
      "money \n",
      "endorsements \n",
      ". \n",
      "campaign \n",
      "hatched \n",
      "halls \n",
      "Washington GPE\n",
      ". \n",
      "began \n",
      "backyards \n",
      "Des GPE\n",
      "Moines GPE\n",
      "living \n",
      "rooms \n",
      "Concord GPE\n",
      "porches \n",
      "Charleston GPE\n",
      ". \n",
      "built \n",
      "working \n",
      "men \n",
      "women \n",
      "dug \n",
      "little \n",
      "savings \n",
      "$ MONEY\n",
      "5 MONEY\n",
      "$ MONEY\n",
      "10 MONEY\n",
      "$ MONEY\n",
      "20 MONEY\n",
      "cause \n",
      ". \n",
      "\n",
      " \n",
      "grew \n",
      "strength \n",
      "young \n",
      "people \n",
      "rejected \n",
      "myth \n",
      "generation \n",
      "apathy \n",
      "left \n",
      "homes \n",
      "families \n",
      "jobs \n",
      "offered \n",
      "little \n",
      "pay \n",
      "sleep \n",
      ". \n",
      "\n",
      " \n",
      "drew \n",
      "strength \n",
      "- \n",
      "- \n",
      "young \n",
      "people \n",
      "braved \n",
      "bitter \n",
      "cold \n",
      "scorching \n",
      "heat \n",
      "knock \n",
      "doors \n",
      "perfect \n",
      "strangers \n",
      ", \n",
      "millions CARDINAL\n",
      "Americans NORP\n",
      "volunteered \n",
      "organized \n",
      "proved \n",
      "centuries DATE\n",
      "later DATE\n",
      "government \n",
      "people \n",
      ", \n",
      "people \n",
      ", \n",
      "people \n",
      "perished \n",
      "Earth LOC\n",
      ". \n",
      "\n",
      " \n",
      "victory \n",
      ". \n",
      "\n",
      " \n",
      "know \n",
      "win \n",
      "election \n",
      ". \n",
      "know \n",
      ". \n",
      "\n",
      " \n",
      "understand \n",
      "enormity \n",
      "task \n",
      "lies \n",
      "ahead \n",
      ". \n",
      "celebrate \n",
      "tonight TIME\n",
      ", \n",
      "know \n",
      "challenges \n",
      "tomorrow DATE\n",
      "bring \n",
      "greatest \n",
      "lifetime \n",
      "— \n",
      "wars \n",
      ", \n",
      "planet \n",
      "peril \n",
      ", \n",
      "worst \n",
      "financial \n",
      "crisis \n",
      "century DATE\n",
      ". \n",
      "\n",
      " \n",
      "stand \n",
      "tonight TIME\n",
      ", \n",
      "know \n",
      "brave \n",
      "Americans NORP\n",
      "waking \n",
      "deserts \n",
      "Iraq GPE\n",
      "mountains \n",
      "Afghanistan GPE\n",
      "risk \n",
      "lives \n",
      ". \n",
      "\n",
      " \n",
      "mothers \n",
      "fathers \n",
      "lie \n",
      "awake \n",
      "children \n",
      "fall \n",
      "asleep \n",
      "wonder \n",
      "mortgage \n",
      "pay \n",
      "doctors \n",
      "’ \n",
      "bills \n",
      "save \n",
      "child \n",
      "college \n",
      "education \n",
      ". \n",
      "\n",
      " \n",
      "new \n",
      "energy \n",
      "harness \n",
      ", \n",
      "new \n",
      "jobs \n",
      "created \n",
      ", \n",
      "new \n",
      "schools \n",
      "build \n",
      ", \n",
      "threats \n",
      "meet \n",
      ", \n",
      "alliances \n",
      "repair \n",
      ". \n",
      "\n",
      " \n",
      "road \n",
      "ahead \n",
      "long \n",
      ". \n",
      "climb \n",
      "steep \n",
      ". \n",
      "year DATE\n",
      "term \n",
      ". \n",
      ", \n",
      "America GPE\n",
      ", \n",
      "hopeful \n",
      "tonight TIME\n",
      ". \n",
      "\n",
      " \n",
      "promise \n",
      ", \n",
      "people \n",
      ". \n",
      "\n",
      " \n",
      "setbacks \n",
      "false \n",
      "starts \n",
      ". \n",
      "wo \n",
      "agree \n",
      "decision \n",
      "policy \n",
      "president \n",
      ". \n",
      "know \n",
      "government \n",
      "solve \n",
      "problem \n",
      ". \n",
      "\n",
      " \n",
      "honest \n",
      "challenges \n",
      "face \n",
      ". \n",
      "listen \n",
      ", \n",
      "especially \n",
      "disagree \n",
      ". \n",
      ", \n",
      ", \n",
      "ask \n",
      "join \n",
      "work \n",
      "remaking \n",
      "nation \n",
      ", \n",
      "way \n",
      "America GPE\n",
      "221 DATE\n",
      "years DATE\n",
      "— \n",
      "block \n",
      "block \n",
      ", \n",
      "brick \n",
      "brick \n",
      ", \n",
      "calloused \n",
      "hand \n",
      "calloused \n",
      "hand \n",
      ". \n",
      "\n",
      " \n",
      "began \n",
      "21 DATE\n",
      "months DATE\n",
      "ago DATE\n",
      "depths \n",
      "winter DATE\n",
      "end \n",
      "autumn TIME\n",
      "night TIME\n",
      ". \n",
      "\n",
      " \n",
      "victory \n",
      "change \n",
      "seek \n",
      ". \n",
      "chance \n",
      "change \n",
      ". \n",
      "happen \n",
      "way \n",
      "things \n",
      ". \n",
      "\n",
      " \n",
      "happen \n",
      ", \n",
      "new \n",
      "spirit \n",
      "service \n",
      ", \n",
      "new \n",
      "spirit \n",
      "sacrifice \n",
      ". \n",
      "\n",
      " \n",
      "let \n",
      "summon \n",
      "new \n",
      "spirit \n",
      "patriotism \n",
      ", \n",
      "responsibility \n",
      ", \n",
      "resolves \n",
      "pitch \n",
      "work \n",
      "harder \n",
      "look \n",
      ". \n",
      "\n",
      " \n",
      "Let \n",
      "remember \n",
      ", \n",
      "financial \n",
      "crisis \n",
      "taught \n",
      ", \n",
      "thriving \n",
      "Wall \n",
      "Street \n",
      "Main FAC\n",
      "Street FAC\n",
      "suffers \n",
      ". \n",
      "\n",
      " \n",
      "country \n",
      ", \n",
      "rise \n",
      "fall \n",
      "nation \n",
      ", \n",
      "people \n",
      ". \n",
      "Let \n",
      "resist \n",
      "temptation \n",
      "fall \n",
      "partisanship \n",
      "pettiness \n",
      "immaturity \n",
      "poisoned \n",
      "politics \n",
      "long \n",
      ". \n",
      "\n",
      " \n",
      "Let \n",
      "remember \n",
      "man \n",
      "state \n",
      "carried \n",
      "banner \n",
      "Republican ORG\n",
      "Party ORG\n",
      "White ORG\n",
      "House ORG\n",
      ", \n",
      "party \n",
      "founded \n",
      "values \n",
      "self \n",
      "- \n",
      "reliance \n",
      "individual \n",
      "liberty \n",
      "national \n",
      "unity \n",
      ". \n",
      "\n",
      " \n",
      "values \n",
      "share \n",
      ". \n",
      "Democratic ORG\n",
      "Party ORG\n",
      "won \n",
      "great \n",
      "victory \n",
      "tonight TIME\n",
      ", \n",
      "measure \n",
      "humility \n",
      "determination \n",
      "heal \n",
      "divides \n",
      "held \n",
      "progress \n",
      ". \n",
      "\n",
      " \n",
      "Lincoln ORG\n",
      "said \n",
      "nation \n",
      "far \n",
      "divided \n",
      ", \n",
      "enemies \n",
      "friends \n",
      ". \n",
      "passion \n",
      "strained \n",
      ", \n",
      "break \n",
      "bonds \n",
      "affection \n",
      ". \n",
      "\n",
      " \n",
      "Americans NORP\n",
      "support \n",
      "earn \n",
      ", \n",
      "won \n",
      "vote \n",
      "tonight TIME\n",
      ", \n",
      "hear \n",
      "voices \n",
      ". \n",
      "need \n",
      "help \n",
      ". \n",
      "president \n",
      ", \n",
      ". \n",
      "\n",
      " \n",
      "watching \n",
      "tonight TIME\n",
      "shores \n",
      ", \n",
      "parliaments \n",
      "palaces \n",
      ", \n",
      "huddled \n",
      "radios \n",
      "forgotten \n",
      "corners \n",
      "world \n",
      ", \n",
      "stories \n",
      "singular \n",
      ", \n",
      "destiny \n",
      "shared \n",
      ", \n",
      "new \n",
      "dawn \n",
      "American NORP\n",
      "leadership \n",
      "hand \n",
      ". \n",
      "\n",
      " \n",
      "— \n",
      "tear \n",
      "world \n",
      ": \n",
      "defeat \n",
      ". \n",
      "seek \n",
      "peace \n",
      "security \n",
      ": \n",
      "support \n",
      ". \n",
      "wondered \n",
      "America GPE\n",
      "beacon \n",
      "burns \n",
      "bright \n",
      ": \n",
      "Tonight TIME\n",
      "proved \n",
      "true \n",
      "strength \n",
      "nation \n",
      "comes \n",
      "arms \n",
      "scale \n",
      "wealth \n",
      ", \n",
      "enduring \n",
      "power \n",
      "ideals \n",
      ": \n",
      "democracy \n",
      ", \n",
      "liberty \n",
      ", \n",
      "opportunity \n",
      "unyielding \n",
      "hope \n",
      ". \n",
      "\n",
      " \n",
      "true \n",
      "genius \n",
      "America GPE\n",
      ": \n",
      "America GPE\n",
      "change \n",
      ". \n",
      "union \n",
      "perfected \n",
      ". \n",
      "achieved \n",
      "gives \n",
      "hope \n",
      "achieve \n",
      "tomorrow DATE\n",
      ". \n",
      "\n",
      " \n",
      "election \n",
      "firsts \n",
      "stories \n",
      "told \n",
      "generations \n",
      ". \n",
      "mind \n",
      "tonight TIME\n",
      "woman \n",
      "cast \n",
      "ballot \n",
      "Atlanta GPE\n",
      ". \n",
      "lot \n",
      "like \n",
      "millions CARDINAL\n",
      "stood \n",
      "line \n",
      "voice \n",
      "heard \n",
      "election \n",
      "thing \n",
      ": \n",
      "Ann PERSON\n",
      "Nixon PERSON\n",
      "Cooper PERSON\n",
      "106 DATE\n",
      "years DATE\n",
      "old DATE\n",
      ". \n",
      "\n",
      " \n",
      "born \n",
      "generation \n",
      "past \n",
      "slavery \n",
      "; \n",
      "time \n",
      "cars \n",
      "road \n",
      "planes \n",
      "sky \n",
      "; \n",
      "like \n",
      "vote \n",
      "reasons \n",
      "— \n",
      "woman \n",
      "color \n",
      "skin \n",
      ". \n",
      "\n",
      " \n",
      "tonight TIME\n",
      ", \n",
      "think \n",
      "seen \n",
      "century \n",
      "America GPE\n",
      "— \n",
      "heartache \n",
      "hope \n",
      "; \n",
      "struggle \n",
      "progress \n",
      "; \n",
      "times \n",
      "told \n",
      ", \n",
      "people \n",
      "pressed \n",
      "American NORP\n",
      "creed \n",
      ": \n",
      "Yes \n",
      ". \n",
      "\n",
      " \n",
      "time \n",
      "women \n",
      "voices \n",
      "silenced \n",
      "hopes \n",
      "dismissed \n",
      ", \n",
      "lived \n",
      "stand \n",
      "speak \n",
      "reach \n",
      "ballot \n",
      ". \n",
      "Yes \n",
      ". \n",
      "\n",
      " \n",
      "despair \n",
      "dust \n",
      "bowl \n",
      "depression \n",
      "land \n",
      ", \n",
      "saw \n",
      "nation \n",
      "conquer \n",
      "fear \n",
      "New \n",
      "Deal \n",
      ", \n",
      "new \n",
      "jobs \n",
      ", \n",
      "new \n",
      "sense \n",
      "common \n",
      "purpose \n",
      ". \n",
      "Yes \n",
      ". \n",
      "\n",
      " \n",
      "bombs \n",
      "fell \n",
      "harbor \n",
      "tyranny \n",
      "threatened \n",
      "world \n",
      ", \n",
      "witness \n",
      "generation \n",
      "rise \n",
      "greatness \n",
      "democracy \n",
      "saved \n",
      ". \n",
      "Yes \n",
      ". \n",
      "\n",
      " \n",
      "buses \n",
      "Montgomery ORG\n",
      ", \n",
      "hoses \n",
      "Birmingham GPE\n",
      ", \n",
      "bridge \n",
      "Selma GPE\n",
      ", \n",
      "preacher \n",
      "Atlanta GPE\n",
      "told \n",
      "people \n",
      "“ \n",
      "Shall \n",
      "Overcome \n",
      ". \n",
      "” \n",
      "Yes \n",
      ". \n",
      "\n",
      " \n",
      "man \n",
      "touched \n",
      "moon LOC\n",
      ", \n",
      "wall \n",
      "came \n",
      "Berlin GPE\n",
      ", \n",
      "world \n",
      "connected \n",
      "science \n",
      "imagination \n",
      ". \n",
      "\n",
      " \n",
      "year DATE\n",
      ", \n",
      "election \n",
      ", \n",
      "touched \n",
      "finger \n",
      "screen \n",
      ", \n",
      "cast \n",
      "vote \n",
      ", \n",
      "106 DATE\n",
      "years DATE\n",
      "America GPE\n",
      ", \n",
      "best \n",
      "times \n",
      "darkest \n",
      "hours TIME\n",
      ", \n",
      "knows \n",
      "America GPE\n",
      "change \n",
      ". \n",
      "\n",
      " \n",
      "Yes \n",
      ". \n",
      "\n",
      " \n",
      "America GPE\n",
      ", \n",
      "come \n",
      "far \n",
      ". \n",
      "seen \n",
      ". \n",
      ". \n",
      "tonight TIME\n",
      ", \n",
      "let \n",
      "ask \n",
      "— \n",
      "children \n",
      "live \n",
      "century DATE\n",
      "; \n",
      "daughters \n",
      "lucky \n",
      "live \n",
      "long \n",
      "Ann PERSON\n",
      "Nixon PERSON\n",
      "Cooper PERSON\n",
      ", \n",
      "change \n",
      "? \n",
      "progress \n",
      "? \n",
      "\n",
      " \n",
      "chance \n",
      "answer \n",
      ". \n",
      "moment \n",
      ". \n",
      "\n",
      " \n",
      "time \n",
      ", \n",
      "people \n",
      "work \n",
      "open \n",
      "doors \n",
      "opportunity \n",
      "kids \n",
      "; \n",
      "restore \n",
      "prosperity \n",
      "promote \n",
      "cause \n",
      "peace \n",
      "; \n",
      "reclaim \n",
      "American NORP\n",
      "dream \n",
      "reaffirm \n",
      "fundamental \n",
      "truth \n",
      ", \n",
      ", \n",
      ", \n",
      "; \n",
      "breathe \n",
      ", \n",
      "hope \n",
      ". \n",
      "met \n",
      "cynicism \n",
      "doubts \n",
      "tell \n",
      ", \n",
      "respond \n",
      "timeless \n",
      "creed \n",
      "sums \n",
      "spirit \n",
      "people \n",
      ": \n",
      "Yes \n",
      ", \n",
      ". \n",
      "[ \n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    if token.is_stop != True:\n",
    "        print(token.text, token.ent_type_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Incluye aquí, debajo de la línea, la explicación de tu respuesta</b>\n",
    "<hr>\n",
    " "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El atributo del token en spaCy que contiene la etiqueta NER (Reconocimiento de Entidades Nombradas, por sus siglas en inglés) es token.ent_type_.\n",
    "\n",
    "Cuando procesas un texto con spaCy, el modelo de lenguaje intenta identificar las entidades nombradas en el texto y les asigna una etiqueta NER. Esta etiqueta puede indicar el tipo de entidad nombrada (por ejemplo, \"persona\", \"organización\", \"país\", etc.) o puede indicar que el token no forma parte de ninguna entidad nombrada (en cuyo caso la etiqueta es una cadena vacía)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size: 14pt; font-weight: bold; color: #0098cd;\">Pregunta 7.</span>\n",
    "<span style=\"font-size: 14pt; font-weight: bold; color: #0098cd;\">¿Qué entidades soporta Spacy?, ¿Qué significa cada una?</span>\n",
    "\n",
    "<b>Nota</b>: Debes escribir el código que liste las entidades disponibles y la explicación de las mismas. El listado sin código se considerará respuesta incompleta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chicago GPE\n",
      "America GPE\n",
      "tonight TIME\n",
      "three hours TIME\n",
      "four hours TIME\n",
      "first ORDINAL\n",
      "Democrat NORP\n",
      "Republican NORP\n",
      "Hispanic NORP\n",
      "Asian NORP\n",
      "Native American NORP\n",
      "Americans NORP\n",
      "the United States of America GPE\n",
      "tonight TIME\n",
      "America GPE\n",
      "Washington GPE\n",
      "Des Moines GPE\n",
      "Concord GPE\n",
      "Charleston GPE\n",
      "$5 and $10 and $20 MONEY\n",
      "millions CARDINAL\n",
      "Americans NORP\n",
      "more than two centuries later DATE\n",
      "Earth LOC\n",
      "tonight TIME\n",
      "tomorrow DATE\n",
      "two CARDINAL\n",
      "a century DATE\n",
      "tonight TIME\n",
      "Americans NORP\n",
      "Iraq GPE\n",
      "Afghanistan GPE\n",
      "one year DATE\n",
      "one CARDINAL\n",
      "America GPE\n",
      "tonight TIME\n",
      "America GPE\n",
      "221 years DATE\n",
      "21 months ago DATE\n",
      "winter DATE\n",
      "this autumn night TIME\n",
      "Main Street FAC\n",
      "one CARDINAL\n",
      "one CARDINAL\n",
      "first ORDINAL\n",
      "the Republican Party ORG\n",
      "the White House ORG\n",
      "the Democratic Party ORG\n",
      "tonight TIME\n",
      "Lincoln ORG\n",
      "Americans NORP\n",
      "tonight TIME\n",
      "tonight TIME\n",
      "American NORP\n",
      "America GPE\n",
      "Tonight TIME\n",
      "America GPE\n",
      "America GPE\n",
      "tomorrow DATE\n",
      "tonight TIME\n",
      "Atlanta GPE\n",
      "millions CARDINAL\n",
      "one CARDINAL\n",
      "Ann Nixon Cooper PERSON\n",
      "106 years old DATE\n",
      "two CARDINAL\n",
      "tonight TIME\n",
      "America GPE\n",
      "American NORP\n",
      "Montgomery ORG\n",
      "Birmingham GPE\n",
      "Selma GPE\n",
      "Atlanta GPE\n",
      "the moon LOC\n",
      "Berlin GPE\n",
      "this year DATE\n",
      "106 years DATE\n",
      "America GPE\n",
      "hours TIME\n",
      "America GPE\n",
      "America GPE\n",
      "tonight TIME\n",
      "the next century DATE\n",
      "Ann Nixon Cooper PERSON\n",
      "American NORP\n"
     ]
    }
   ],
   "source": [
    "for entidad in doc.ents:\n",
    "    print(entidad.text, entidad.label_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Incluye aquí, debajo de la línea, la explicación de tu respuesta</b>\n",
    "<hr>\n",
    " "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PERSON: Nombres de personas.\n",
    "\n",
    "NORP: Nacionalidades o grupos étnicos.\n",
    "\n",
    "FAC: Edificios, aeropuertos, autopistas, puentes, etc.\n",
    "\n",
    "ORG: Nombres de organizaciones.\n",
    "\n",
    "GPE: Países, ciudades y estados.\n",
    "\n",
    "LOC: Ubicaciones geográficas específicas (por ejemplo, montañas, ríos, etc).\n",
    "\n",
    "PRODUCT: Nombres de productos (por ejemplo, \"iPhone\").\n",
    "\n",
    "EVENT: Nombres de eventos (por ejemplo, \"Olimpiadas\").\n",
    "\n",
    "WORK_OF_ART: Nombres de obras de arte (por ejemplo, \"Mona Lisa\").\n",
    "\n",
    "LAW: Nombres de leyes y regulaciones.\n",
    "\n",
    "LANGUAGE: Nombres de lenguajes naturales.\n",
    "\n",
    "DATE: Fechas específicas o rangos de fechas.\n",
    "\n",
    "TIME: Tiempos específicos o rangos de tiempo.\n",
    "\n",
    "PERCENT: Valores de porcentaje (por ejemplo, \"50%\").\n",
    "\n",
    "MONEY: Valores monetarios (por ejemplo, \"$10\").\n",
    "\n",
    "QUANTITY: Medidas de cantidad (por ejemplo, \"10 kilos\").\n",
    "\n",
    "ORDINAL: Números ordinales (por ejemplo, \"1st\", \"2nd\", etc).\n",
    "\n",
    "CARDINAL: Números cardinales (por ejemplo, \"1\", \"2\", \"3\", etc).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size: 14pt; font-weight: bold; color: #0098cd;\">Pregunta 8.</span>\n",
    "<span style=\"font-size: 14pt; font-weight: bold; color: #0098cd;\">¿Qué entidades diferentes son reconocidas en el texto?, ¿cuántas hay de cada tipo?</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entidades encontradas en el texto:\n",
      "- GPE: 24\n",
      "- TIME: 16\n",
      "- ORDINAL: 2\n",
      "- NORP: 12\n",
      "- MONEY: 1\n",
      "- CARDINAL: 8\n",
      "- DATE: 12\n",
      "- LOC: 2\n",
      "- FAC: 1\n",
      "- ORG: 5\n",
      "- PERSON: 2\n"
     ]
    }
   ],
   "source": [
    "entidades = {}\n",
    "for entidad in doc.ents:\n",
    "    # Obtener el texto y la etiqueta de la entidad\n",
    "    tipo_entidad = entidad.label_\n",
    "    texto_entidad = entidad.text\n",
    "    # Actualizar el contador para el tipo de entidad correspondiente\n",
    "    if tipo_entidad in entidades:\n",
    "        entidades[tipo_entidad] += 1\n",
    "    else:\n",
    "        entidades[tipo_entidad] = 1\n",
    "\n",
    "# Imprimir el resultado\n",
    "print(\"Entidades encontradas en el texto:\")\n",
    "for tipo, frecuencia in entidades.items():\n",
    "    print(\"- {}: {}\".format(tipo, frecuencia))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Incluye aquí, debajo de la línea, la explicación de tu respuesta</b>\n",
    "<hr>\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size: 14pt; font-weight: bold; color: #0098cd;\">Pregunta 9.</span>\n",
    "<span style=\"font-size: 14pt; font-weight: bold; color: #0098cd;\">Explica con tus palabras qué es el código IOB para el reconocimiento de entiedades. Pon un ejemplo, sacado del texto, de una etiqueta de un único token y una etiqueta compuesta por varios tokens.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Incluye aquí el código generado para poder responder a tu pregunta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Incluye aquí, debajo de la línea, la explicación de tu respuesta</b>\n",
    "<hr>\n",
    " "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El código IOB es un formato comúnmente utilizado para etiquetar secuencias de texto con información de entidades nombradas. IOB significa \"Inside, Outside, Beginning\", lo que indica si un token en una secuencia pertenece a una entidad (\"Inside\"), no pertenece a una entidad (\"Outside\"), o es el primer token de una entidad (\"Beginning\"). El código IOB se utiliza para representar las entidades nombradas como secuencias de tokens en lugar de tokens individuales, lo que hace que sea más fácil identificar y manejar las entidades en el análisis de texto.\n",
    "\n",
    "Un ejemplo de una etiqueta de un único token utilizando el formato IOB podría ser:\n",
    "\n",
    "    \"Barack\" -> B-PER (comenzando la entidad de tipo persona)\n",
    "\n",
    "Un ejemplo de una etiqueta compuesta por varios tokens utilizando el formato IOB podría ser:\n",
    "\n",
    "    \"Barack Obama is the president of the United States.\" -> B-PER I-PER O O O O O O O\n",
    "\n",
    "En este ejemplo, \"Barack\" y \"Obama\" forman una entidad de tipo persona, por lo que son etiquetados con las etiquetas \"B-PER\" (comenzando la entidad de tipo persona) y \"I-PER\" (continuando la entidad de tipo persona) respectivamente. El resto de las palabras en la oración no forman parte de ninguna entidad nombrada y se etiquetan como \"O\" (fuera de la entidad)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
